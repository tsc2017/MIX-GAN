{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MIX-MHingeGAN-CIFAR-10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RbpVxU6sF2qhDD0EV1yP_WjCeIf_tBKq",
      "authorship_tag": "ABX9TyOKAYCPT5uXpXFmf6yYLqqv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsc2017/MIX-GAN/blob/main/MIX-MHingeGAN-CIFAR-10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2KyBv_2qxmK",
        "outputId": "2e2e4e3b-6b6f-4122-be28-eb5ec273fed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct 14 18:33:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    25W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVMsjRIZrbO2",
        "outputId": "ad50cb4d-a490-4810-bcad-bc25d1530c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Mounting Google Drive â†–here would be simpler if you are the creator of a notebook. Maybe you can create a new notebook and copy the cells.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB_9wmqKJ4Sr"
      },
      "source": [
        "# Monitor GPU Utilization, GPU temp, etc\n",
        "#!pip install wandb\n",
        "#import wandb\n",
        "#wandb.init()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5VOpNC-Jlr4",
        "outputId": "979404fb-4752-4f29-e178-eccbc5883720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "pip install tensorflow-gan"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gan in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: tensorflow-probability>=0.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gan) (0.11.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gan) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle==1.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow-gan) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow-gan) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow-gan) (0.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow-gan) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow-gan) (0.1.5)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.7->tensorflow-gan) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub>=0.2->tensorflow-gan) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub>=0.2->tensorflow-gan) (50.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3BbtNdwQuw7"
      },
      "source": [
        "# GPUs with Tensor Cores can benefit from mixed-precision training substancially\n",
        "!export TF_ENABLE_AUTO_MIXED_PRECISION=1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqgBrY57JmUh"
      },
      "source": [
        "import os, sys\n",
        "# The \"tflib\" directory is in os.environ['HOME']; the datasets are in os.environ['DATA']. The log directory will be created automatically if it does not exist.\n",
        "os.environ['HOME']=\"/content/drive/Shared drives/shared/mix-gan\" # My Drive or Shared drives\n",
        "os.environ['DATA']=\"/content/drive/Shared drives/shared/mix-gan/data\" \n",
        "os.environ['LOG']=\"/content/drive/Shared drives/shared/mix-gan/logs\" "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNfTqNF8KEFh",
        "outputId": "3188cc2a-f923-4f87-8202-779f9cbc939a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%cd /content/drive/Shared drives/shared/mix-gan/data\n",
        "# Download and extract the CIFAR-10 dataset automatically if it does not exist\n",
        "if not os.path.isfile(os.environ['DATA']+'/cifar-10-python.tar.gz'):\n",
        "  !wget www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "  !tar vxzf cifar-10-python.tar.gz\n",
        "%cd .."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/shared/mix-gan/data\n",
            "/content/drive/Shared drives/shared/mix-gan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZDHUw-pJQQP",
        "outputId": "6d88dc31-30f4-4392-c947-f6f7a9d8d1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import os, sys\n",
        "sys.path.append(os.getcwd())\n",
        "gpu_id=[0]\n",
        "DEVICES = ['/gpu:{}'.format(i) for i in range(len(gpu_id))]\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=','.join([str(i) for i in gpu_id]) #set gpu id\n",
        "import random\n",
        "import time\n",
        "\n",
        "import functools\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "import scipy.misc\n",
        "import urllib\n",
        "import tflib as lib\n",
        "import tflib.ops.linear\n",
        "import tflib.ops.conv2d\n",
        "import tflib.ops.batchnorm\n",
        "import tflib.ops.cond_batchnorm\n",
        "import tflib.ops.layernorm\n",
        "import tflib.ops.deconv2d\n",
        "import tflib.save_images\n",
        "import tflib.mnist\n",
        "import tflib.cifar10\n",
        "#import tflib.cifar100\n",
        "import tflib.imagenet64\n",
        "import tflib.imagenet128_10classes\n",
        "import tflib.imagenet128\n",
        "import tflib.small_imagenet\n",
        "#import tflib.stl\n",
        "from tflib.ada import augment\n",
        "import tflib.plot\n",
        "import tflib.inception_score\n",
        "import tflib.fid\n",
        "import errno\n",
        "#from cleverhans.attacks_tf import fgsm\n",
        "import locale\n",
        "dtype='float32'\n",
        "\n",
        "DATASET = 'CIFAR-10' #CIFAR, small_ImageNet, ImageNet64, ImageNet128_10classes, ImageNet128, STL\n",
        "\n",
        "gan_learning_rate=2e-4\n",
        "\n",
        "NUM_GENERATORS=10\n",
        "NUM_DISCRIMINATORS=10\n",
        "\n",
        "# For WGAN-GP\n",
        "BASE_DIM=8\n",
        "G_DIM = 32*BASE_DIM # Generator dimensionality\n",
        "D_DIM = 32*BASE_DIM  # Discriminator dimensionality\n",
        "\n",
        "RAND_LABELS=False\n",
        "SHARED_EMBED=1\n",
        "PL_COEFF=0\n",
        "HIER=1\n",
        "ATTENTION=0\n",
        "NUM_RESIDUAL_UNIT=1\n",
        "BOTTLENECK=0\n",
        "GET_LABELS=True\n",
        "BATCH_SIZE = 50 # Batch size, must be divisible by the dataset size if using MNIST \n",
        "GET_INCEPTION_SCORE=1\n",
        "GET_FID=1\n",
        "INCEPTION_BATCHES=int(50000/BATCH_SIZE)\n",
        "FID_BATCHES=int(50000/BATCH_SIZE)\n",
        "TRAIN_SIZE=BATCH_SIZE*1 # Define the training set size, ignored if using a realistic image dataset\n",
        "TEST_SIZE=BATCH_SIZE*1 # Define the test set size, ignored if using a realistic image dataset\n",
        "LAMBDA =0 # Smaller lambda makes things faster for toy tasks, but isn't necessary if you increase N_CRITIC enough\n",
        "R1_COEFF=0\n",
        "################################################\n",
        "GAN_LOSS=False\n",
        "HINGE_LOSS=False\n",
        "WGAN_LOSS=False\n",
        "AM_LOSS=False\n",
        "MH_LOSS=True\n",
        "assert GAN_LOSS + HINGE_LOSS + WGAN_LOSS + AM_LOSS + MH_LOSS == 1\n",
        "############################################\n",
        "#settings\n",
        "ADA=False\n",
        "ADA_TARGET=.6\n",
        "REC_NORM=2 # useless and need not be changed\n",
        "REC_COEFF=0\n",
        "ORTH_COEFF=0\n",
        "LAMBDA3=0.05\n",
        "Z_DIM=120\n",
        "\n",
        "N_GENERATOR = 1 # Generator steps per general steps\n",
        "N_CRITIC = 4 # Critic steps per general steps\n",
        "ITERS=1000000\n",
        "EMA=True\n",
        "EMA_ITER=2000\n",
        "ACCU_STATS=True\n",
        "snapshot_interval=5000\n",
        "log_interval=1000\n",
        "num_modal=3\n",
        "std=.0# noise strength in CMNIST\n",
        "\n",
        "\n",
        "LAMBDA2 = 0  # parameter LAMBDA2 for CT-GAN\n",
        "DROPOUT=1 if LAMBDA2>0 else 0\n",
        "Factor_M = 0.0  # factor M\n",
        "NORMALIZATION_G = True # Use batchnorm in generator?\n",
        "NORMALIZATION_D = False # Use batchnorm (or layernorm) in critic?\n",
        "DECAY = True # Whether to decay LR over learning\n",
        "SPECTRAL_NORMALIZATION = True\n",
        "CONDITIONAL = True  # Whether to train a conditional or unconditional model\n",
        "\n",
        "ACGAN_SCALE = 0 # How to scale the critic's ACGAN loss relative to WGAN loss\n",
        "ACGAN_SCALE_G = .0 # How to scale generator's ACGAN loss relative to WGAN loss\n",
        "ACGAN = ACGAN_SCALE!=0\n",
        "\n",
        "BETA1=0.\n",
        "BETA2=.9\n",
        "STYLEGAN=False\n",
        "STYLEGAN2=False\n",
        "if STYLEGAN or STYLEGAN2: Z_DIM=512\n",
        "if STYLEGAN2:\n",
        "    GAN_LOSS=1\n",
        "    MH_LOSS=False\n",
        "    HINGE_LOSS=False\n",
        "    WGAN_LOSS=0\n",
        "    AM_LOSS=False\n",
        "    R1_COEFF=0.01\n",
        "    RAND_LABELS=True\n",
        "    ACCU_STATS=False\n",
        "    LAMBDA3=0\n",
        "    N_CRITIC = 1\n",
        "    BATCH_SIZE=64\n",
        "    BETA2= .99\n",
        "    gan_learning_rate=2.5e-3\n",
        "    ITERS=100e6//BATCH_SIZE\n",
        "COMPUTE_GRADIENT = LAMBDA>0 or R1_COEFF>0\n",
        "locale.setlocale(locale.LC_ALL, '')\n",
        "lib.print_model_settings(locals().copy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:635: flatten (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Flatten instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:635: flatten (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Flatten instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
            "\n",
            "Uppercase local vars:\n",
            "\tACCU_STATS: True\n",
            "\tACGAN: False\n",
            "\tACGAN_SCALE: 0\n",
            "\tACGAN_SCALE_G: 0.0\n",
            "\tADA: False\n",
            "\tADA_TARGET: 0.6\n",
            "\tAM_LOSS: False\n",
            "\tATTENTION: 0\n",
            "\tBASE_DIM: 8\n",
            "\tBATCH_SIZE: 50\n",
            "\tBETA1: 0.0\n",
            "\tBETA2: 0.9\n",
            "\tBOTTLENECK: 0\n",
            "\tCOMPUTE_GRADIENT: False\n",
            "\tCONDITIONAL: True\n",
            "\tDATASET: CIFAR-10\n",
            "\tDECAY: True\n",
            "\tDEVICES: ['/gpu:0']\n",
            "\tDROPOUT: 0\n",
            "\tD_DIM: 256\n",
            "\tEMA: True\n",
            "\tEMA_ITER: 2000\n",
            "\tFID_BATCHES: 1000\n",
            "\tGAN_LOSS: False\n",
            "\tGET_FID: 1\n",
            "\tGET_INCEPTION_SCORE: 1\n",
            "\tGET_LABELS: True\n",
            "\tG_DIM: 256\n",
            "\tHIER: 1\n",
            "\tHINGE_LOSS: False\n",
            "\tINCEPTION_BATCHES: 1000\n",
            "\tITERS: 1000000\n",
            "\tLAMBDA: 0\n",
            "\tLAMBDA2: 0\n",
            "\tLAMBDA3: 0.05\n",
            "\tMH_LOSS: True\n",
            "\tNORMALIZATION_D: False\n",
            "\tNORMALIZATION_G: True\n",
            "\tNUM_DISCRIMINATORS: 10\n",
            "\tNUM_GENERATORS: 10\n",
            "\tNUM_RESIDUAL_UNIT: 1\n",
            "\tN_CRITIC: 4\n",
            "\tN_GENERATOR: 1\n",
            "\tORTH_COEFF: 0\n",
            "\tPL_COEFF: 0\n",
            "\tR1_COEFF: 0\n",
            "\tRAND_LABELS: False\n",
            "\tREC_COEFF: 0\n",
            "\tREC_NORM: 2\n",
            "\tSHARED_EMBED: 1\n",
            "\tSPECTRAL_NORMALIZATION: True\n",
            "\tSTYLEGAN: False\n",
            "\tSTYLEGAN2: False\n",
            "\tTEST_SIZE: 50\n",
            "\tTRAIN_SIZE: 50\n",
            "\tWGAN_LOSS: False\n",
            "\tZ_DIM: 120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KtwmlDJJQQV",
        "outputId": "21554680-c31e-4575-8361-37eb920dab68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axLYJLaEJQQZ"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6ggh59AJQQd"
      },
      "source": [
        "#Datasets\n",
        "IMAGE_DATASETS=['MNIST','CMNIST','CIFAR-10', 'ImageNet64', 'ImageNet128_10classes', 'ImageNet128','small_ImageNet','STL','STL32','STL48','STL64','STL128','Zap50k']\n",
        "ENCODER_MODELS=['ALI','IDGAN']\n",
        "\n",
        "assert DATASET in IMAGE_DATASETS or NETWORK_TYPE is 'FCGAN', 'Cannot use DCGAN for non-image datasets.'\n",
        "\n",
        "if DATASET=='MNIST':\n",
        "    NUM_CHANNELS=1\n",
        "    HEIGHT=WIDTH=32\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    TRAIN_SIZE=50000\n",
        "    TEST_SIZE=10000\n",
        "if DATASET=='CMNIST':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=32\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    SKETCH_DIM=HEIGHT*WIDTH\n",
        "    TRAIN_SIZE=50000\n",
        "    TEST_SIZE=10000\n",
        "if DATASET=='CIFAR-10':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=32\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    NUM_CLASSES=10\n",
        "    CODE_DIM=10\n",
        "    TRAIN_SIZE=50000\n",
        "    TEST_SIZE=10000\n",
        "    # Download CIFAR-10 (Python version) at\n",
        "    # https://www.cs.toronto.edu/~kriz/cifar.html and fill in the path to the\n",
        "    # extracted files here!\n",
        "    DATA_DIR = os.environ['DATA']+'/cifar-10-batches-py/'#directory to save the dataset\n",
        "\n",
        "if DATASET=='ImageNet64':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=64\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    NUM_CLASSES=1000\n",
        "    CODE_DIM=NUM_CLASSES\n",
        "    TRAIN_SIZE=1281167\n",
        "    TEST_SIZE=50000\n",
        "    DATA_DIR = os.environ['DATA']+'/ImageNet64/'#directory to save the dataset\n",
        "    \n",
        "if DATASET=='ImageNet128_10classes':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=128\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    NUM_CLASSES=10\n",
        "    CODE_DIM=NUM_CLASSES\n",
        "    TRAIN_SIZE=12697\n",
        "    TEST_SIZE=500\n",
        "    DATA_DIR = os.environ['DATA']+'/ImageNet128_10classes/'#directory to save the dataset\n",
        "    \n",
        "if DATASET=='ImageNet128':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=128\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    NUM_CLASSES=1000\n",
        "    CODE_DIM=NUM_CLASSES\n",
        "    TRAIN_SIZE=1281159\n",
        "    TEST_SIZE=50000\n",
        "    DATA_DIR = os.environ['DATA']+'/ImageNet128/'#directory to save the dataset\n",
        "    \n",
        "if DATASET=='small_ImageNet':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=64\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    NUM_CLASSES=1000\n",
        "    CODE_DIM=NUM_CLASSES\n",
        "    TRAIN_SIZE=1281150\n",
        "    TEST_SIZE=50000\n",
        "    # Download 64x64 small_ImageNet at http://image-net.org/small/download.php and\n",
        "    # fill in the path to the extracted files here!\n",
        "    DATA_DIR = os.environ['DATA']+'/small_ImageNet/' #directory to save the dataset\n",
        "\n",
        "if DATASET=='STL':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=96\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    NUM_CLASSES=10\n",
        "    CODE_DIM=10\n",
        "    TRAIN_SIZE=5000\n",
        "    TEST_SIZE=8000\n",
        "    # fill in the path to the extracted files here!\n",
        "    DATA_DIR = os.environ['DATA']+'/STL-10/stl10_matlab/' #directory to save the dataset\n",
        "    \n",
        "if DATASET=='STL32':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=32\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    NUM_CLASSES=10\n",
        "    CODE_DIM=10\n",
        "    TRAIN_SIZE=5000\n",
        "    TEST_SIZE=8000\n",
        "    # fill in the path to the extracted files here!\n",
        "    DATA_DIR = os.environ['DATA']+'/STL-10/stl10_matlab/' #directory to save the dataset    \n",
        "if DATASET=='STL48':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=48\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    NUM_CLASSES=10\n",
        "    CODE_DIM=10\n",
        "    TRAIN_SIZE=5000\n",
        "    TEST_SIZE=8000\n",
        "    # fill in the path to the extracted files here!\n",
        "    DATA_DIR = os.environ['DATA']+'/STL-10/stl10_matlab/' #directory to save the dataset  \n",
        "if DATASET=='STL64':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=64\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    NUM_CLASSES=10\n",
        "    CODE_DIM=10\n",
        "    TRAIN_SIZE=5000\n",
        "    TEST_SIZE=8000\n",
        "    # fill in the path to the extracted files here!\n",
        "    DATA_DIR = os.environ['DATA']+'/STL-10/stl10_matlab/' #directory to save the dataset  \n",
        "if DATASET=='STL128':\n",
        "    NUM_CHANNELS=3\n",
        "    HEIGHT=WIDTH=128\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    NUM_CLASSES=10\n",
        "    CODE_DIM=10\n",
        "    TRAIN_SIZE=5000\n",
        "    TEST_SIZE=8000\n",
        "    # fill in the path to the extracted files here!\n",
        "    DATA_DIR = os.environ['DATA']+'/STL-10/stl10_matlab/' #directory to save the dataset  \n",
        "if DATASET=='Zap50k':\n",
        "    NUM_CHANNELS=3\n",
        "    REAL_HEIGHT=102\n",
        "    REAL_WIDTH=136\n",
        "    HEIGHT=WIDTH=128\n",
        "    DATA_DIM=HEIGHT*WIDTH*NUM_CHANNELS\n",
        "    SKETCH_DIM=HEIGHT*WIDTH\n",
        "    TRAIN_SIZE=40000\n",
        "    TEST_SIZE=10025\n",
        "    DATA_DIR = os.environ['DATA']+'/ut-zap50k/ut-zap50k-images-unfolded'#directory to save the dataset\n",
        "    SKETCH_DIR =os.environ['DATA']+'/ut-zap50k/ut-zap50k-sketches-unfolded'\n",
        "\n",
        "if DATASET in IMAGE_DATASETS:\n",
        "    G_LAYERS=int(np.ceil(np.log2(HEIGHT/4)))+2\n",
        "\n",
        "# Dataset iterator\n",
        "def inf_gen(MODE='TRAIN'):\n",
        "    if DATASET == '25gaussians':\n",
        "    \n",
        "        dataset = []\n",
        "        for i in range(100000/25):\n",
        "            for x in range(-2, 3):\n",
        "                for y in range(-2, 3):\n",
        "                    point = np.random.randn(2)*0.05\n",
        "                    point[0] += 2*x\n",
        "                    point[1] += 2*y\n",
        "                    dataset.append(point)\n",
        "        dataset = np.array(dataset, dtype=dtype)\n",
        "        np.random.shuffle(dataset)\n",
        "        dataset /= 2.828 # stdev\n",
        "        while True:\n",
        "            for i in range(len(dataset)/BATCH_SIZE):\n",
        "                yield dataset[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "\n",
        "    elif DATASET == 'swissroll':\n",
        "\n",
        "        while True:\n",
        "            data = sklearn.datasets.make_swiss_roll(\n",
        "                n_samples=BATCH_SIZE, \n",
        "                ran_noise=0.25\n",
        "            )[0]\n",
        "            data = data.astype(dtype)[:, [0, 2]]\n",
        "            data /= 7.5 # stdev plus a little\n",
        "            yield data\n",
        "\n",
        "    elif DATASET == '8gaussians':\n",
        "    \n",
        "        centers = [\n",
        "            (1,0),\n",
        "            (-1,0),\n",
        "            (0,1),\n",
        "            (0,-1),\n",
        "            (1./np.sqrt(2), 1./np.sqrt(2)),\n",
        "            (1./np.sqrt(2), -1./np.sqrt(2)),\n",
        "            (-1./np.sqrt(2), 1./np.sqrt(2)),\n",
        "            (-1./np.sqrt(2), -1./np.sqrt(2))\n",
        "        ]\n",
        "        centers = [(scale*x,scale*y) for x,y in centers]\n",
        "        while True:\n",
        "            dataset = []\n",
        "            for i in range(BATCH_SIZE):\n",
        "                point = np.random.randn(2)*.02\n",
        "                center = random.choice(centers)\n",
        "                point[0] += center[0]\n",
        "                point[1] += center[1]\n",
        "                dataset.append(point)\n",
        "            dataset = np.array(dataset, dtype=dtype)\n",
        "            dataset /= 1.414 # stdev\n",
        "            yield dataset\n",
        "\n",
        "            \n",
        "    elif DATASET == 'n-gaussians':         \n",
        "        centers = []\n",
        "        for i in range(num_modal):\n",
        "            centers.append(scale*tf.one_hot(i,DATA_DIM,dtype=dtype).eval())\n",
        "                    \n",
        "        if not FIX_DATA:\n",
        "            while True:\n",
        "                dataset = []\n",
        "                points = np.random.randn(BATCH_SIZE, DATA_DIM)*std\n",
        "                #points=tf.random_normal([BATCH_SIZE, DATA_DIM])*std\n",
        "                #center_choice=np.zeros((BATCH_SIZE, DATA_DIM), dtype='float32')\n",
        "                for i in range(BATCH_SIZE):\n",
        "                    points[i][random.randint(0,num_modal-1)]+=1.\n",
        "                #dataset = np.array(points, dtype='float32')\n",
        "                #dataset /= 1.414 # stdev\n",
        "                yield points\n",
        "        else:            \n",
        "            if MODE=='TRAIN':\n",
        "                fixed_train_data=np.random.randn(TRAIN_SIZE, DATA_DIM)*std\n",
        "                for i in range(TRAIN_SIZE):\n",
        "                    fixed_train_data[i][random.randint(0,num_modal-1)]+=1.\n",
        "                while True:\n",
        "                    for i in range(fixed_train_data.shape[0]/BATCH_SIZE):\n",
        "                        yield fixed_train_data[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "                        \n",
        "            elif MODE=='TEST':\n",
        "                fixed_test_data=np.random.randn(TEST_SIZE, DATA_DIM)*std\n",
        "                for i in range(TEST_SIZE):\n",
        "                    fixed_test_data[i][random.randint(0,num_modal-1)]+=1.\n",
        "                while True:\n",
        "                    for i in range(fixed_test_data.shape[0]/BATCH_SIZE):\n",
        "                        yield fixed_test_data[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "            else:\n",
        "                raise UnsupportedDataMode\n",
        "            \n",
        "    elif DATASET == 'ball':           \n",
        "        if not FIX_DATA:\n",
        "            while True:\n",
        "                points=np.random.randn(BATCH_SIZE,DATA_DIM)\n",
        "                dataset=points/np.linalg.norm(points,axis=1,keepdims=True)*scale\n",
        "                yield dataset\n",
        "        else:              \n",
        "            if MODE=='TRAIN':\n",
        "                fixed_train_data = np.random.randn(TRAIN_SIZE,DATA_DIM)\n",
        "                fixed_train_data=fixed_train_data/np.linalg.norm(fixed_train_data,axis=1,keepdims=True)*scale\n",
        "                while True:\n",
        "                    for i in range(fixed_train_data.shape[0]/BATCH_SIZE):\n",
        "                        yield fixed_train_data[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "            elif MODE=='TEST':\n",
        "                fixed_test_data = np.random.randn(TEST_SIZE,DATA_DIM)\n",
        "                fixed_test_data=fixed_test_data/np.linalg.norm(fixed_test_data,axis=1,keepdims=True)*scale\n",
        "                while True:\n",
        "                    for i in range(fixed_test_data.shape[0]/BATCH_SIZE):\n",
        "                        yield fixed_test_data[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "            else:\n",
        "                raise UnsupportedDataMode\n",
        "    elif DATASET == 'net': \n",
        "        if not FIX_DATA:\n",
        "            while True:\n",
        "                yield session.run(real_gen_data)\n",
        "        else:              \n",
        "            if MODE=='TRAIN':\n",
        "                fixed_train_data = Real_Gen(TRAIN_SIZE, real_data).eval()\n",
        "                while True:\n",
        "                    for i in range(fixed_train_data.shape[0]/BATCH_SIZE):\n",
        "                        yield fixed_train_data[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "            elif MODE=='TEST':\n",
        "                fixed_test_data = Real_Gen(TEST_SIZE, real_data).eval()\n",
        "                while True:\n",
        "                    for i in range(fixed_test_data.shape[0]/BATCH_SIZE):\n",
        "                        yield fixed_test_data[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "            else:\n",
        "                raise UnsupportedDataMode\n",
        "    elif DATASET=='MNIST':\n",
        "        if MODE=='TRAIN':\n",
        "            train_gen, _, _ = lib.mnist.load(BATCH_SIZE, BATCH_SIZE)\n",
        "            while True:\n",
        "                for images,targets in train_gen():\n",
        "                    yield images*2-1\n",
        "        elif MODE=='TEST':\n",
        "            _, val_gen, _ = lib.mnist.load(BATCH_SIZE, BATCH_SIZE)\n",
        "            while True:\n",
        "                for images,targets in val_gen():\n",
        "                    yield images*2-1\n",
        "    elif DATASET=='CMNIST':\n",
        "        if MODE=='TRAIN':\n",
        "            train_gen, _, _ = lib.mnist.load(BATCH_SIZE, BATCH_SIZE)\n",
        "            while True:\n",
        "                for images,targets in train_gen():\n",
        "                    if DENOISE:\n",
        "                        images=np.tile(images.reshape(-1,1,HEIGHT,WIDTH),(1,3,1,1))\n",
        "                        images=(images*np.random.rand(images.shape[0],3,1,1)).reshape(-1,DATA_DIM)*2-1\n",
        "                        images+=std*np.random.randn(images.shape[0],images.shape[1])\n",
        "                        images[images>1]=1\n",
        "                        images[images<-1]=-1\n",
        "                        yield images\n",
        "                    else:\n",
        "                        images=np.tile(images.reshape(-1,1,HEIGHT,WIDTH),(1,3,1,1))\n",
        "                        yield (images*np.random.rand(images.shape[0],3,1,1)).reshape(-1,DATA_DIM)*2-1                   \n",
        "        elif MODE=='TEST':\n",
        "            _, val_gen, _ = lib.mnist.load(BATCH_SIZE, BATCH_SIZE)\n",
        "            while True:\n",
        "                for images,targets in val_gen():\n",
        "                    if DENOISE:\n",
        "                        images=np.tile(images.reshape(-1,1,HEIGHT,WIDTH),(1,3,1,1))\n",
        "                        images=(images*np.random.rand(images.shape[0],3,1,1)).reshape(-1,DATA_DIM)*2-1\n",
        "                        images+=std*np.random.randn(images.shape[0],images.shape[1])\n",
        "                        images[images>1]=1\n",
        "                        images[images<-1]=-1\n",
        "                        yield images\n",
        "                    else:\n",
        "                        images=np.tile(images.reshape(-1,1,HEIGHT,WIDTH),(1,3,1,1))\n",
        "                        yield (images*np.random.rand(images.shape[0],3,1,1)).reshape(-1,DATA_DIM)*2-1  \n",
        "    elif DATASET=='CIFAR-10':\n",
        "        if MODE=='TRAIN':\n",
        "            train_gen, _ = lib.cifar10.load(BATCH_SIZE, data_dir=DATA_DIR)\n",
        "            while True:\n",
        "                for original_images, labels in train_gen():\n",
        "                    yield 2./255*original_images-1,labels\n",
        "        elif MODE=='TEST':\n",
        "            _, test_gen = lib.cifar10.load(BATCH_SIZE, data_dir=DATA_DIR)\n",
        "            while True:\n",
        "                for original_images, labels in test_gen():\n",
        "                    yield 2./255*original_images-1,labels\n",
        "    elif DATASET=='ImageNet64':\n",
        "            gen = lib.imagenet64.load(MODE, BATCH_SIZE, data_dir=DATA_DIR)\n",
        "            while True:\n",
        "                for original_images, labels in gen():\n",
        "                    yield 2./255*original_images-1,labels\n",
        "    elif DATASET=='ImageNet128':\n",
        "            gen = lib.imagenet128.load(MODE, BATCH_SIZE, data_dir=DATA_DIR)\n",
        "            while True:\n",
        "                for original_images, labels in gen():\n",
        "                    yield 2./255*original_images-1,labels\n",
        "    elif DATASET=='ImageNet128_10classes':\n",
        "            gen = lib.imagenet128_10classes.load(MODE, BATCH_SIZE, data_dir=DATA_DIR)\n",
        "            while True:\n",
        "                for original_images, labels in gen():\n",
        "                    yield 2./255*original_images-1,labels\n",
        "    elif DATASET=='small_ImageNet':\n",
        "        if MODE=='TRAIN':\n",
        "            train_gen, _ = lib.small_imagenet.load(BATCH_SIZE, data_dir=DATA_DIR)\n",
        "            while True:\n",
        "                for images in train_gen():\n",
        "                    yield images[0].reshape((-1,DATA_DIM))*2./255-1, np.zeros([BATCH_SIZE])\n",
        "        elif MODE=='TEST':\n",
        "            _, test_gen = lib.small_imagenet.load(BATCH_SIZE, data_dir=DATA_DIR)\n",
        "            while True:\n",
        "                for images in test_gen():\n",
        "                    yield images[0].reshape((-1,DATA_DIM))*2./255-1, np.zeros([BATCH_SIZE])\n",
        "    elif 'STL' in DATASET:\n",
        "            gen = lib.stl.load(MODE, BATCH_SIZE, data_dir=DATA_DIR, size=HEIGHT)\n",
        "            while True:\n",
        "                for original_images, labels in gen():\n",
        "                    yield 2./255*original_images-1,labels\n",
        "    elif DATASET=='Zap50k':\n",
        "        perm_matrices=np.zeros((6,3,3))\n",
        "        perm_matrices[0]=np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
        "        perm_matrices[1]=np.array([[1,0,0],[0,0,1],[0,1,0]])\n",
        "        perm_matrices[2]=np.array([[0,1,0],[1,0,0],[0,0,1]])\n",
        "        perm_matrices[3]=np.array([[0,1,0],[0,0,1],[1,0,0]])\n",
        "        perm_matrices[4]=np.array([[0,0,1],[1,0,0],[0,1,0]])\n",
        "        perm_matrices[5]=np.array([[0,0,1],[0,1,0],[1,0,0]])\n",
        "        perm_matrices=perm_matrices.reshape(6,-1)\n",
        "        if MODE=='TRAIN':\n",
        "            perm=np.arange(TRAIN_SIZE)\n",
        "            while True:\n",
        "                np.random.shuffle(perm)\n",
        "                for i in range(TRAIN_SIZE/BATCH_SIZE):\n",
        "                    train_images,train_sketches=\\\n",
        "                    lib.ut_zap50k.load('TRAIN', DATA_DIR, SKETCH_DIR,[perm[j+i*BATCH_SIZE] for j in range(BATCH_SIZE)])                  \n",
        "                    if PERMUTE_COLORS:\n",
        "                        for j in range(BATCH_SIZE):\n",
        "                            coeffs=np.zeros(COLOR_DIM)\n",
        "                            coeffs[0]=np.random.rand()\n",
        "                            for i in range(COLOR_DIM-1):\n",
        "                                coeffs[i+1]=np.random.rand()*(1-np.sum(coeffs[:(i+1)]))\n",
        "                            coeffs/=np.sum(coeffs)\n",
        "                            np.random.shuffle(perm_matrices)\n",
        "                            ds=np.matmul(coeffs,perm_matrices[:COLOR_DIM]).reshape(3,3)\n",
        "                            train_images[j]=np.matmul(ds,train_images[j].reshape(3,-1)).reshape(3,train_images[j].shape[1],train_images[j].shape[2])    \n",
        "                    yield train_images.reshape((-1,DATA_DIM))*2./255-1\n",
        "        elif MODE=='TEST':\n",
        "            perm=np.arange(TEST_SIZE)\n",
        "            while True:\n",
        "                np.random.shuffle(perm)\n",
        "                for i in range(TEST_SIZE/BATCH_SIZE):\n",
        "                    test_images,test_sketches=\\\n",
        "                    lib.ut_zap50k.load('TEST', DATA_DIR, SKETCH_DIR,[perm[j+i*BATCH_SIZE] for j in range(BATCH_SIZE)])\n",
        "                    yield test_images.reshape((-1,DATA_DIM))*2./255-1\n",
        "                    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik1b9fotdQWh"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZWjirtyJQQg"
      },
      "source": [
        "if not RAND_LABELS:\n",
        "    assert BATCH_SIZE % NUM_CLASSES==0\n",
        "assert NUM_GENERATORS % len(gpu_id)==0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87hbTsltJQQj",
        "outputId": "7124d579-19bb-4810-e12e-5e2314d131c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "config=tf.ConfigProto(log_device_placement=True,allow_soft_placement=True)\n",
        "config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
        "from tensorflow.core.protobuf import rewriter_config_pb2\n",
        "config.graph_options.rewrite_options.auto_mixed_precision = rewriter_config_pb2.RewriterConfig.ON\n",
        "session=tf.Session(config=config)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTCQY6i1JQQm"
      },
      "source": [
        "#Placeholders\n",
        "with tf.device('/cpu:0'):\n",
        "    real_data = tf.placeholder(dtype, shape=[None, DATA_DIM],name='real_data')\n",
        "    rec_real_data=adv_x=real_data\n",
        "    real_labels = tf.placeholder(tf.int32, shape=[None],name='real_labels')\n",
        "    real_code = tf.one_hot(real_labels,NUM_CLASSES,dtype=dtype)\n",
        "\n",
        "    lr = tf.placeholder(\n",
        "           dtype, [],\n",
        "            name='lr'\n",
        "        )\n",
        "    curr_iter=tf.placeholder(\n",
        "           tf.int32, [],\n",
        "            name='curr_iter'\n",
        "        )\n",
        "    update_p=tf.placeholder(\n",
        "           tf.bool, [],\n",
        "            name='update_p'\n",
        "        )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMKg2ghyJQQr"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuJQTVfXJQQu"
      },
      "source": [
        "#Utilities\n",
        "def mkdir_p(path):\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError as exc:  # Python >2.5\n",
        "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
        "            pass\n",
        "        else:\n",
        "            raise\n",
        "# where to load the snapshot, if you need to specify it, comment its subsequent line: #log_dir=''\n",
        "load_dir='/mnt/Data/logs/test'\n",
        "load_dir=''\n",
        "log_dir=os.environ['LOG']+'/MIX-MHingeGAN-%iG%iD-CIFAR-10-conditional-%s/'\\\n",
        "%(NUM_GENERATORS, NUM_DISCRIMINATORS, DATASET)\n",
        "if load_dir=='':\n",
        "    load_dir=log_dir\n",
        "    \n",
        "\n",
        "mkdir_p(log_dir)\n",
        "snapshot_dir = os.path.join(log_dir,\"summaries/\")#where to save\n",
        "mkdir_p(snapshot_dir)\n",
        "load_snapshot_dir=os.path.join(load_dir,\"summaries/\")\n",
        "if len([file for file in os.listdir(load_snapshot_dir) if 'ckpt' in file])>0:\n",
        "    g_snapshot_path=os.path.join(load_snapshot_dir, [file for file in os.listdir(load_snapshot_dir) if '_G.ckpt' in file][-1]).split('.ckpt')[0]+'.ckpt'#where to load\n",
        "    d_snapshot_path=g_snapshot_path.replace('_G', '_D')\n",
        "else:\n",
        "    g_snapshot_path=''\n",
        "\n",
        "log_vars=[]\n",
        "def define_summaries():\n",
        "        [g_sum,d_sum,hist_sum,j_sum_train,w_sum_train,j_sum_test,w_sum_test]=[_,_,_,_,_,_,_]\n",
        "        '''Helper function for init_opt'''\n",
        "        all_sum = {'G': [], 'D': [], 'hist': [], 'J_train': [], 'W_train': [], 'J_test': [], 'W_test': []}\n",
        "        for k, v in log_vars:\n",
        "            if k.startswith('G'):\n",
        "                all_sum['G'].append(tf.summary.scalar(k, v))\n",
        "            elif k.startswith('D'):\n",
        "                all_sum['D'].append(tf.summary.scalar(k, v))\n",
        "            elif k.startswith('hist'):\n",
        "                all_sum['hist'].append(tf.summary.histogram(k, v))\n",
        "        if len(all_sum['G'])>0:\n",
        "            g_sum = tf.summary.merge(all_sum['G'])\n",
        "        if len(all_sum['D'])>0:\n",
        "            d_sum = tf.summary.merge(all_sum['D'])\n",
        "        if len(all_sum['hist'])>0:\n",
        "            hist_sum = tf.summary.merge(all_sum['hist'])\n",
        "\n",
        "        return [g_sum,d_sum,hist_sum]\n",
        "\n",
        "\n",
        "def random_pick(some_list, probabilities):  \n",
        "    x = random.uniform(0,1)  \n",
        "    cumulative_probability = 0.0  \n",
        "    for item, item_probability in zip(some_list, probabilities):  \n",
        "        cumulative_probability += item_probability  \n",
        "        if x < cumulative_probability:break  \n",
        "    return item  \n",
        "\n",
        "\n",
        "\n",
        "def label2onehot(labels,num_classes=NUM_CLASSES):\n",
        "    labels=labels.astype(int)\n",
        "    one_hots=np.zeros((len(labels),num_classes))\n",
        "    for i in range(len(labels)):\n",
        "        one_hots[i][labels[i]]=1\n",
        "    return one_hots\n",
        "\n",
        "# For calculating inception score\n",
        "\n",
        "def get_inception_score(n, splits=10):\n",
        "    BATCH_SIZE=int(fake_sample.shape[0])\n",
        "    all_samples = np.zeros([int(np.ceil(float(n)/BATCH_SIZE)*BATCH_SIZE),DATA_DIM],dtype=np.uint8)\n",
        "    if not GET_INCEPTION_SCORE:\n",
        "        return 0,0\n",
        "    labels=np.arange(n)%NUM_CLASSES\n",
        "    for i in range(int(np.ceil(float(n)/BATCH_SIZE))):# inception score for num_batches of fake data\n",
        "        all_samples[i*BATCH_SIZE:(i+1)*BATCH_SIZE]=((\\\n",
        "        session.run(fake_sample,\\\n",
        "        feed_dict={\\\n",
        "        real_labels:labels[i*BATCH_SIZE:(i+1)*BATCH_SIZE].astype(int),\n",
        "        real_code:label2onehot(labels[i*BATCH_SIZE:(i+1)*BATCH_SIZE]),})\\\n",
        "        +1)/2*255).astype(np.uint8)\n",
        "        #all_samples[i*BATCH_SIZE:(i+1)*BATCH_SIZE]=((next(train_gen)[0]+1)/2*255).astype(np.uint8) # IS on real data\n",
        "    return lib.inception_score.get_inception_score(all_samples[:n].reshape([-1,HEIGHT,WIDTH,3]).transpose([0,3,1,2]), splits)\n",
        "def get_fid(n,gen):\n",
        "    if not GET_FID:\n",
        "        return 0\n",
        "    labels=np.arange(n)%NUM_CLASSES\n",
        "    BATCH_SIZE=fake_sample.shape[0]\n",
        "    all_fake_samples = np.zeros([n//BATCH_SIZE*BATCH_SIZE,DATA_DIM],dtype=np.uint8)\n",
        "    for i in range(n//BATCH_SIZE):#\n",
        "        all_fake_samples[i*BATCH_SIZE:(i+1)*BATCH_SIZE]=((session.run(fake_sample,\\\n",
        "        feed_dict={\\\n",
        "        real_labels:labels[i*BATCH_SIZE:(i+1)*BATCH_SIZE].astype(int),\n",
        "        real_code:label2onehot(labels[i*BATCH_SIZE:(i+1)*BATCH_SIZE]),\\\n",
        "        })+1)/2*255).astype(np.uint8)\n",
        "    BATCH_SIZE=next(gen)[0].shape[0]\n",
        "    all_real_samples = np.zeros([n//BATCH_SIZE*BATCH_SIZE,DATA_DIM],dtype=np.uint8)\n",
        "    for i in range(n//BATCH_SIZE):# inception score for num_batches of fake data\n",
        "        all_real_samples[i*BATCH_SIZE:(i+1)*BATCH_SIZE]=((next(gen)[0]+1)/2*255).astype(np.uint8) # range: [0, 255], stored as int8 to save memory\n",
        "    sample_size=min(all_fake_samples.shape[0],all_real_samples.shape[0])\n",
        "    return lib.fid.get_fid(all_real_samples[:sample_size].reshape([-1,HEIGHT,WIDTH,3]).transpose([0,3,1,2]),all_fake_samples[:sample_size].reshape([-1,HEIGHT,WIDTH,3]).transpose([0,3,1,2]))\n",
        "\n",
        "def generate_image(plot_number):\n",
        "        num_images=100 #save 100 images any no matter how big BATCH_SIZE is\n",
        "        num_batches=int(np.ceil(100./BATCH_SIZE)) # number of iterations needed to get 100 images\n",
        "        total_images=num_batches*BATCH_SIZE #might be 128\n",
        "        _labels=np.arange(total_images)//10\n",
        "        _labels[num_images:]=0\n",
        "\n",
        "        _all_samples=[]\n",
        "        _real_data=[]\n",
        "        _rec_real_data=[]\n",
        "        for i in np.arange(num_batches):\n",
        "            real_data_batch,real_code_batch=next(train_gen)\n",
        "            _real_data_batch=session.run(\n",
        "            real_data,\n",
        "            feed_dict={\n",
        "            real_data:real_data_batch\n",
        "            })\n",
        "            #_rec_real_data.append(_rec_real_data_batch)\n",
        "            _real_data.append(_real_data_batch)\n",
        "        for i in np.arange(np.ceil(100./int(fake_sample.shape[0]))):\n",
        "            _samples_batch=session.run(\n",
        "            fake_sample,\n",
        "            feed_dict={})\n",
        "            _all_samples.append(_samples_batch) \n",
        "        _all_samples=np.concatenate(_all_samples)[:100]/2+.5\n",
        "        _real_data=np.concatenate(_real_data)[:100]/2+.5\n",
        "        #_rec_real_data=np.concatenate(_rec_real_data)[:100]/2+.5\n",
        "        \n",
        "        lib.save_images.save_images(\n",
        "        _all_samples.reshape((num_images, HEIGHT, WIDTH, NUM_CHANNELS)), \n",
        "        log_dir+DATASET+'_SAMPLE_'+str(plot_number)+'_all.jpg')\n",
        "        if plot_number % (100000) == 0:\n",
        "            lib.save_images.show_images(_all_samples.reshape((num_images, HEIGHT, WIDTH, NUM_CHANNELS)))\n",
        "        lib.save_images.save_images(\n",
        "        _real_data.reshape((num_images, HEIGHT, WIDTH, NUM_CHANNELS)), \n",
        "        log_dir+DATASET+'_REAL_'+str(plot_number)+'.jpg')\n",
        "        \n",
        "        samples={}\n",
        "        for i in range(NUM_GENERATORS):\n",
        "            samples[i]=[]\n",
        "            for k in range(num_batches):\n",
        "                samples[i].append(session.run(all_fake_sample[i%NUM_GENERATORS]))    \n",
        "            samples[i]=np.concatenate(samples[i])[:100]/2+.5\n",
        "            lib.save_images.save_images(\n",
        "            samples[i].reshape((num_images, HEIGHT, WIDTH, NUM_CHANNELS)), \n",
        "            log_dir+DATASET+'_SAMPLE_'+str(plot_number)+'-'+str(i)+'.jpg')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANsB5FzjJQQw"
      },
      "source": [
        "def pixelwise_norm(x, epsilon=1e-8):\n",
        "    return x * tf.rsqrt(tf.reduce_mean(tf.square(x), axis=-1, keepdims=True) + epsilon)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JysTUDB-JQQ0",
        "outputId": "96d905bd-bff4-4269-fb38-04abb1fdaac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Layers and networks definitions\n",
        "\n",
        "if CONDITIONAL and (not ACGAN) and (not NORMALIZATION_D):\n",
        "    print (\"WARNING! Conditional model without normalization in D might be effectively unconditional!\")\n",
        "\n",
        "def nonlinearity(x):\n",
        "    return tf.nn.relu(x)\n",
        "    #return tf.nn.relu6(x)\n",
        "    return tf.nn.leaky_relu(x)\n",
        "def dropout(x, keep_prob):\n",
        "    if DROPOUT:\n",
        "        return tf.nn.dropout(x, keep_prob=keep_prob)\n",
        "    else:\n",
        "        return x\n",
        "def ReLULayer(name, n_in, n_out, inputs):\n",
        "    output = lib.ops.linear.Linear(\n",
        "        name+'.Linear',\n",
        "        n_in,\n",
        "        n_out,\n",
        "        inputs,\n",
        "        initialization='he'\n",
        "    )\n",
        "    output = nonlinearity(output)\n",
        "    return output\n",
        "\n",
        "def Normalize(name, inputs,labels=None, is_training=None):\n",
        "    \"\"\"This is messy, but basically it chooses between batchnorm, layernorm, \n",
        "    their conditional variants, or nothing, depending on the value of `name` and\n",
        "    the global hyperparam flags.\"\"\"\n",
        "    if not CONDITIONAL:\n",
        "        labels = None\n",
        "    if CONDITIONAL and ACGAN and ('Discriminator' in name):\n",
        "        labels = None\n",
        "\n",
        "    if ('Discriminator' in name) and NORMALIZATION_D:\n",
        "        return lib.ops.batchnorm.Batchnorm(name,[0,1,2],inputs,fused=True)\n",
        "        return lib.ops.layernorm.Layernorm(name,[1,2,3],inputs,labels=labels,n_labels=10)\n",
        "    elif ('Generator' in name) and NORMALIZATION_G:\n",
        "        if labels is not None and NUM_GENERATORS < NUM_CLASSES:\n",
        "            return class_condition_batch_norm(name, inputs, labels=labels, is_training=is_training, center=True, scale=True, use_bias=False)\n",
        "            return condition_batch_norm(name, inputs, tf.one_hot(labels, NUM_CLASSES), is_training=is_training, center=True, scale=True, use_bias=False)\n",
        "            return lib.ops.cond_batchnorm.Batchnorm(name,[0,1,2],inputs,labels=labels,n_labels=10)\n",
        "        else:\n",
        "            return batch_norm(name, inputs, is_training=is_training)\n",
        "            return lib.ops.batchnorm.Batchnorm(name,[0,1,2],inputs,fused=True, is_training=True)\n",
        "    else:\n",
        "        return inputs\n",
        "\n",
        "def separable_conv2d(name, input_dim, output_dim, filter_size, inputs, stride=1, labels=None,he_init=True, biases=False):\n",
        "    name=name+'.separable'\n",
        "    #assert(filter_size==3)\n",
        "    output = lib.ops.conv2d.Conv2D(name+'.depthwise',input_dim, input_dim, 3, inputs, depthwise=True, stride=stride,he_init=he_init,biases=biases)\n",
        "    output = Normalize(name+'.BN',output, labels=labels)\n",
        "    output = nonlinearity(output)\n",
        "    output = lib.ops.conv2d.Conv2D(name+'.pointwise', input_dim, output_dim, 1, output,he_init=he_init,biases=biases)  \n",
        "    return output\n",
        "\n",
        "conv2d=functools.partial(lib.ops.conv2d.Conv2D, spectralnorm=SPECTRAL_NORMALIZATION)\n",
        "linear=functools.partial(lib.ops.linear.Linear, spectralnorm=SPECTRAL_NORMALIZATION)\n",
        "\n",
        "def SubpixelConv2D(*args, **kwargs):\n",
        "    kwargs['output_dim'] = 4*kwargs['output_dim']\n",
        "    output = conv2d(*args, **kwargs)\n",
        "    #output = tf.transpose(output, [0,2,3,1])\n",
        "    output = tf.depth_to_space(output, 2, data_format='NHWC')\n",
        "    #output = tf.transpose(output, [0,3,1,2])\n",
        "    return output\n",
        "\n",
        "def BottleneckResidualBlock(name, input_dim, output_dim, filter_size, inputs, resample=None, he_init=True, labels=None):\n",
        "    \"\"\"\n",
        "    resample: None, 'down', or 'up'\n",
        "    \"\"\"\n",
        "    if resample=='down':\n",
        "        conv_shortcut = functools.partial(conv2d, stride=2)\n",
        "        conv_1        = functools.partial(conv2d, input_dim=input_dim, output_dim=input_dim/2)\n",
        "        conv_1b       = functools.partial(conv2d, input_dim=input_dim/2, output_dim=output_dim/2, stride=2)\n",
        "        conv_2        = functools.partial(conv2d, input_dim=output_dim/2, output_dim=output_dim)\n",
        "    elif resample=='up':\n",
        "        conv_shortcut = SubpixelConv2D\n",
        "        conv_1        = functools.partial(conv2d, input_dim=input_dim, output_dim=input_dim/2)\n",
        "        conv_1b       = functools.partial(lib.ops.deconv2d.Deconv2D, input_dim=input_dim/2, output_dim=output_dim/2)\n",
        "        conv_2        = functools.partial(conv2d, input_dim=output_dim/2, output_dim=output_dim)\n",
        "    elif resample==None:\n",
        "        conv_shortcut = conv2d\n",
        "        conv_1        = functools.partial(conv2d, input_dim=input_dim,  output_dim=input_dim/2)\n",
        "        conv_1b       = functools.partial(conv2d, input_dim=input_dim/2,  output_dim=output_dim/2)\n",
        "        conv_2        = functools.partial(conv2d, input_dim=input_dim/2, output_dim=output_dim)\n",
        "    else:\n",
        "        raise Exception('invalid resample value')\n",
        "\n",
        "    if output_dim==input_dim and resample==None:\n",
        "        shortcut = inputs # Identity skip-connection\n",
        "    else:\n",
        "        shortcut = conv_shortcut(name+'.Shortcut', input_dim=input_dim, output_dim=output_dim, filter_size=1,\n",
        "                                 he_init=False, biases=True, inputs=inputs,labels=labels)\n",
        "    output = inputs\n",
        "    output = nonlinearity(output)\n",
        "    output = conv_1(name+'.Conv1', filter_size=1, inputs=output, he_init=he_init,labels=labels)\n",
        "    output = nonlinearity(output)\n",
        "    output = conv_1b(name+'.Conv1B', filter_size=filter_size, inputs=output, he_init=he_init,labels=labels)\n",
        "    output = nonlinearity(output)\n",
        "    output = conv_2(name+'.Conv2', filter_size=1, inputs=output, he_init=he_init, biases=False,labels=labels)\n",
        "    output = Normalize(name+'.BN', [0,2,3], output)\n",
        "    return shortcut + (0.3*output)\n",
        "\n",
        "def ConvMeanPool(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
        "    output = conv2d(name, input_dim, output_dim, filter_size, inputs, he_init=he_init, biases=biases)\n",
        "    output = tf.add_n([output[:,::2,::2,:], output[:,1::2,::2,:], output[:,::2,1::2,:], output[:,1::2,1::2,:]]) / 4.\n",
        "    return output\n",
        "\n",
        "def MeanPoolConv(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
        "    output = inputs\n",
        "    output = tf.add_n([output[:,::2,::2,:], output[:,1::2,::2,:], output[:,::2,1::2,:], output[:,1::2,1::2,:]]) / 4.\n",
        "    output = conv2d(name, input_dim, output_dim, filter_size, output, he_init=he_init, biases=biases)\n",
        "    return output\n",
        "\n",
        "def UpsampleConv(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
        "    output = inputs\n",
        "    #output = tf.concat([output, output, output, output], axis=1)\n",
        "    #output = tf.transpose(output, [0,2,3,1])\n",
        "    #print(output)\n",
        "    output = tf.image.resize_nearest_neighbor(output, [2*int(output.shape[1]), 2*int(output.shape[2])])\n",
        "    #output = tf.image.resize_bilinear(output, [2*int(output.shape[1]), 2*int(output.shape[2])])\n",
        "    #print(output)\n",
        "    #output = tf.depth_to_space(output, 2)\n",
        "    #output = tf.transpose(output, [0,3,1,2])\n",
        "    output = conv2d(name, input_dim, output_dim, filter_size, output, he_init=he_init, biases=biases)\n",
        "    return output\n",
        "\n",
        "def ResidualBlock(name, input_dim, output_dim, filter_size, inputs, resample=None, no_dropout=False, labels=None, is_training=None, wide=True):\n",
        "    \"\"\"\n",
        "    resample: None, 'down', or 'up'\n",
        "    \"\"\"\n",
        "    if resample=='down':\n",
        "        conv_1        = functools.partial(conv2d, input_dim=input_dim, output_dim=output_dim if wide else input_dim)\n",
        "        conv_2        = functools.partial(ConvMeanPool, input_dim=output_dim if wide else input_dim, output_dim=output_dim)\n",
        "        conv_shortcut = ConvMeanPool\n",
        "    elif resample=='up':\n",
        "        conv_1        = functools.partial(UpsampleConv, input_dim=input_dim, output_dim=output_dim)\n",
        "        conv_shortcut = UpsampleConv\n",
        "        conv_2        = functools.partial(conv2d, input_dim=output_dim, output_dim=output_dim)\n",
        "    elif resample==None:\n",
        "        conv_shortcut =conv2d\n",
        "        conv_1        = functools.partial(conv2d, input_dim=input_dim, output_dim=output_dim)\n",
        "        conv_2        = functools.partial(conv2d, input_dim=output_dim, output_dim=output_dim)\n",
        "    else:\n",
        "        raise Exception('invalid resample value')\n",
        "\n",
        "    if output_dim==input_dim and resample==None:\n",
        "        shortcut = inputs # Identity skip-connection\n",
        "    else:\n",
        "        shortcut = conv_shortcut(name+'.Shortcut', input_dim=input_dim, output_dim=output_dim, filter_size=1, he_init=False, biases=True, inputs=inputs)\n",
        "\n",
        "    output = inputs\n",
        "    output = Normalize(name+'.N1', output, labels=labels, is_training=is_training)\n",
        "    output = nonlinearity(output)\n",
        "    if 'tGenerator' in name:\n",
        "        output=pixelwise_norm(output)\n",
        "    output = conv_1(name+'.Conv1', filter_size=filter_size, inputs=output)    \n",
        "    output = Normalize(name+'.N2', output, labels=labels, is_training=is_training)\n",
        "    output = nonlinearity(output)  \n",
        "    if 'tGenerator' in name:\n",
        "        output=pixelwise_norm(output)\n",
        "    output = conv_2(name+'.Conv2', filter_size=filter_size, inputs=output)\n",
        "\n",
        "    return shortcut + output\n",
        "\n",
        "def OptimizedResBlockDisc1(name, inputs):\n",
        "    conv_1        = functools.partial(conv2d, input_dim=3, output_dim=D_DIM)\n",
        "    conv_2        = functools.partial(ConvMeanPool, input_dim=D_DIM, output_dim=D_DIM)\n",
        "    conv_shortcut = MeanPoolConv\n",
        "    shortcut = conv_shortcut(name+'.1.Shortcut', input_dim=3, output_dim=D_DIM, filter_size=1, he_init=False, biases=True, inputs=inputs)\n",
        "\n",
        "    output = inputs\n",
        "    output = conv_1(name+'.1.Conv1', filter_size=3, inputs=output)    \n",
        "    output = nonlinearity(output)            \n",
        "    output = conv_2(name+'.1.Conv2', filter_size=3, inputs=output)\n",
        "    return shortcut + output\n",
        "\n",
        "def _Generator(ID, noise, n_samples, labels=None, ema=False, is_training=True):\n",
        "    name= 'Generator'+'.%i'%ID if not ema else 'Generator_ema'+'.%i'%ID\n",
        "    if noise is None:\n",
        "        noise = tf.random_normal([BATCH_SIZE, Z_DIM],dtype=dtype)\n",
        "    if labels is not None:\n",
        "        assert noise.shape[0]==labels.shape[0], (noise.shape[0],labels.shape[0])\n",
        "    output = linear(name+'.Input', Z_DIM, 4**2*G_DIM, noise, biases=False)\n",
        "    output = tf.reshape(output, [-1, 4, 4, G_DIM])\n",
        "    output = ResidualBlock(name+'.1', G_DIM, G_DIM, 3, output, resample='up', labels=labels, is_training=is_training)\n",
        "    output = ResidualBlock(name+'.2', G_DIM, G_DIM, 3, output, resample='up', labels=labels, is_training=is_training)\n",
        "    output = ResidualBlock(name+'.3', G_DIM, G_DIM, 3, output, resample='up', labels=labels, is_training=is_training)\n",
        "    #output = ResidualBlock(name+'.3', G_DIM, G_DIM, 3, output, resample='up', labels=labels, is_training=is_training)\n",
        "    output = batch_norm(name+'.last_bn',output,is_training=is_training)\n",
        "    output = nonlinearity(output)\n",
        "    output = conv2d(name+'.Output', G_DIM, 3, 3, output, stride=1)\n",
        "    output = tf.tanh(output)\n",
        "    return tf.reshape(output, [-1, DATA_DIM])\n",
        "\n",
        "def MobilenetDiscriminator(\\\n",
        "    ID, inputs, labels,kp1,kp2,kp3, D_DIM=D_DIM, OUT_DIM=1,\\\n",
        "    code=None, NUM_CHANNELS=3, HEIGHT=HEIGHT, WIDTH=WIDTH): #allow code as condition\n",
        "    name='Discriminator%i'%ID\n",
        "    output=tf.reshape(inputs, [-1, 3, HEIGHT, WIDTH]) \n",
        "    output = OptimizedResBlockDisc1(output,ID)\n",
        "    print(output)\n",
        "    D_LAYERS=int(np.ceil(np.log2(HEIGHT/4)))+2  \n",
        "    for i in range(2):# e.g., [32, 16, 8] for CIFAR-10\n",
        "        scale=HEIGHT//2**(i+1)\n",
        "        output=conv2d(name+'.%i'%scale,2**i*D_DIM, 2*2**i*D_DIM, 3, output, stride=2)\n",
        "        output = Normalize(name+'.%i.BN'%scale,output)\n",
        "        output = nonlinearity(output)\n",
        "        for k in range(5 if i==1 else 1):\n",
        "            output = conv2d(name+'.%i.%i'% (scale,k), 2*2**i*D_DIM, 2*2**i*D_DIM, 3, output)\n",
        "            output = Normalize(name+'.%i.%i.BN'%(scale,k),output)\n",
        "            output = nonlinearity(output)\n",
        "    print('before pooling:', output)\n",
        "    output2 = tf.reduce_mean(output, axis=[2,3])  #corresponding to D_\n",
        "    output_wgan = lib.ops.linear.Linear('Discriminator%i.Output'%ID, 2*2**i*D_DIM, 1, output2)\n",
        "    output_wgan = tf.reshape(output_wgan, [-1])    #conrresponding to D\n",
        "    if CONDITIONAL and ACGAN:\n",
        "        output_acgan = lib.ops.linear.Linear('Discriminator%i.ACGANOutput'%ID, 2*2**i*D_DIM, NUM_CLASSES, output2)\n",
        "        return output_wgan, output2, output_acgan\n",
        "    else:\n",
        "        return output_wgan, output2, None  # two layers' of output\n",
        "\n",
        "def MobilenetV1( # untested\n",
        "    ID, inputs, labels,kp1,kp2,kp3, D_DIM=D_DIM, OUT_DIM=1,\\\n",
        "    code=None, NUM_CHANNELS=3, HEIGHT=HEIGHT, WIDTH=WIDTH): #allow code as condition\n",
        "    name='Discriminator%i'%ID\n",
        "    output=tf.reshape(inputs, [BATCH_SIZE, 3, HEIGHT, WIDTH]) \n",
        "    output = OptimizedResBlockDisc1(output,ID)\n",
        "    output = Normalize(name+'.In',output)\n",
        "    output = nonlinearity(output)\n",
        "\n",
        "    D_LAYERS=int(np.ceil(np.log2(HEIGHT/4)))+2  \n",
        "    for i in range(1):# e.g., [32, 16, 8] for CIFAR-10\n",
        "        scale=HEIGHT//2**(i)\n",
        "        output=conv2d(name+'.%i'%scale,D_DIM, D_DIM, 3, output, stride=2)\n",
        "        output = Normalize(name+'.%i.BN'%scale,output)\n",
        "        output = nonlinearity(output)\n",
        "        for k in range(5 if i==0 else 1):\n",
        "            output = conv2d(name+'.%i.%i'% (scale,k), D_DIM, D_DIM, 3, output)\n",
        "            output = Normalize(name+'.%i.%i.BN'%(scale,k),output)\n",
        "            output = nonlinearity(output)\n",
        "    print('before pooling:', output)\n",
        "    output2 = tf.reduce_mean(output, axis=[2,3])  #corresponding to D_\n",
        "    output_wgan = lib.ops.linear.Linear('Discriminator%i.Output'%ID, D_DIM, 1, output2)\n",
        "    output_wgan = tf.reshape(output_wgan, [-1])    #conrresponding to D\n",
        "    if CONDITIONAL and ACGAN:\n",
        "        output_acgan = lib.ops.linear.Linear('Discriminator%i.ACGANOutput'%ID, D_DIM, NUM_CLASSES, output2)\n",
        "        return output_wgan, output2, output_acgan\n",
        "    else:\n",
        "        return output_wgan, output2, None  # two layers' of output\n",
        "    \n",
        "def V2Block(name, input_dim, output_dim, filter_size, inputs, resample=None, relu=False, labels=None, t=6):\n",
        "    \"\"\"\n",
        "    resample: None, 'down', or 'up'\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    resample: None, 'down', or 'up'\n",
        "    \"\"\"\n",
        "    if resample=='down':\n",
        "        conv_1        = functools.partial(conv2d, input_dim=input_dim, output_dim=t*input_dim, stride=1)\n",
        "        conv_2_3        = functools.partial(separable_conv2d, input_dim=t*input_dim, output_dim=output_dim, stride=2)\n",
        "    elif resample==None:\n",
        "        conv_1        = functools.partial(conv2d, input_dim=input_dim, output_dim=t*input_dim, stride=1)\n",
        "        conv_2_3     = functools.partial(separable_conv2d, input_dim=t*input_dim, output_dim=output_dim, stride=1)\n",
        "    else:\n",
        "        raise Exception('invalid resample value')\n",
        "\n",
        "    if resample==None and output_dim==input_dim:\n",
        "        shortcut = inputs # Identity skip-connection\n",
        "    else:\n",
        "        shortcut = None\n",
        "\n",
        "    output = inputs\n",
        "    output = Normalize(name+'.N1', output, labels=labels)\n",
        "    if relu:\n",
        "        output = nonlinearity(output)\n",
        "    output = conv_1(name+'.expand', filter_size=1, inputs=output,labels=labels,he_init=True, biases=False)    \n",
        "    output = Normalize(name+'.N2', output, labels=labels)\n",
        "    output = nonlinearity(output)            \n",
        "    output = conv_2_3(name+'.dwise_n_linear', filter_size=filter_size, inputs=output,labels=labels)\n",
        "    if shortcut is None:\n",
        "        return output\n",
        "    else:\n",
        "        return output + shortcut\n",
        "\n",
        "def V2Blocks_Xn(name, input_dim, output_dim, filter_size, inputs, resample=None, relu=False, labels=None, t=6 ,n=1):\n",
        "    output=inputs\n",
        "    for k in range(n-1):\n",
        "        output= V2Block(name+'.Blk.%i'%k, input_dim, input_dim, filter_size, output, None, False, labels, t)\n",
        "    output=V2Block(name+'.Blk.last', input_dim, output_dim, filter_size, output, resample, relu, labels, t) #rulu only after first conv\n",
        "    return output\n",
        "\n",
        "def MobilenetV2(\\\n",
        "    ID, inputs, labels,kp1,kp2,kp3, D_DIM=D_DIM, OUT_DIM=1,\\\n",
        "    code=None, NUM_CHANNELS=3, HEIGHT=HEIGHT, WIDTH=WIDTH): #allow code as condition\n",
        "    name='Discriminator%i'%ID\n",
        "    output=tf.reshape(inputs, [BATCH_SIZE, 3, HEIGHT, WIDTH]) \n",
        "    print('input:',output)\n",
        "    output = lib.ops.conv2d.Conv2D(name+'.In', 3, D_DIM, 3, output, he_init=False, stride=1)\n",
        "\n",
        "    output = V2Blocks_Xn(name+'.112.1', D_DIM, D_DIM//2, 3, output, resample=None, relu=True, labels=None, t=1, n=1)\n",
        "    output = V2Blocks_Xn(name+'.112.2', D_DIM//2, D_DIM//4*3, 3, output, resample='down', labels=None, t=6, n=2)\n",
        "    output = V2Blocks_Xn(name+'.56', D_DIM//4*3, D_DIM, 3, output, resample='down', labels=None, t=6, n=3)\n",
        "    output = V2Blocks_Xn(name+'.28', D_DIM, 2*D_DIM, 3, output, resample='down', labels=None, t=6, n=4)\n",
        "    output = V2Blocks_Xn(name+'.14.1', 2*D_DIM, 3*D_DIM, 3, output, resample=None, labels=None, t=6, n=3)\n",
        "    output = V2Blocks_Xn(name+'.14.2', 3*D_DIM, 5*D_DIM, 3, output, resample='down', labels=None, t=6, n=3)\n",
        "    output = V2Blocks_Xn(name+'.7.1', 5*D_DIM, 10*D_DIM, 3, output, resample=None, labels=None, t=6, n=1)\n",
        "    output = Normalize(name+'.before_last_conv',output)\n",
        "    output = lib.ops.conv2d.Conv2D(name+'.7.2', 10*D_DIM, 40*D_DIM, 1, output, he_init=True, biases=False, stride=1)\n",
        "    output = Normalize(name+'.before_last_pool',output)\n",
        "    output = nonlinearity(output)\n",
        "    print('before pooling:', output)\n",
        "    output2 = tf.reduce_mean(output, axis=[2,3])  #corresponding to D_\n",
        "    output_wgan = lib.ops.linear.Linear('Discriminator%i.Output'%ID, 1280, 1, output2)\n",
        "    output_wgan = tf.reshape(output_wgan, [-1])    #conrresponding to D\n",
        "    if CONDITIONAL and ACGAN:\n",
        "        output_acgan = lib.ops.linear.Linear('Discriminator%i.ACGANOutput'%ID, 1280, NUM_CLASSES, output2)\n",
        "        return output_wgan, output2, output_acgan\n",
        "    else:\n",
        "        return output_wgan, output2, None  # two layers' of output\n",
        "    \n",
        "\n",
        "\n",
        "def concat_shuffle_split(x, y):\n",
        "        shape = tf.shape(x)\n",
        "        batch_size = shape[0]\n",
        "        height, width = shape[1], shape[2]\n",
        "        depth = x.shape[3].value\n",
        "        z = tf.stack([x, y], axis=3)  # shape [batch_size, height, width, depth, 2]\n",
        "        z = tf.transpose(z, [0, 1, 2, 4, 3])\n",
        "        z = tf.reshape(z, [batch_size, height, width, 2*depth])\n",
        "        x, y = tf.split(z, num_or_size_splits=2, axis=3)\n",
        "        return x, y\n",
        "\n",
        "def basic_unit(name, x):\n",
        "    in_channels = x.shape[3].value\n",
        "    x = lib.ops.conv2d.Conv2D(name+'.pointwise', in_channels,in_channels, 1, x, stride=1)\n",
        "    x = Normalize(name+'.bn1',x)\n",
        "    x = nonlinearity(x)\n",
        "    x = conv2d(name+'.separable', in_channels, in_channels, 3, x, stride=1, nonlinearity=None)\n",
        "    x = Normalize(name+'.bn2',x)\n",
        "    x = nonlinearity(x)\n",
        "    return x\n",
        "\n",
        "def basic_unit_with_downsampling(name, x, out_channels=None):\n",
        "    in_channels = x.shape[3].value\n",
        "    out_channels = 2 * in_channels if out_channels is None else out_channels\n",
        "    \n",
        "    right = lib.ops.conv2d.Conv2D(name+'.pointwise_right', in_channels,in_channels, 1,x, stride=1)\n",
        "    right = Normalize(name+'.bn_right1',right)\n",
        "    right = nonlinearity(right)\n",
        "    right = conv2d(name+'.separable_right', in_channels, out_channels // 2,  1, right, stride=2, nonlinearity=None)  \n",
        "    right = Normalize(name+'.bn_right2',right)\n",
        "    right = nonlinearity(right)\n",
        "    \n",
        "    left = conv2d(name+'.separable_left', in_channels, out_channels // 2,  1, x, stride=2, nonlinearity=None)\n",
        "    left = Normalize(name+'.bn_left',left)\n",
        "    left = nonlinearity(left)\n",
        "    \n",
        "    return left, right\n",
        "\n",
        "def block(name, x, num_units, out_channels=None):\n",
        "    x, y = basic_unit_with_downsampling(name+'.0',x, out_channels)\n",
        "    for j in range(num_units - 1):\n",
        "        x, y = concat_shuffle_split(x, y)\n",
        "        x = basic_unit(name+'.%i'%(j+1), x)\n",
        "    x = tf.concat([x, y], axis=1)\n",
        "    return x\n",
        "\n",
        "def ShufflenetV2( # untested\n",
        "    ID, inputs, labels,kp1,kp2,kp3, D_DIM=D_DIM, OUT_DIM=1,\\\n",
        "    code=None, NUM_CHANNELS=3, HEIGHT=HEIGHT, WIDTH=WIDTH): #allow code as condition\n",
        "    name='Discriminator%i'%ID\n",
        "    output=tf.reshape(inputs, [BATCH_SIZE, HEIGHT, WIDTH, 3]) \n",
        "    print('input:',output)\n",
        "    output=lib.ops.conv2d.Conv2D(name+'.conv1',3, 24, 3, output, stride=1)\n",
        "    output = Normalize(name+'conv1.BN',output)\n",
        "    output = nonlinearity(output)\n",
        "    #output = tf.nn.max_pool(output,ksize=[1,1,3,3],strides=[1,1,2,2],padding='SAME',data_format='NCHW')\n",
        "    complexity = 244  #0.5x: 48, 1x: 116, 1.5x: 176, 2x: 244 \n",
        "    output = block(name+'.Stage2', output, num_units=4, out_channels=complexity) \n",
        "    print('after stage 2', output)\n",
        "    output = block(name+'.Stage3',output, num_units=8)\n",
        "    print('after stage 3', output)\n",
        "    output = lib.ops.conv2d.Conv2D(name+'.conv5', int(output.shape[3]), 1024 if complexity < 244 else 2048, 1, output, he_init=True, biases=False, stride=1)\n",
        "    output = Normalize(name+'.before_last_pool',output)\n",
        "    output = nonlinearity(output)\n",
        "    print('before pooling:', output)\n",
        "    output2 = tf.reduce_mean(output, axis=[1,2])  #corresponding to D_\n",
        "    output_wgan = lib.ops.linear.Linear('Discriminator%i.Output'%ID, 1024 if complexity < 244 else 2048, 1, output2)\n",
        "    output_wgan = tf.reshape(output_wgan, [-1])    #conrresponding to D\n",
        "    if CONDITIONAL and ACGAN:\n",
        "        output_acgan = lib.ops.linear.Linear('Discriminator%i.ACGANOutput'%ID, 1024 if complexity < 244 else 2048, NUM_CLASSES, output2)\n",
        "        return output_wgan, output2, output_acgan\n",
        "    else:\n",
        "        return output_wgan, output2, None  # two layers' of output\n",
        "    \n",
        "    \n",
        "def _Discriminator(ID, inputs, labels,kp1,kp2,kp3, DEVICE_ID=None): # three more parameters of keep rate\n",
        "    name='Discriminator%i'%(ID)\n",
        "    output = tf.reshape(inputs, [-1, HEIGHT, WIDTH, 3])\n",
        "    output = OptimizedResBlockDisc1(name, output)\n",
        "    print(output)\n",
        "    output = ResidualBlock(name+'.3', D_DIM, D_DIM, 3, output, resample='down', labels=labels)\n",
        "    output = dropout(output, keep_prob=kp1)     #dropout after activator\n",
        "    output = ResidualBlock(name+'.4', D_DIM, D_DIM, 3, output, resample=None, labels=labels)\n",
        "    output = dropout(output, keep_prob=kp2)     #dropout after activator\n",
        "    output = ResidualBlock(name+'.5', D_DIM, D_DIM, 3, output, resample=None, labels=labels)\n",
        "    output = dropout(output, keep_prob=kp2)     #dropout after activator\n",
        "    #output = ResidualBlock(name+'.3.0', D_DIM, D_DIM, 3, output, resample='down', labels=labels)\n",
        "    #output = dropout(output, keep_prob=kp1)     #dropout after activator\n",
        "   # output = ResidualBlock(name+'.3.1', D_DIM, D_DIM, 3, output, resample=None, labels=labels)\n",
        "   # output = dropout(output, keep_prob=kp3)     #dropout after activator\n",
        "   # output = ResidualBlock(name+'.3.2', D_DIM, D_DIM, 3, output, resample=None, labels=labels)\n",
        "  #  output = ResidualBlock(name+'.4'.0, D_DIM, D_DIM, 3, output, resample='down', labels=labels)\n",
        "   # output = dropout(output, keep_prob=kp1)     #dropout after activator\n",
        "   # output = ResidualBlock(name+'.4.1', D_DIM, D_DIM, 3, output, resample=None, labels=labels)\n",
        "   # output = dropout(output, keep_prob=kp3)     #dropout after activator\n",
        "   # output = ResidualBlock(name+'.4.2', D_DIM, D_DIM, 3, output, resample=None, labels=labels)\n",
        "    #output = dropout(output, keep_prob=kp3)     #dropout after activator\n",
        "    #output=minibatch_stddev_layer(output)\n",
        "    #output =  lib.ops.conv2d.Conv2D(name+'.refine', \\\n",
        "      #                                     int(output.shape[-1]), int(output.shape[-1])-1,3,output,stride=1)\n",
        "    \n",
        "    output = nonlinearity(output)\n",
        "    output2 =  tf.reduce_sum(output, axis=[1,2])\n",
        "\n",
        "         #  shape = output2.get_shape().as_list() # shape is [BS,1,1,n]\n",
        "            #all_embeddings = lib.get_param(name+'.embed', [NUM_CLASSES, shape[1]], dtype, tf.glorot_uniform_initializer())\n",
        "            #embedding = tf.nn.embedding_lookup(all_embeddings, labels)\n",
        "    embedding = linear(name+'.embed', NUM_CLASSES, int(output2.shape[-1]), tf.one_hot(labels, NUM_CLASSES), biases=False, weight_init=tf.initializers.glorot_normal())\n",
        "    output_wgan = linear('Discriminator%i.Output'%ID, int(output2.shape[-1]), 1, output2)\n",
        "    output_wgan = tf.reshape(output_wgan, [-1])+tf.reduce_sum(embedding*output2, 1)    #conrresponding to D\n",
        "    if CONDITIONAL and ACGAN:\n",
        "        output_acgan =linear('Discriminator%i.ACGANOutput'%ID, int(output2.shape[-1]), NUM_CLASSES, output2)\n",
        "        return output_wgan, output2, output_acgan\n",
        "    else:\n",
        "        return output_wgan, output2, None  # two layers' of output\n",
        "    \n",
        "#Discriminator=ShufflenetV2\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING! Conditional model without normalization in D might be effectively unconditional!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UahBnGLtJQQ3"
      },
      "source": [
        "from tensorflow.python.training import moving_averages \n",
        "from absl import logging\n",
        "def _moving_moments_for_inference(name, mean, variance, is_training, decay):\n",
        "  \"\"\"Use moving averages of moments during inference.\n",
        "  Args:\n",
        "    mean: Tensor of shape [num_channels] with the mean of the current batch.\n",
        "    variance: Tensor of shape [num_channels] with the variance of the current\n",
        "      batch.\n",
        "    is_training: Boolean, wheather to construct ops for training or inference\n",
        "      graph.\n",
        "    decay: Decay rate to use for moving averages.\n",
        "  Returns:\n",
        "    Tuple of (mean, variance) to use. This can the same as the inputs.\n",
        "  \"\"\"\n",
        "  # Create the moving average variables and add them to the appropriate\n",
        "  # collections.\n",
        "  variable_collections = [\n",
        "      tf.GraphKeys.MOVING_AVERAGE_VARIABLES,\n",
        "      tf.GraphKeys.MODEL_VARIABLES, tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "  ]\n",
        "  # Disable partition setting for moving_mean and moving_variance\n",
        "  # as assign_moving_average op below doesn\"t support partitioned variable.\n",
        "  moving_mean = lib.get_param(\n",
        "      name+\".moving_mean\",\n",
        "      shape=mean.shape,\n",
        "      initializer=tf.zeros_initializer(),\n",
        "      trainable=False,\n",
        "      partitioner=None,\n",
        "      )\n",
        "  moving_variance = lib.get_param(\n",
        "      name+\".moving_variance\",\n",
        "      shape=variance.shape,\n",
        "      initializer=tf.ones_initializer(),\n",
        "      trainable=False,\n",
        "      partitioner=None,\n",
        "      )\n",
        "  if is_training:\n",
        "    #logging.debug(\"Adding update ops for moving averages of mean and variance.\")\n",
        "    # Update variables for mean and variance during training.\n",
        "    update_moving_mean = moving_averages.assign_moving_average(\n",
        "        moving_mean,\n",
        "        tf.cast(mean, moving_mean.dtype),\n",
        "        decay,\n",
        "        zero_debias=False)\n",
        "    update_moving_variance = moving_averages.assign_moving_average(\n",
        "        moving_variance,\n",
        "        tf.cast(variance, moving_variance.dtype),\n",
        "        decay,\n",
        "        zero_debias=False)\n",
        "    tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_moving_mean)\n",
        "    tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_moving_variance)\n",
        "    return mean, variance\n",
        "  #logging.debug(\"Using moving mean and variance.\")\n",
        "  return moving_mean, moving_variance\n",
        "clear_op=[]\n",
        "accu_op=[]\n",
        "def _accumulated_moments_for_inference(name, mean, variance, is_training):\n",
        "  \"\"\"Use accumulated statistics for moments during inference.\n",
        "  After training the user is responsible for filling the accumulators with the\n",
        "  actual values. See _UpdateBnAccumulators() in eval_gan_lib.py for an example.\n",
        "  Args:\n",
        "    mean: Tensor of shape [num_channels] with the mean of the current batch.\n",
        "    variance: Tensor of shape [num_channels] with the variance of the current\n",
        "      batch.\n",
        "    is_training: Boolean, wheather to construct ops for training or inference\n",
        "      graph.\n",
        "  Returns:\n",
        "    Tuple of (mean, variance) to use. This can the same as the inputs.\n",
        "  \"\"\"\n",
        "  #variable_collections = [\n",
        "  #    tf.GraphKeys.MODEL_VARIABLES, tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "  #]\n",
        "  if 1:\n",
        "    # Create variables for accumulating batch statistic and use them during\n",
        "    # inference. The ops for filling the accumulators must be created and run\n",
        "    # before eval. See docstring above.\n",
        "    mean = tf.identity(mean, \"mean\")\n",
        "    variance = tf.identity(variance, \"variance\")\n",
        "    if is_training or not ACCU_STATS:\n",
        "      return mean, variance\n",
        "\n",
        "    accu_mean = lib.get_param(\n",
        "        name+\".accu_mean\",\n",
        "        shape=mean.shape,\n",
        "        initializer=tf.zeros_initializer(),\n",
        "        trainable=False\n",
        "        )\n",
        "    accu_variance = lib.get_param(\n",
        "        name+\".accu_variance\",\n",
        "        shape=variance.shape,\n",
        "        initializer=tf.zeros_initializer(),\n",
        "        trainable=False)\n",
        "    accu_counter = lib.get_param(\n",
        "        name+\".accu_counter\",\n",
        "        shape=[],\n",
        "        initializer=tf.initializers.constant(1e-12),\n",
        "        trainable=False)\n",
        "    update_accus = lib.get_param(\n",
        "        name+\".update_accus\",\n",
        "        shape=[],\n",
        "        dtype=tf.int32,\n",
        "        initializer=tf.ones_initializer(),\n",
        "        trainable=False\n",
        "        )\n",
        "\n",
        "    #logging.debug(\"Using accumulated moments.\")\n",
        "    # Return the accumulated batch statistics and add current batch statistics\n",
        "    # to accumulators if update_accus variables equals 1.\n",
        "    def update_accus_fn():\n",
        "      return tf.group([\n",
        "          tf.assign_add(accu_mean, mean),\n",
        "          tf.assign_add(accu_variance, variance),\n",
        "          tf.assign_add(accu_counter, 1),\n",
        "      ])\n",
        "    dep = tf.cond(\n",
        "        tf.equal(update_accus, 1),\n",
        "        update_accus_fn,\n",
        "        tf.no_op)\n",
        "    clear_op.append(tf.group(*[\n",
        "          tf.assign(accu_mean, 0*accu_mean),\n",
        "          tf.assign(accu_variance, 0*accu_variance),\n",
        "          tf.assign(accu_counter, 1e-12)\n",
        "      ]))\n",
        " \n",
        "    with tf.control_dependencies([dep]):\n",
        "      return accu_mean / accu_counter, accu_variance / accu_counter\n",
        "\n",
        "def standardize_batch(name, inputs,\n",
        "                      is_training,\n",
        "                      decay=0.9,\n",
        "                      epsilon=1e-5,\n",
        "                      data_format=\"NHWC\",\n",
        "                      use_moving_averages=False,\n",
        "                      use_cross_replica_mean=False):\n",
        "  \"\"\"Adds TPU-enabled batch normalization layer.\n",
        "  This version does not apply trainable scale or offset!\n",
        "  It normalizes a tensor by mean and variance.\n",
        "  Details on Batch Normalization can be found in \"Batch Normalization:\n",
        "  Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\n",
        "  Ioffe S. and Szegedy C. 2015 [http://arxiv.org/abs/1502.03167].\n",
        "  Note #1: This method computes the batch statistic across all TPU replicas,\n",
        "  thus simulating the true batch norm in the distributed setting. If one wants\n",
        "  to avoid the cross-replica communication set use_cross_replica_mean=False.\n",
        "  Note #2: When is_training is True the moving_mean and moving_variance need\n",
        "  to be updated in each training step. By default, the update_ops are placed\n",
        "  in `tf.GraphKeys.UPDATE_OPS` and they need to be added as a dependency to\n",
        "  the `train_op`. For example:\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    if update_ops:\n",
        "      updates = tf.group(*update_ops)\n",
        "      total_loss = control_flow_ops.with_dependencies([updates], total_loss)\n",
        "  Note #3: Reasonable values for `decay` are close to 1.0, typically in the\n",
        "  multiple-nines range: 0.999, 0.99, 0.9, etc. Lower the `decay` value (trying\n",
        "  `decay`=0.9) if model experiences reasonably good training performance but\n",
        "  poor validation and/or test performance.\n",
        "  Args:\n",
        "    inputs: A tensor with 2 or 4 dimensions, where the first dimension is\n",
        "      `batch_size`. The normalization is over all but the last dimension if\n",
        "      `data_format` is `NHWC`, and the second dimension if `data_format` is\n",
        "      `NCHW`.\n",
        "    is_training: Whether or not the layer is in training mode. In training\n",
        "      mode it would accumulate the statistics of the moments into the\n",
        "      `moving_mean` and `moving_variance` using an exponential moving average\n",
        "      with the given `decay`. When is_training=False, these variables are not\n",
        "      updated, and the precomputed values are used verbatim.\n",
        "    decay: Decay for the moving averages. See notes above for reasonable\n",
        "      values.\n",
        "    epsilon: Small float added to variance to avoid dividing by zero.\n",
        "    data_format: Input data format. NHWC or NCHW.\n",
        "    use_moving_averages: If True keep moving averages of mean and variance that\n",
        "      are used during inference. Otherwise use accumlators.\n",
        "    use_cross_replica_mean: If True add operations to do computes batch norm\n",
        "      statistics across all TPU cores. These ops are not compatible with other\n",
        "      platforms. The default (None) will only add the operations if running\n",
        "      on TPU.\n",
        "  Returns:\n",
        "    The normalized tensor with the same type and shape as `inputs`.\n",
        "  \"\"\"\n",
        "  if data_format not in {\"NCHW\", \"NHWC\"}:\n",
        "    raise ValueError(\n",
        "        \"Invalid data_format {}. Allowed: NCHW, NHWC.\".format(data_format))\n",
        "  if use_cross_replica_mean is None:\n",
        "    # Default to global batch norm only on TPUs.\n",
        "    use_cross_replica_mean = (\n",
        "        tpu_function.get_tpu_context().number_of_shards is not None)\n",
        "    logging.debug(\"Automatically determined use_cross_replica_mean=%s.\",\n",
        "                  use_cross_replica_mean)\n",
        "\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  inputs_dtype = inputs.dtype\n",
        "  inputs_shape = inputs.get_shape()\n",
        "\n",
        "  num_channels = inputs.shape[-1].value\n",
        "  if num_channels is None:\n",
        "    raise ValueError(\"`C` dimension must be known but is None\")\n",
        "\n",
        "  inputs_rank = inputs_shape.ndims\n",
        "  if inputs_rank is None:\n",
        "    raise ValueError(\"Inputs %s has undefined rank\" % inputs.name)\n",
        "  elif inputs_rank not in [2, 4]:\n",
        "    raise ValueError(\n",
        "        \"Inputs %s has unsupported rank.\"\n",
        "        \" Expected 2 or 4 but got %d\" % (inputs.name, inputs_rank))\n",
        "  # Bring 2-D inputs into 4-D format.\n",
        "  if inputs_rank == 2:\n",
        "    new_shape = [-1, 1, 1, num_channels]\n",
        "    if data_format == \"NCHW\":\n",
        "      new_shape = [-1, num_channels, 1, 1]\n",
        "    inputs = tf.reshape(inputs, new_shape)\n",
        "\n",
        "  # Execute a distributed batch normalization\n",
        "  axis = 1 if data_format == \"NCHW\" else 3\n",
        "  inputs = tf.cast(inputs, tf.float32)\n",
        "  reduction_axes = [i for i in range(4) if i != axis]\n",
        "  if use_cross_replica_mean:\n",
        "    mean, variance = tpu_ops.cross_replica_moments(inputs, reduction_axes)\n",
        "  else:\n",
        "    counts, mean_ss, variance_ss, _ = tf.nn.sufficient_statistics(\n",
        "        inputs, reduction_axes, keep_dims=False)\n",
        "    mean, variance = tf.nn.normalize_moments(\n",
        "        counts, mean_ss, variance_ss, shift=None)\n",
        "  use_moving_averages= 0\n",
        "  if use_moving_averages:\n",
        "    mean, variance = _moving_moments_for_inference(\n",
        "        name, mean=mean, variance=variance, is_training=is_training, decay=decay)\n",
        "  else:\n",
        "    mean, variance = _accumulated_moments_for_inference(\n",
        "        name, mean=mean, variance=variance, is_training=is_training)\n",
        "\n",
        "  outputs = tf.nn.batch_normalization(\n",
        "      inputs,\n",
        "      mean=mean,\n",
        "      variance=variance,\n",
        "      offset=None,\n",
        "      scale=None,\n",
        "      variance_epsilon=epsilon)\n",
        "  outputs = tf.cast(outputs, inputs_dtype)\n",
        "\n",
        "  # Bring 2-D inputs back into 2-D format.\n",
        "  if inputs_rank == 2:\n",
        "    outputs = tf.reshape(outputs, [-1] + inputs_shape[1:].as_list())\n",
        "  outputs.set_shape(inputs_shape)\n",
        "  return outputs\n",
        "'''\n",
        "def condition_batch_norm(name, x, z, is_training=True):\n",
        "        _, _, _ , c= x.get_shape().as_list()\n",
        "        decay = 0.999\n",
        "        epsilon = 1e-4\n",
        "\n",
        "        test_mean = lib.param(name+\".pop_mean\", tf.zeros([1,1,1,c],dtype=dtype), dtype=dtype, trainable=False)\n",
        "        test_var = lib.param(name+\".pop_var\", tf.ones([1,1,1,c],dtype=dtype), dtype=dtype, trainable=False)\n",
        "        beta = linear(name+'.beta', int(z.shape[-1]), c, z, biases=False)\n",
        "        gamma = linear(name+'.gamma', int(z.shape[-1]), c, z, biases=False) + 1\n",
        "\n",
        "        beta = tf.reshape(beta, shape=[-1, 1, 1, c])\n",
        "        gamma = tf.reshape(gamma, shape=[-1, 1, 1, c])\n",
        "\n",
        "        if is_training:\n",
        "            batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], keep_dims=True)\n",
        "            ema_mean = tf.assign(test_mean, test_mean * decay + batch_mean * (1 - decay))\n",
        "            ema_var = tf.assign(test_var, test_var * decay + batch_var * (1 - decay))\n",
        "\n",
        "            with tf.control_dependencies([ema_mean, ema_var]):\n",
        "                return gamma*tf.nn.batch_normalization(x, test_mean, test_var, offset=None, scale=None,variance_epsilon=epsilon)+beta\n",
        "        else:\n",
        "            return tf.nn.batch_normalization(x, test_mean, test_var, beta, gamma, epsilon)\n",
        "'''\n",
        "def batch_norm(name, inputs, is_training, center=True, scale=True):\n",
        "  \"\"\"Performs the vanilla batch normalization with trainable scaling and offset.\n",
        "  Args:\n",
        "    inputs: A tensor with 2 or 4 dimensions, where the first dimension is\n",
        "      `batch_size`. The normalization is over all but the last dimension if\n",
        "      `data_format` is `NHWC`, and the second dimension if `data_format` is\n",
        "      `NCHW`.\n",
        "    is_training: Whether or not the layer is in training mode.\n",
        "    center: If True, add offset of beta to normalized tensor.\n",
        "    scale: If True, multiply by gamma. When the next layer is linear  this can\n",
        "      be disabled since the scaling will be done by the next layer.\n",
        "    name: Name of the variable scope.\n",
        "  Returns:\n",
        "    The normalized tensor with the same type and shape as `inputs`.\n",
        "  \"\"\"\n",
        "  if 1:\n",
        "    outputs = standardize_batch(name, inputs, is_training=is_training)\n",
        "    num_channels = inputs.shape[-1].value\n",
        "\n",
        "    # Allocate parameters for the trainable variables.\n",
        "#    collections = [tf.GraphKeys.MODEL_VARIABLES,\n",
        "             #      tf.GraphKeys.GLOBAL_VARIABLES]\n",
        "    if scale:\n",
        "      gamma = lib.get_param(\n",
        "          name+\".gamma\",\n",
        "          [num_channels],\n",
        "          initializer=tf.ones_initializer())\n",
        "      outputs *= gamma\n",
        "    if center:\n",
        "      beta = lib.get_param(\n",
        "          name+\".beta\",\n",
        "          [num_channels],\n",
        "          initializer=tf.zeros_initializer())\n",
        "      outputs += beta\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def condition_batch_norm(name, inputs, y, is_training, center=True,\n",
        "                           scale=True, use_bias=False):\n",
        "  \"\"\"Conditional batch normalization.\"\"\"\n",
        "  if y is None:\n",
        "    raise ValueError(\"You must provide y for conditional batch normalization.\")\n",
        "  if y.shape.ndims != 2:\n",
        "    raise ValueError(\"Conditioning must have rank 2.\")\n",
        "  if 1:\n",
        "    outputs = standardize_batch(name, inputs, is_training=is_training)\n",
        "    num_channels = inputs.shape[-1].value\n",
        "    if 1:\n",
        "      if scale:\n",
        "        gamma = linear(name+'.Gamma', int(y.shape[-1]), num_channels, y, biases=use_bias)\n",
        "        gamma = tf.reshape(gamma, [-1, 1, 1, num_channels])\n",
        "        outputs *= gamma\n",
        "      if center:\n",
        "        beta = linear(name+'.Beta', int(y.shape[-1]), num_channels, y, biases=use_bias)\n",
        "        beta = tf.reshape(beta, [-1, 1, 1, num_channels])\n",
        "        outputs += beta\n",
        "      return outputs\n",
        "\n",
        "def class_condition_batch_norm(name, inputs, y, is_training, center=True,\n",
        "                           scale=True, use_bias=False):\n",
        "  \"\"\"Conditional batch normalization.\"\"\"\n",
        "  if y is None:\n",
        "    raise ValueError(\"You must provide labels for conditional batch normalization.\")\n",
        "  if y.shape.ndims != 1:\n",
        "    raise ValueError(\"Labels must have rank 1.\")\n",
        "  if 1:\n",
        "    outputs = standardize_batch(name, inputs, is_training=is_training)\n",
        "    num_channels = inputs.shape[-1].value\n",
        "    if 1:\n",
        "      offset_m = lib.get_param(name+'.offset', [NUM_CLASSES,num_channels], initializer=tf.zeros_initializer())\n",
        "      scale_m = lib.get_param(name+'.scale', [NUM_CLASSES,num_channels], initializer=tf.ones_initializer())\n",
        "      gamma = tf.nn.embedding_lookup(offset_m, y)\n",
        "      beta = tf.nn.embedding_lookup(scale_m, y)\n",
        "      if scale:\n",
        "        gamma = tf.reshape(gamma, [-1, 1, 1, num_channels])\n",
        "        outputs *= gamma\n",
        "      if center:\n",
        "        beta = tf.reshape(beta, [-1, 1, 1, num_channels])\n",
        "        outputs += beta\n",
        "      return outputs\n",
        "\n",
        "def upsample(x):\n",
        "            x = tf.image.resize_nearest_neighbor(x, [2*int(x.shape[1]), 2*int(x.shape[2])])\n",
        "            return x    \n",
        "##################################################################################\n",
        "# Residual-block, Self-Attention-block\n",
        "##################################################################################\n",
        "\n",
        "def GBlock(name, x, y, channels, is_training, use_bias=True, sn=False,use_upsample=True):\n",
        "\n",
        "    in_channels, out_channels = int(x.shape[3]), channels\n",
        "    activation = nonlinearity\n",
        "    upsample_fn = upsample\n",
        "    learnable_sc = in_channels != out_channels or upsample\n",
        "    \n",
        "    # Conv layers\n",
        "    conv1 = functools.partial(conv2d, name=name+'.conv1', input_dim=in_channels, output_dim=out_channels, biases=use_bias, filter_size=3)\n",
        "    conv2 =functools.partial(conv2d, name=name+'.conv2', input_dim=out_channels, output_dim=out_channels, biases=use_bias, filter_size=3)\n",
        "    if learnable_sc:\n",
        "      conv_sc = functools.partial(conv2d, name=name+'.conv_sc',input_dim=in_channels, output_dim=out_channels, biases=use_bias, filter_size=1)\n",
        "    # Batchnorm layers\n",
        "    if 1:\n",
        "        which_bn = condition_batch_norm\n",
        "    else:\n",
        "        which_bn = class_condition_batch_norm\n",
        "    bn = functools.partial(which_bn,is_training=is_training, use_bias=False)\n",
        "\n",
        "    h = activation(bn(name=name+'.cbn1', inputs=x, y=y))\n",
        "    if use_upsample:\n",
        "      h = upsample_fn(h)\n",
        "      x = upsample_fn(x)\n",
        "    h = conv1(inputs=h)\n",
        "    h = activation(bn(name=name+'.cbn2', inputs=h, y=y))\n",
        "    h = conv2(inputs=h)\n",
        "    if learnable_sc:       \n",
        "      x = conv_sc(inputs=x)\n",
        "    return h + x\n",
        "\n",
        "def DBlock(name, x, channels, use_bias=True, is_training=True, sn=False,preactivation=True,downsample=True,wide=True):\n",
        "    '''        #x = Normalize(name+'BN1',x_init)\n",
        "            if preactivation:\n",
        "                x = nonlinearity(x_init)\n",
        "            else:\n",
        "                x = x_init\n",
        "            x = conv2d(name+'res1',int(x.shape[3]), channels, 3, x, stride=1, biases=use_bias)\n",
        "            #x = Normalize(name+'BN2',x)\n",
        "            x = nonlinearity(x)\n",
        "            x = conv2d(name+'res2',int(x.shape[3]), channels, 3, x, stride=1, biases=use_bias)\n",
        "            x=tf.nn.avg_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',data_format='NHWC')\n",
        "            if preactivation:\n",
        "                x_init = conv2d(name+'skip',int(x_init.shape[3]), channels, 1, x_init, stride=1,  biases=use_bias)\n",
        "                x_init=tf.nn.avg_pool(x_init,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',data_format='NHWC') \n",
        "            else:\n",
        "                x_init=tf.nn.avg_pool(x_init,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',data_format='NHWC') \n",
        "                x_init = conv2d(name+'skip',int(x_init.shape[3]), channels, 1, x_init, stride=1,  biases=use_bias)\n",
        "            return x + x_init\n",
        "'''\n",
        "    in_channels, out_channels = int(x.shape[3]), channels\n",
        "    # If using wide D (as in SA-GAN and BigGAN), change the channel pattern\n",
        "    hidden_channels = out_channels if wide else in_channels\n",
        "    activation = nonlinearity\n",
        "    downsample_fn=functools.partial(tf.nn.avg_pool,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',data_format='NHWC')\n",
        "    # Conv layers\n",
        "    conv1 = functools.partial(conv2d, name=name+'.conv1', input_dim=in_channels, output_dim=hidden_channels, biases=use_bias, filter_size=3)\n",
        "    conv2 =functools.partial(conv2d, name=name+'.conv2', input_dim=hidden_channels, output_dim=out_channels, biases=use_bias, filter_size=3)\n",
        "    learnable_sc = True if (in_channels != out_channels) or downsample else False\n",
        "    if learnable_sc:\n",
        "        conv_sc=functools.partial(conv2d, name=name+'.conv_sc',input_dim=in_channels, output_dim=out_channels, biases=use_bias, filter_size=1)\n",
        "    def shortcut(x):\n",
        "        if preactivation:\n",
        "          if learnable_sc:\n",
        "            x = conv_sc(inputs=x)\n",
        "          if downsample:\n",
        "            x = downsample_fn(x)\n",
        "        else:\n",
        "          if downsample:\n",
        "            x = downsample_fn(x)\n",
        "          if learnable_sc:\n",
        "            x = conv_sc(inputs=x)\n",
        "        return x\n",
        "    if preactivation:\n",
        "      # h = self.activation(x) # NOT TODAY SATAN\n",
        "      # Andy's note: This line *must* be an out-of-place ReLU or it \n",
        "      #              will negatively affect the shortcut connection.\n",
        "      h = nonlinearity(x)\n",
        "    else:\n",
        "      h = x    \n",
        "    h = conv1(inputs=h)\n",
        "    h = conv2(inputs=nonlinearity(h))\n",
        "    if downsample:\n",
        "      h =downsample_fn(h)\n",
        "    return h + shortcut(x)\n",
        "\n",
        "def bottleneck_resblock(name, x, z, channels, use_bias=True, is_training=True, sn=False):\n",
        "            x_init = x\n",
        "            if 'Generator' in name:\n",
        "                x = condition_batch_norm(name+'.cbn1',x, z, is_training)\n",
        "            x = nonlinearity(x)\n",
        "            x = conv2d(name+'.res1',int(x.shape[3]), int(x.shape[3])//4, 1, x, stride=1, biases=use_bias)\n",
        "            if 'Generator' in name:\n",
        "                x = condition_batch_norm(name+'.cbn2',x, z, is_training)\n",
        "            x = nonlinearity(x_init)\n",
        "            x = conv2d(name+'.res2',int(x.shape[3]), int(x.shape[3]), 3, x, stride=1, biases=use_bias)\n",
        "            if 'Generator' in name:\n",
        "                x = condition_batch_norm(name+'.cbn3',x, z, is_training)\n",
        "            x = nonlinearity(x)\n",
        "            x = conv2d(name+'.res3',int(x.shape[3]), int(x.shape[3]), 3, x, stride=1, biases=use_bias)\n",
        "            if 'Generator' in name:\n",
        "                x = condition_batch_norm(name+'.cbn4',x, z, is_training)\n",
        "            x = nonlinearity(x)\n",
        "            x = conv2d(name+'.res4',int(x.shape[3]), channels, 1, x, stride=1, biases=use_bias)\n",
        "            \n",
        "            return x + x_init\n",
        "        \n",
        "def bottleneck_resblock_up_condition(name, x_init, z, channels, use_bias=True, is_training=True, sn=False):\n",
        "            x = condition_batch_norm(name+'.cbn1',x_init, z, is_training)\n",
        "            x = nonlinearity(x)\n",
        "            x = conv2d(name+'.res1',int(x.shape[3]), int(x.shape[3])//4, 1, x, stride=1, biases=use_bias)\n",
        "            x = condition_batch_norm(name+'.cbn2',x, z, is_training)\n",
        "            x = nonlinearity(x_init)\n",
        "            x = upsample(x)\n",
        "            x = conv2d(name+'.res2',int(x.shape[3]), int(x.shape[3]), 3, x, stride=1, biases=use_bias)\n",
        "            x = condition_batch_norm(name+'.cbn3',x, z, is_training)\n",
        "            x = nonlinearity(x)\n",
        "            x = conv2d(name+'.res3',int(x.shape[3]), int(x.shape[3]), 3, x, stride=1, biases=use_bias)\n",
        "            x = condition_batch_norm(name+'.cbn4',x, z, is_training)\n",
        "            x = nonlinearity(x)\n",
        "            x = conv2d(name+'.res4',int(x.shape[3]), channels, 1, x, stride=1, biases=use_bias)\n",
        "            \n",
        "            x_skip=x_init[:,:,:,:channels]\n",
        "            x_skip=upsample(x_skip)\n",
        "            \n",
        "            return x + x_skip\n",
        "\n",
        "def bottleneck_resblock_down(name, x_init, channels, use_bias=True, is_training=True, sn=False, scope='resblock_down'):\n",
        "            x = nonlinearity(x_init)\n",
        "            x = conv2d(name+'.res1',int(x.shape[3]), int(x.shape[3])//4, 1, x, stride=1, biases=use_bias)\n",
        "            x = nonlinearity(x_init)\n",
        "            x = conv2d(name+'.res2',int(x.shape[3]), int(x.shape[3]), 3, x, stride=1, biases=use_bias)\n",
        "            x = nonlinearity(x)\n",
        "            x = conv2d(name+'.res3',int(x.shape[3]), int(x.shape[3]), 3, x, stride=1, biases=use_bias)\n",
        "            x = nonlinearity(x)\n",
        "            x=tf.nn.avg_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',data_format='NHWC')\n",
        "            x = conv2d(name+'.res4',int(x.shape[3]), channels, 1, x, stride=1, biases=use_bias)\n",
        "            x_skip=tf.nn.avg_pool(x_init,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',data_format='NHWC')\n",
        "            if channels>int(x_skip.shape[3]):\n",
        "                x_skip=tf.concat([x_skip, conv2d(name+'.skip',int(x_skip.shape[3]), int(x_skip.shape[3]), 1, x_skip, stride=1,  biases=use_bias)],3)\n",
        "\n",
        "            return x + x_skip\n",
        "        \n",
        "def hw_flatten(x) :\n",
        "    return tf.reshape(x, [-1, int(x.shape[1])*int(x.shape[2]), int(x.shape[3])])\n",
        "\n",
        "def self_attention(name, x, channels, sn=False, scope='self_attention'):\n",
        "\n",
        "        f = conv2d(name+'.sa.conv1',int(x.shape[3]), channels // 8, 1, x, stride=1, sn=sn, scope='f_conv')  # [bs, h, w, c']\n",
        "        g = conv2d(name+'.sa.conv2',int(x.shape[3]), channels // 8, 1, x, stride=1, sn=sn, scope='g_conv')  # [bs, h, w, c']\n",
        "        h = conv2d(name+'.sa.conv3',int(x.shape[3]), channels, 1, x, stride=1, sn=sn, scope='h_conv')  # [bs, h, w, c]\n",
        "\n",
        "        # N = h * w\n",
        "        s = tf.matmul(hw_flatten(g), hw_flatten(f),  transpose_b=True)  # # [bs, N, N]\n",
        "\n",
        "        beta = tf.nn.softmax(s)  # attention map\n",
        "\n",
        "        o = tf.matmul(beta, hw_flatten(h))  # [bs, N, C]\n",
        "        gamma = lib.param(name+\".gamma\", 0.,dtype=dtype)\n",
        "\n",
        "        o = tf.reshape(o, shape=x.shape)  # [bs, h, w, C]\n",
        "        x = gamma * o + x\n",
        "\n",
        "        return x\n",
        "\n",
        "def self_attention_2(name, x, channels, sn=False, biases=False):\n",
        "    \n",
        "        f = conv2d(name+'.sa.conv1',int(x.shape[3]), channels // 8, 1, x, stride=1, biases=biases)  # [bs, h, w, c/8]\n",
        "        f =  tf.nn.max_pool(f,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',data_format='NHWC')# [bs, h/2, w/2, c/8]\n",
        "\n",
        "        g = conv2d(name+'.sa.conv2',int(x.shape[3]), channels // 8, 1, x, stride=1, biases=biases)  # [bs, h, w, c/8]\n",
        "\n",
        "        h = conv2d(name+'.sa.conv3',int(x.shape[3]), channels // 2, 1, x, stride=1, biases=biases)  # [bs, h, w, c/2]\n",
        "        h = tf.nn.max_pool(h,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',data_format='NHWC')# [bs, h/2, w/2, c/2]\n",
        "\n",
        "        # N = h * w\n",
        "        s = tf.matmul(hw_flatten(g), hw_flatten(f),  transpose_b=True)  # # [bs, N, N/4]\n",
        "\n",
        "        beta = tf.nn.softmax(s)  # attention map # [bs, N, N/4]\n",
        "\n",
        "        o = tf.matmul(beta, hw_flatten(h))  # [bs, N, C/2]\n",
        "        gamma = lib.param(name+\".gamma\", 0.,dtype=dtype)\n",
        "\n",
        "        o = tf.reshape(o, shape=[-1, x.shape[1], x.shape[2], channels // 2])  # [bs, h, w, C/2]\n",
        "        o = conv2d(name+'.out',channels // 2, channels, 1, o, stride=1, biases=biases)  # [bs, h, w, C]\n",
        "        x = gamma * o + x\n",
        "\n",
        "        return x\n",
        "\n",
        "    ##################################################################################\n",
        "    # Generator\n",
        "    ##################################################################################\n",
        "\n",
        "def Generator(ID, noise, n_samples, labels=None, ema=False, is_training=True):\n",
        "            name= 'Generator'+'.%i'%ID if not ema else 'Generator_ema'+'.%i'%ID\n",
        "            z=noise\n",
        "            # 6\n",
        "            if Z_DIM == 128:\n",
        "                split_dim = 20\n",
        "                split_dim_remainder = Z_DIM - (split_dim * 5)\n",
        "\n",
        "                z_split = tf.split(z, num_or_size_splits=[split_dim] * 5 + [split_dim_remainder], axis=1)\n",
        "\n",
        "            else:\n",
        "                split_dim = Z_DIM // 6\n",
        "                split_dim_remainder = Z_DIM - (split_dim * 6)\n",
        "\n",
        "                if split_dim_remainder == 0 :\n",
        "                    z_split = tf.split(z, num_or_size_splits=[split_dim] * 6, axis=-1)\n",
        "                else :\n",
        "                    z_split = tf.split(z, num_or_size_splits=[split_dim] * 5 + [split_dim_remainder], axis=1)\n",
        "\n",
        "            ch = G_DIM\n",
        "            #ch=G_DIM\n",
        "            #all_embeddings = lib.get_param(name+'.embed', [NUM_CLASSES, 128], dtype, tf.glorot_uniform_initializer())\n",
        "            #embedding = tf.nn.embedding_lookup(all_embeddings, labels)\n",
        "            print(tf.one_hot(labels, NUM_CLASSES))\n",
        "            if SHARED_EMBED:\n",
        "                embedding = lib.ops.linear.Linear(name+'.embed', NUM_CLASSES, 128, tf.one_hot(labels, NUM_CLASSES), biases=False, spectralnorm=0,weight_regularizer=None)\n",
        "            else:\n",
        "                embedding = tf.one_hot(labels, NUM_CLASSES)\n",
        "            if HIER:    \n",
        "                code=[tf.concat([embedding, z_split[i]],1) for i in range(6)]\n",
        "            else:\n",
        "                code=[embedding]*5\n",
        "            print('code: ', code)\n",
        "            BOTTOM_WIDTH=int(WIDTH//2**np.ceil(np.log2(WIDTH/4)))\n",
        "            NUM_BLOCKS=int(np.log2(WIDTH/BOTTOM_WIDTH))\n",
        "            x = linear(name+'dense',int(z_split[0].shape[-1]), BOTTOM_WIDTH**2 * ch, z_split[0], biases=False)\n",
        "            x = tf.reshape(x, shape=[-1, BOTTOM_WIDTH, BOTTOM_WIDTH, ch])\n",
        "            print('after dense', x)\n",
        "            for k in range(NUM_BLOCKS):\n",
        "                x = GBlock(name+'.up%i'%k, x, code[k+1], channels=ch,is_training=is_training)\n",
        "                print('After Block %i:'%k, x)\n",
        "                #ch = ch // 2\n",
        "                if 2**k*BOTTOM_WIDTH*2==ATTENTION:\n",
        "                    x = self_attention_2(name+'.sa',x, channels=ch)\n",
        "                    print('after sa', x)\n",
        "            \n",
        "            x = batch_norm(name+'.last_bn',x,is_training=is_training)\n",
        "            x = nonlinearity(x)\n",
        "            x = conv2d(name+'.last_conv', int(x.shape[3]), 3, 3, x, stride=1)\n",
        "\n",
        "            x = tf.nn.tanh(x)\n",
        "\n",
        "            return tf.reshape(x, [-1, DATA_DIM])\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Discriminator\n",
        "    ##################################################################################\n",
        "\n",
        "def Discriminator(\\\n",
        "    ID, inputs, labels,kp1,kp2,kp3, D_DIM=D_DIM, OUT_DIM=1,\\\n",
        "    code=None, NUM_CHANNELS=3, HEIGHT=HEIGHT, WIDTH=WIDTH, is_training=True):\n",
        "            ch = D_DIM\n",
        "            is_train=True\n",
        "            name='Discriminator.%i'%ID\n",
        "            x = tf.reshape(inputs, [-1, HEIGHT, WIDTH, 3])\n",
        "            print('inputs:', x)\n",
        "            if ADA:\n",
        "              x = augment(x,p=d_p,flip=False)\n",
        "            #x=conv2d(name+'.input', 3, ch, 3, x, stride=1)\n",
        "           # x = nonlinearity(x)\n",
        "        \n",
        "            ch = D_DIM\n",
        "            x = DBlock(name+'.resdown1', x, channels=ch, is_training=is_training,preactivation=False)\n",
        "            x = dropout(x, keep_prob=kp1)\n",
        "            print('after resdown1', x)\n",
        "            \n",
        "            # Non-Local Block\n",
        "            #x = self_attention_2(name+'.sa', x, channels=ch)\n",
        "            #x = dropout(x, keep_prob=kp1)\n",
        "            #print('after sa', x)\n",
        "            \n",
        "            #ch = ch * 2\n",
        "            x = DBlock(name+'.resdown2', x, channels=ch, is_training=is_training)\n",
        "            x = dropout(x, keep_prob=kp1) \n",
        "            print('after resdown2', x)\n",
        "\n",
        "            #ch = ch * 2\n",
        "            #x = DBlock(name+'.resdown4', x, channels=ch, is_training=is_training)\n",
        "            #x = dropout(x, keep_prob=kp1) \n",
        "            #print('after resdown4', x)\n",
        "        \n",
        "            #ch = ch * 2\n",
        "            #x = DBlock(name+'.resdown8', x, channels=ch,  is_training=is_training)\n",
        "           # x = dropout(x, keep_prob=kp1) \n",
        "           # print('after resdown8', x)\n",
        "            #ch = ch * 2\n",
        "            x = DBlock(name+'.res8', x, channels=ch, is_training=is_training, downsample=False)\n",
        "            x = dropout(x, keep_prob=kp2)\n",
        "            print('after res8', x)\n",
        "            #ch = ch * 2\n",
        "            x = DBlock(name+'.res16', x, channels=ch, is_training=is_training, downsample=False)\n",
        "            x = dropout(x, keep_prob=kp2)\n",
        "            print('after res16', x)\n",
        "          #  x = resblock(name+'.reslast', x, channels=ch, is_training=is_training)\n",
        "            x = nonlinearity(x)\n",
        "            #print('after reslast', x)\n",
        "           # x=minibatch_stddev_layer(x)\n",
        "           # x =  lib.ops.conv2d.Conv2D(name+'.refine', int(x.shape[-1]), int(x.shape[-1])-1, 3,x,stride=1)\n",
        "            output2 =  tf.reduce_sum(x, axis=[1,2])\n",
        "\n",
        "         #  shape = output2.get_shape().as_list() # shape is [BS,1,1,n]\n",
        "            #all_embeddings = lib.get_param(name+'.embed', [NUM_CLASSES, shape[1]], dtype, tf.glorot_uniform_initializer())\n",
        "            #embedding = tf.nn.embedding_lookup(all_embeddings, labels)\n",
        "            embedding = linear(name+'.embed', NUM_CLASSES, int(output2.shape[-1]), tf.one_hot(labels, NUM_CLASSES), biases=False, weight_init=tf.random_uniform_initializer(-.1,.1))\n",
        "            output_wgan = linear('Discriminator%i.Output'%ID, ch, 1, output2)\n",
        "            output_wgan = tf.reshape(output_wgan, [-1]) + (tf.reduce_sum(embedding*output2, 1) if CONDITIONAL else 0)    #conrresponding to D\n",
        "            if MH_LOSS or AM_LOSS:\n",
        "                output_mhingegan = linear(name+'.MHINGEGANOutput', D_DIM, NUM_CLASSES+1, output2)\n",
        "                return output_wgan, output2, output_mhingegan\n",
        "            if CONDITIONAL and ACGAN:\n",
        "                output_acgan =linear('Discriminator%i.ACGANOutput'%ID, ch, NUM_CLASSES, output2)\n",
        "                return output_wgan, output2, output_acgan\n",
        "            else:\n",
        "                return output_wgan, output2, None  # two layers' of output\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Bottleneck Generator\n",
        "    ##################################################################################\n",
        "\n",
        "def Bottleneck_Generator(ID, noise, n_samples, labels=None):\n",
        "            name='Generator'+'.%i'%ID\n",
        "            z=noise\n",
        "\n",
        "            ch = 16 * G_DIM\n",
        "            embedding = lib.ops.linear.Linear(name+'.embed', NUM_CLASSES, 128, tf.one_hot(labels, NUM_CLASSES))\n",
        "            code=tf.concat([embedding, z],1)\n",
        "            print('code: ', code)\n",
        "            x = linear(name+'dense',int(z.shape[-1]), 4 * 4 * ch, z)\n",
        "            x = tf.reshape(x, shape=[-1, 4, 4, ch])\n",
        "            print('after dense', x)\n",
        "            x=bottleneck_resblock(name+'.16ch.1',x, code, channels=ch, use_bias=False)\n",
        "            x=bottleneck_resblock_up_condition(name+'.16ch.up',x, code, channels=ch, use_bias=False)\n",
        "            x=bottleneck_resblock(name+'.16ch.2',x, code, channels=ch, use_bias=False)\n",
        "            print('after up1', x)  \n",
        "            \n",
        "            ch = ch // 2\n",
        "            x=bottleneck_resblock_up_condition(name+'.8ch.up',x, code, channels=ch, use_bias=False)\n",
        "            x=bottleneck_resblock(name+'.8ch',x, code, channels=ch, use_bias=False)\n",
        "            print('after up2', x)\n",
        "            \n",
        "            ch = ch // 2\n",
        "            x=bottleneck_resblock_up_condition(name+'.4ch.up',x, code, channels=ch, use_bias=False)\n",
        "            x=bottleneck_resblock(name+'.4ch',x, code, channels=ch, use_bias=False)\n",
        "            print('after up3', x)\n",
        "            \n",
        "            ch = ch // 2\n",
        "            x=bottleneck_resblock_up_condition(name+'.2ch.up',x, code, channels=ch, use_bias=False)\n",
        "            print('after up4', x)\n",
        "            # Non-Local Block\n",
        "            x = self_attention_2(name+'.2ch.sa',x, channels=ch)\n",
        "            print('after sa', x)\n",
        "            x=bottleneck_resblock(name+'.2ch',x, code, channels=ch, use_bias=False)\n",
        "\n",
        "            ch = ch // 2\n",
        "            x =bottleneck_resblock_up_condition(name+'.ch.up',x, code, channels=ch, use_bias=False)\n",
        "            print('after up5', x)\n",
        "            x = Normalize('last_bn',x)\n",
        "            x = nonlinearity(x)\n",
        "            x = conv2d(name+'.last_conv', int(x.shape[3]), 3, 3, x, stride=1, biases=False)\n",
        "\n",
        "            x = tf.nn.tanh(x)\n",
        "\n",
        "            return tf.reshape(x, [-1, DATA_DIM])\n",
        "            \n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    #Bottleneck Discriminator\n",
        "    ##################################################################################\n",
        "\n",
        "def Bottleneck_Discriminator(\\\n",
        "    ID, inputs, labels,kp1,kp2,kp3, D_DIM=D_DIM, OUT_DIM=1,\\\n",
        "    code=None, NUM_CHANNELS=3, HEIGHT=HEIGHT, WIDTH=WIDTH, is_training=True):\n",
        "            ch = D_DIM\n",
        "            is_train=True\n",
        "            name='Discriminator%i'%ID\n",
        "            x = tf.reshape(inputs, [-1, HEIGHT, WIDTH, 3])\n",
        "            print('inputs:', x)\n",
        "            x=conv2d(name+'.input', 3, ch, 3, x, stride=1, biases=False)\n",
        "            #x = nonlinearity(x)\n",
        "            ch = ch * 2\n",
        "            x = bottleneck_resblock_down(name+'.2ch.down', x, channels=ch, use_bias=False, is_training=is_training)\n",
        "            #x = dropout(x, keep_prob=kp1)\n",
        "            x = bottleneck_resblock(name+'.2ch', x, None, channels=ch, use_bias=False, is_training=is_training)\n",
        "            x = dropout(x, keep_prob=kp1)\n",
        "            print('after resdown1', x)\n",
        "            #x = dropout(x, keep_prob=kp2)\n",
        "            # Non-Local Block\n",
        "            x = self_attention_2(name+'.sa', x, channels=ch)\n",
        "            print('after sa', x)\n",
        "            #x = dropout(x, keep_prob=kp2)\n",
        "            ch = ch * 2\n",
        "            x = bottleneck_resblock_down(name+'.4ch.down', x, channels=ch, use_bias=False, is_training=is_training)\n",
        "            #x = dropout(x, keep_prob=kp2)\n",
        "            x = bottleneck_resblock(name+'.4ch', x, None, channels=ch, use_bias=False, is_training=is_training)\n",
        "            x = dropout(x, keep_prob=kp1)\n",
        "            print('after resdown2', x)    \n",
        "            #x = dropout(x, keep_prob=kp2)\n",
        "            ch = ch * 2\n",
        "            x = bottleneck_resblock_down(name+'.8ch.down', x, channels=ch, use_bias=False, is_training=is_training)\n",
        "            #x = dropout(x, keep_prob=kp2)\n",
        "            x = bottleneck_resblock(name+'.8ch', x, None, channels=ch, use_bias=False, is_training=is_training)\n",
        "            x = dropout(x, keep_prob=kp2)\n",
        "            print('after resdown4', x)\n",
        "            #x = dropout(x, keep_prob=kp2)\n",
        "            ch = ch * 2\n",
        "            x = bottleneck_resblock_down(name+'.16ch.down1', x, channels=ch, use_bias=False, is_training=is_training)\n",
        "            #x = dropout(x, keep_prob=kp2)\n",
        "            x = bottleneck_resblock(name+'.16ch.1', x, None, channels=ch, use_bias=False, is_training=is_training)\n",
        "            x = dropout(x, keep_prob=kp2)\n",
        "            print('after resdown8', x)\n",
        "            #x = dropout(x, keep_prob=kp2)\n",
        "            x = bottleneck_resblock_down(name+'.16ch.down2', x, channels=ch, use_bias=False, is_training=is_training)\n",
        "            #x = dropout(x, keep_prob=kp2)\n",
        "            x = bottleneck_resblock(name+'.16ch.2', x, None, channels=ch, use_bias=False, is_training=is_training)\n",
        "            x = dropout(x, keep_prob=kp2)\n",
        "            print('after resdown16', x)\n",
        "            #x = dropout(x, keep_prob=kp2)\n",
        "            x = nonlinearity(x)\n",
        "            output2 =  tf.reduce_sum(x, axis=[1,2])\n",
        "            embedding = linear(name+'.embed', NUM_CLASSES, int(output2.shape[-1]), tf.one_hot(labels, NUM_CLASSES), weight_init=tf.random_uniform_initializer(-.1,.1))\n",
        "            output_wgan = linear('Discriminator%i.Output'%ID, ch, 1, output2)\n",
        "            output_wgan = tf.reshape(output_wgan, [-1])+tf.reduce_sum(embedding*output2, 1)    #conrresponding to D\n",
        "            if CONDITIONAL and ACGAN:\n",
        "                output_acgan = linear('Discriminator%i.ACGANOutput'%ID, ch, 10, output2)\n",
        "                return output_wgan, output2, output_acgan\n",
        "            else:\n",
        "                return output_wgan, output2, None  # two layers' of output\n",
        "\n",
        "#Generator=Bottleneck_Generator\n",
        "#Discriminator=Bottleneck_Discriminator"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvRrryfiZnE_"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import tflib as lib\n",
        "import tflib.custom_ops.custom_ops\n",
        "from typing import Any, List, Tuple, Union\n",
        "IMPL='ref'\n",
        "#IMPL='cuda'\n",
        "from pathlib import Path\n",
        "def _get_plugin(op_name):\n",
        "    cuda_src_dir =os.path.join(os.path.dirname(os.path.realpath('__file__')),'tflib/custom_ops/')\n",
        "    return tflib.custom_ops.custom_ops.get_plugin( cuda_src_dir + op_name + '.cu')\n",
        "class EasyDict(dict):\n",
        "    \"\"\"Convenience class that behaves like a dict but allows access with the attribute syntax.\"\"\"\n",
        "\n",
        "    def __getattr__(self, name: str) -> Any:\n",
        "        try:\n",
        "            return self[name]\n",
        "        except KeyError:\n",
        "            raise AttributeError(name)\n",
        "\n",
        "    def __setattr__(self, name: str, value: Any) -> None:\n",
        "        self[name] = value\n",
        "\n",
        "    def __delattr__(self, name: str) -> None:\n",
        "        del self[name]\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "activation_funcs = {\n",
        "    'linear':   EasyDict(func=lambda x, **_:        x,                          def_alpha=None, def_gain=1.0,           cuda_idx=1, ref='y', zero_2nd_grad=True),\n",
        "    'relu':     EasyDict(func=lambda x, **_:        tf.nn.relu(x),              def_alpha=None, def_gain=np.sqrt(2),    cuda_idx=2, ref='y', zero_2nd_grad=True),\n",
        "    'lrelu':    EasyDict(func=lambda x, alpha, **_: tf.nn.leaky_relu(x, alpha), def_alpha=0.2,  def_gain=np.sqrt(2),    cuda_idx=3, ref='y', zero_2nd_grad=True),\n",
        "    'tanh':     EasyDict(func=lambda x, **_:        tf.nn.tanh(x),              def_alpha=None, def_gain=1.0,           cuda_idx=4, ref='y', zero_2nd_grad=False),\n",
        "    'sigmoid':  EasyDict(func=lambda x, **_:        tf.nn.sigmoid(x),           def_alpha=None, def_gain=1.0,           cuda_idx=5, ref='y', zero_2nd_grad=False),\n",
        "    'elu':      EasyDict(func=lambda x, **_:        tf.nn.elu(x),               def_alpha=None, def_gain=1.0,           cuda_idx=6, ref='y', zero_2nd_grad=False),\n",
        "    'selu':     EasyDict(func=lambda x, **_:        tf.nn.selu(x),              def_alpha=None, def_gain=1.0,           cuda_idx=7, ref='y', zero_2nd_grad=False),\n",
        "    'softplus': EasyDict(func=lambda x, **_:        tf.nn.softplus(x),          def_alpha=None, def_gain=1.0,           cuda_idx=8, ref='y', zero_2nd_grad=False),\n",
        "    'swish':    EasyDict(func=lambda x, **_:        tf.nn.sigmoid(x) * x,       def_alpha=None, def_gain=np.sqrt(2),    cuda_idx=9, ref='x', zero_2nd_grad=False),\n",
        "}\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def lerp(a, b, t):\n",
        "    \"\"\"Linear interpolation.\"\"\"\n",
        "    return a + (b - a) * t\n",
        "        \n",
        "def is_tf_expression(x):\n",
        "    \"\"\"Check whether the input is a valid Tensorflow expression, i.e., Tensorflow Tensor, Variable, or Operation.\"\"\"\n",
        "    return isinstance(x, (tf.Tensor, tf.Variable, tf.Operation))\n",
        "    \n",
        "def get_weight(name, shape, gain=1, use_wscale=True, lrmul=1):\n",
        "    fan_in = np.prod(shape[:-1]) # [kernel, kernel, fmaps_in, fmaps_out] or [in, out]\n",
        "    he_std = gain / np.sqrt(fan_in) # He init\n",
        "\n",
        "    # Equalized learning rate and custom learning rate multiplier.\n",
        "    if use_wscale:\n",
        "        init_std = 1.0 / lrmul\n",
        "        runtime_coef = he_std * lrmul\n",
        "    else:\n",
        "        init_std = he_std / lrmul\n",
        "        runtime_coef = lrmul\n",
        "\n",
        "    # Create variable.\n",
        "    init = tf.initializers.random_normal(0, init_std)\n",
        "    return lib.get_param(name, shape=shape, initializer=init) * runtime_coef\n",
        "\n",
        "\n",
        "def upsample_2d(x, k=None, factor=2, gain=1, data_format='NCHW', impl=IMPL):\n",
        "    r\"\"\"Upsample a batch of 2D images with the given filter.\n",
        "\n",
        "    Accepts a batch of 2D images of the shape `[N, C, H, W]` or `[N, H, W, C]`\n",
        "    and upsamples each image with the given filter. The filter is normalized so that\n",
        "    if the input pixels are constant, they will be scaled by the specified `gain`.\n",
        "    Pixels outside the image are assumed to be zero, and the filter is padded with\n",
        "    zeros so that its shape is a multiple of the upsampling factor.\n",
        "\n",
        "    Args:\n",
        "        x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n",
        "        k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n",
        "                      The default is `[1] * factor`, which corresponds to nearest-neighbor\n",
        "                      upsampling.\n",
        "        factor:       Integer upsampling factor (default: 2).\n",
        "        gain:         Scaling factor for signal magnitude (default: 1.0).\n",
        "        data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n",
        "        impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n",
        "\n",
        "    Returns:\n",
        "        Tensor of the shape `[N, C, H * factor, W * factor]` or\n",
        "        `[N, H * factor, W * factor, C]`, and same datatype as `x`.\n",
        "    \"\"\"\n",
        "\n",
        "    assert isinstance(factor, int) and factor >= 1\n",
        "    if k is None:\n",
        "        k = [1] * factor\n",
        "    k = _setup_kernel(k) * (gain * (factor ** 2))\n",
        "    p = k.shape[0] - factor\n",
        "    return _simple_upfirdn_2d(x, k, up=factor, pad0=(p+1)//2+factor-1, pad1=p//2, data_format=data_format, impl=impl)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def downsample_2d(x, k=None, factor=2, gain=1, data_format='NCHW', impl=IMPL):\n",
        "    r\"\"\"Downsample a batch of 2D images with the given filter.\n",
        "\n",
        "    Accepts a batch of 2D images of the shape `[N, C, H, W]` or `[N, H, W, C]`\n",
        "    and downsamples each image with the given filter. The filter is normalized so that\n",
        "    if the input pixels are constant, they will be scaled by the specified `gain`.\n",
        "    Pixels outside the image are assumed to be zero, and the filter is padded with\n",
        "    zeros so that its shape is a multiple of the downsampling factor.\n",
        "\n",
        "    Args:\n",
        "        x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n",
        "        k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n",
        "                      The default is `[1] * factor`, which corresponds to average pooling.\n",
        "        factor:       Integer downsampling factor (default: 2).\n",
        "        gain:         Scaling factor for signal magnitude (default: 1.0).\n",
        "        data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n",
        "        impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n",
        "\n",
        "    Returns:\n",
        "        Tensor of the shape `[N, C, H // factor, W // factor]` or\n",
        "        `[N, H // factor, W // factor, C]`, and same datatype as `x`.\n",
        "    \"\"\"\n",
        "\n",
        "    assert isinstance(factor, int) and factor >= 1\n",
        "    if k is None:\n",
        "        k = [1] * factor\n",
        "    k = _setup_kernel(k) * gain\n",
        "    p = k.shape[0] - factor\n",
        "    return _simple_upfirdn_2d(x, k, down=factor, pad0=(p+1)//2, pad1=p//2, data_format=data_format, impl=impl)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def upsample_conv_2d(x, w, k=None, factor=2, gain=1, data_format='NCHW', impl=IMPL):\n",
        "    r\"\"\"Fused `upsample_2d()` followed by `tf.nn.conv2d()`.\n",
        "\n",
        "    Padding is performed only once at the beginning, not between the operations.\n",
        "    The fused op is considerably more efficient than performing the same calculation\n",
        "    using standard TensorFlow ops. It supports gradients of arbitrary order.\n",
        "\n",
        "    Args:\n",
        "        x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n",
        "        w:            Weight tensor of the shape `[filterH, filterW, inChannels, outChannels]`.\n",
        "                      Grouped convolution can be performed by `inChannels = x.shape[0] // numGroups`.\n",
        "        k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n",
        "                      The default is `[1] * factor`, which corresponds to nearest-neighbor\n",
        "                      upsampling.\n",
        "        factor:       Integer upsampling factor (default: 2).\n",
        "        gain:         Scaling factor for signal magnitude (default: 1.0).\n",
        "        data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n",
        "        impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n",
        "\n",
        "    Returns:\n",
        "        Tensor of the shape `[N, C, H * factor, W * factor]` or\n",
        "        `[N, H * factor, W * factor, C]`, and same datatype as `x`.\n",
        "    \"\"\"\n",
        "\n",
        "    assert isinstance(factor, int) and factor >= 1\n",
        "\n",
        "    # Check weight shape.\n",
        "    w = tf.convert_to_tensor(w)\n",
        "    assert w.shape.rank == 4\n",
        "    convH = w.shape[0].value\n",
        "    convW = w.shape[1].value\n",
        "    inC = _shape(w, 2)\n",
        "    outC = _shape(w, 3)\n",
        "    assert convW == convH\n",
        "\n",
        "    # Setup filter kernel.\n",
        "    if k is None:\n",
        "        k = [1] * factor\n",
        "    k = _setup_kernel(k) * (gain * (factor ** 2))\n",
        "    p = (k.shape[0] - factor) - (convW - 1)\n",
        "\n",
        "    # Determine data dimensions.\n",
        "    if data_format == 'NCHW':\n",
        "        stride = [1, 1, factor, factor]\n",
        "        output_shape = [_shape(x, 0), outC, (_shape(x, 2) - 1) * factor + convH, (_shape(x, 3) - 1) * factor + convW]\n",
        "        num_groups = _shape(x, 1) // inC\n",
        "    else:\n",
        "        stride = [1, factor, factor, 1]\n",
        "        output_shape = [_shape(x, 0), (_shape(x, 1) - 1) * factor + convH, (_shape(x, 2) - 1) * factor + convW, outC]\n",
        "        num_groups = _shape(x, 3) // inC\n",
        "\n",
        "    # Transpose weights.\n",
        "    w = tf.reshape(w, [convH, convW, inC, num_groups, -1])\n",
        "    w = tf.transpose(w[::-1, ::-1], [0, 1, 4, 3, 2])\n",
        "    w = tf.reshape(w, [convH, convW, -1, num_groups * inC])\n",
        "\n",
        "    # Execute.\n",
        "    x = tf.nn.conv2d_transpose(x, w, output_shape=output_shape, strides=stride, padding='VALID', data_format=data_format)\n",
        "    return _simple_upfirdn_2d(x, k, pad0=(p+1)//2+factor-1, pad1=p//2+1, data_format=data_format, impl=impl)\n",
        "\n",
        "def _shape(tf_expr, dim_idx):\n",
        "    if tf_expr.shape.rank is not None:\n",
        "        dim = tf_expr.shape[dim_idx].value\n",
        "        if dim is not None:\n",
        "            return dim\n",
        "    return tf.shape(tf_expr)[dim_idx]\n",
        "\n",
        "def _setup_kernel(k):\n",
        "    k = np.asarray(k, dtype=np.float32)\n",
        "    if k.ndim == 1:\n",
        "        k = np.outer(k, k)\n",
        "    k /= np.sum(k)\n",
        "    assert k.ndim == 2\n",
        "    assert k.shape[0] == k.shape[1]\n",
        "    return k\n",
        "\n",
        "\n",
        "def upfirdn_2d(x, k, upx=1, upy=1, downx=1, downy=1, padx0=0, padx1=0, pady0=0, pady1=0, impl=IMPL):\n",
        "    r\"\"\"Pad, upsample, FIR filter, and downsample a batch of 2D images.\n",
        "\n",
        "    Accepts a batch of 2D images of the shape `[majorDim, inH, inW, minorDim]`\n",
        "    and performs the following operations for each image, batched across\n",
        "    `majorDim` and `minorDim`:\n",
        "\n",
        "    1. Pad the image with zeros by the specified number of pixels on each side\n",
        "       (`padx0`, `padx1`, `pady0`, `pady1`). Specifying a negative value\n",
        "       corresponds to cropping the image.\n",
        "\n",
        "    2. Upsample the image by inserting the zeros after each pixel (`upx`, `upy`).\n",
        "\n",
        "    3. Convolve the image with the specified 2D FIR filter (`k`), shrinking the\n",
        "       image so that the footprint of all output pixels lies within the input image.\n",
        "\n",
        "    4. Downsample the image by throwing away pixels (`downx`, `downy`).\n",
        "\n",
        "    This sequence of operations bears close resemblance to scipy.signal.upfirdn().\n",
        "    The fused op is considerably more efficient than performing the same calculation\n",
        "    using standard TensorFlow ops. It supports gradients of arbitrary order.\n",
        "\n",
        "    Args:\n",
        "        x:      Input tensor of the shape `[majorDim, inH, inW, minorDim]`.\n",
        "        k:      2D FIR filter of the shape `[firH, firW]`.\n",
        "        upx:    Integer upsampling factor along the X-axis (default: 1).\n",
        "        upy:    Integer upsampling factor along the Y-axis (default: 1).\n",
        "        downx:  Integer downsampling factor along the X-axis (default: 1).\n",
        "        downy:  Integer downsampling factor along the Y-axis (default: 1).\n",
        "        padx0:  Number of pixels to pad on the left side (default: 0).\n",
        "        padx1:  Number of pixels to pad on the right side (default: 0).\n",
        "        pady0:  Number of pixels to pad on the top side (default: 0).\n",
        "        pady1:  Number of pixels to pad on the bottom side (default: 0).\n",
        "        impl:   Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n",
        "\n",
        "    Returns:\n",
        "        Tensor of the shape `[majorDim, outH, outW, minorDim]`, and same datatype as `x`.\n",
        "    \"\"\"\n",
        "\n",
        "    impl_dict = {\n",
        "        'ref':  _upfirdn_2d_ref,\n",
        "        'cuda': _upfirdn_2d_cuda,\n",
        "    }\n",
        "    return impl_dict[impl](x=x, k=k, upx=upx, upy=upy, downx=downx, downy=downy, padx0=padx0, padx1=padx1, pady0=pady0, pady1=pady1)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "def _upfirdn_2d_cuda(x, k, upx, upy, downx, downy, padx0, padx1, pady0, pady1):\n",
        "    \"\"\"Fast CUDA implementation of `upfirdn_2d()` using custom ops.\"\"\"\n",
        "\n",
        "    x = tf.convert_to_tensor(x)\n",
        "    k = np.asarray(k, dtype=np.float32)\n",
        "    majorDim, inH, inW, minorDim = x.shape.as_list()\n",
        "    kernelH, kernelW = k.shape\n",
        "    assert inW >= 1 and inH >= 1\n",
        "    assert kernelW >= 1 and kernelH >= 1\n",
        "    assert isinstance(upx, int) and isinstance(upy, int)\n",
        "    assert isinstance(downx, int) and isinstance(downy, int)\n",
        "    assert isinstance(padx0, int) and isinstance(padx1, int)\n",
        "    assert isinstance(pady0, int) and isinstance(pady1, int)\n",
        "\n",
        "    outW = (inW * upx + padx0 + padx1 - kernelW) // downx + 1\n",
        "    outH = (inH * upy + pady0 + pady1 - kernelH) // downy + 1\n",
        "    assert outW >= 1 and outH >= 1\n",
        "\n",
        "    kc = tf.constant(k, dtype=x.dtype)\n",
        "    gkc = tf.constant(k[::-1, ::-1], dtype=x.dtype)\n",
        "    gpadx0 = kernelW - padx0 - 1\n",
        "    gpady0 = kernelH - pady0 - 1\n",
        "    gpadx1 = inW * upx - outW * downx + padx0 - upx + 1\n",
        "    gpady1 = inH * upy - outH * downy + pady0 - upy + 1\n",
        "\n",
        "    @tf.custom_gradient\n",
        "    def func(x):\n",
        "        y = _get_plugin('upfirdn_2d').up_fir_dn2d(x=x, k=kc, upx=upx, upy=upy, downx=downx, downy=downy, padx0=padx0, padx1=padx1, pady0=pady0, pady1=pady1)\n",
        "        y.set_shape([majorDim, outH, outW, minorDim])\n",
        "        @tf.custom_gradient\n",
        "        def grad(dy):\n",
        "            dx = _get_plugin('upfirdn_2d').up_fir_dn2d(x=dy, k=gkc, upx=downx, upy=downy, downx=upx, downy=upy, padx0=gpadx0, padx1=gpadx1, pady0=gpady0, pady1=gpady1)\n",
        "            dx.set_shape([majorDim, inH, inW, minorDim])\n",
        "            return dx, func\n",
        "        return y, grad\n",
        "    return func(x)\n",
        "\n",
        "def _upfirdn_2d_ref(x, k, upx, upy, downx, downy, padx0, padx1, pady0, pady1):\n",
        "    \"\"\"Slow reference implementation of `upfirdn_2d()` using standard TensorFlow ops.\"\"\"\n",
        "\n",
        "    x = tf.convert_to_tensor(x)\n",
        "    k = np.asarray(k, dtype=np.float32)\n",
        "    assert x.shape.rank == 4\n",
        "    inH = x.shape[1].value\n",
        "    inW = x.shape[2].value\n",
        "    minorDim = _shape(x, 3)\n",
        "    kernelH, kernelW = k.shape\n",
        "    assert inW >= 1 and inH >= 1\n",
        "    assert kernelW >= 1 and kernelH >= 1\n",
        "    assert isinstance(upx, int) and isinstance(upy, int)\n",
        "    assert isinstance(downx, int) and isinstance(downy, int)\n",
        "    assert isinstance(padx0, int) and isinstance(padx1, int)\n",
        "    assert isinstance(pady0, int) and isinstance(pady1, int)\n",
        "\n",
        "    # Upsample (insert zeros).\n",
        "    x = tf.reshape(x, [-1, inH, 1, inW, 1, minorDim])\n",
        "    x = tf.pad(x, [[0, 0], [0, 0], [0, upy - 1], [0, 0], [0, upx - 1], [0, 0]])\n",
        "    x = tf.reshape(x, [-1, inH * upy, inW * upx, minorDim])\n",
        "\n",
        "    # Pad (crop if negative).\n",
        "    x = tf.pad(x, [[0, 0], [max(pady0, 0), max(pady1, 0)], [max(padx0, 0), max(padx1, 0)], [0, 0]])\n",
        "    x = x[:, max(-pady0, 0) : x.shape[1].value - max(-pady1, 0), max(-padx0, 0) : x.shape[2].value - max(-padx1, 0), :]\n",
        "\n",
        "    # Convolve with filter.\n",
        "    x = tf.transpose(x, [0, 3, 1, 2])\n",
        "    x = tf.reshape(x, [-1, 1, inH * upy + pady0 + pady1, inW * upx + padx0 + padx1])\n",
        "    w = tf.constant(k[::-1, ::-1, np.newaxis, np.newaxis], dtype=x.dtype)\n",
        "    x = tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='VALID', data_format='NCHW')\n",
        "    x = tf.reshape(x, [-1, minorDim, inH * upy + pady0 + pady1 - kernelH + 1, inW * upx + padx0 + padx1 - kernelW + 1])\n",
        "    x = tf.transpose(x, [0, 2, 3, 1])\n",
        "\n",
        "    # Downsample (throw away pixels).\n",
        "    return x[:, ::downy, ::downx, :]\n",
        "\n",
        "def _simple_upfirdn_2d(x, k, up=1, down=1, pad0=0, pad1=0, data_format='NCHW', impl=IMPL):\n",
        "    assert data_format in ['NCHW', 'NHWC']\n",
        "    assert x.shape.rank == 4\n",
        "    y = x\n",
        "    if data_format == 'NCHW':\n",
        "        y = tf.reshape(y, [-1, _shape(y, 2), _shape(y, 3), 1])\n",
        "    y = upfirdn_2d(y, k, upx=up, upy=up, downx=down, downy=down, padx0=pad0, padx1=pad1, pady0=pad0, pady1=pad1, impl=impl)\n",
        "    if data_format == 'NCHW':\n",
        "        y = tf.reshape(y, [-1, _shape(x, 1), _shape(y, 1), _shape(y, 2)])\n",
        "    return y\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def conv_downsample_2d(x, w, k=None, factor=2, gain=1, data_format='NCHW', impl=IMPL):\n",
        "    r\"\"\"Fused `tf.nn.conv2d()` followed by `downsample_2d()`.\n",
        "\n",
        "    Padding is performed only once at the beginning, not between the operations.\n",
        "    The fused op is considerably more efficient than performing the same calculation\n",
        "    using standard TensorFlow ops. It supports gradients of arbitrary order.\n",
        "\n",
        "    Args:\n",
        "        x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n",
        "        w:            Weight tensor of the shape `[filterH, filterW, inChannels, outChannels]`.\n",
        "                      Grouped convolution can be performed by `inChannels = x.shape[0] // numGroups`.\n",
        "        k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n",
        "                      The default is `[1] * factor`, which corresponds to average pooling.\n",
        "        factor:       Integer downsampling factor (default: 2).\n",
        "        gain:         Scaling factor for signal magnitude (default: 1.0).\n",
        "        data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n",
        "        impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n",
        "\n",
        "    Returns:\n",
        "        Tensor of the shape `[N, C, H // factor, W // factor]` or\n",
        "        `[N, H // factor, W // factor, C]`, and same datatype as `x`.\n",
        "    \"\"\"\n",
        "\n",
        "    assert isinstance(factor, int) and factor >= 1\n",
        "    w = tf.convert_to_tensor(w)\n",
        "    convH, convW, _inC, _outC = w.shape.as_list()\n",
        "    assert convW == convH\n",
        "    if k is None:\n",
        "        k = [1] * factor\n",
        "    k = _setup_kernel(k) * gain\n",
        "    p = (k.shape[0] - factor) + (convW - 1)\n",
        "    if data_format == 'NCHW':\n",
        "        s = [1, 1, factor, factor]\n",
        "    else:\n",
        "        s = [1, factor, factor, 1]\n",
        "    x = _simple_upfirdn_2d(x, k, pad0=(p+1)//2, pad1=p//2, data_format=data_format, impl=impl)\n",
        "    return tf.nn.conv2d(x, w, strides=s, padding='VALID', data_format=data_format)\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Fully-connected layer.\n",
        "\n",
        "def dense_layer(name, x, fmaps, gain=1, use_wscale=True, lrmul=1):\n",
        "    if len(x.shape) > 2:\n",
        "        x = tf.reshape(x, [-1, np.prod([d.value for d in x.shape[1:]])])\n",
        "    w = get_weight(name+'.Weight', [x.shape[1].value, fmaps], gain=gain, use_wscale=use_wscale, lrmul=lrmul)\n",
        "    w = tf.cast(w, x.dtype)\n",
        "    return tf.matmul(x, w)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Convolution layer with optional upsampling or downsampling.\n",
        "\n",
        "def conv2d_layer(name, x, fmaps, kernel, up=False, down=False, resample_kernel=None, gain=1, use_wscale=True, lrmul=1):\n",
        "    assert not (up and down)\n",
        "    assert kernel >= 1 and kernel % 2 == 1\n",
        "    w = get_weight(name+'.Filters', [kernel, kernel, x.shape[1].value, fmaps], gain=gain, use_wscale=use_wscale, lrmul=lrmul)\n",
        "    if up:\n",
        "        x = upsample_conv_2d(x, tf.cast(w, x.dtype), data_format='NCHW', k=resample_kernel)\n",
        "    elif down:\n",
        "        x = conv_downsample_2d(x, tf.cast(w, x.dtype), data_format='NCHW', k=resample_kernel)\n",
        "    else:\n",
        "        x = tf.nn.conv2d(x, tf.cast(w, x.dtype), data_format='NCHW', strides=[1,1,1,1], padding='SAME')\n",
        "    return x\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Apply bias and activation func.\n",
        "def fused_bias_act(x, b=None, axis=1, act='linear', alpha=None, gain=None, impl=IMPL):\n",
        "    r\"\"\"Fused bias and activation function.\n",
        "\n",
        "    Adds bias `b` to activation tensor `x`, evaluates activation function `act`,\n",
        "    and scales the result by `gain`. Each of the steps is optional. In most cases,\n",
        "    the fused op is considerably more efficient than performing the same calculation\n",
        "    using standard TensorFlow ops. It supports first and second order gradients,\n",
        "    but not third order gradients.\n",
        "\n",
        "    Args:\n",
        "        x:      Input activation tensor. Can have any shape, but if `b` is defined, the\n",
        "                dimension corresponding to `axis`, as well as the rank, must be known.\n",
        "        b:      Bias vector, or `None` to disable. Must be a 1D tensor of the same type\n",
        "                as `x`. The shape must be known, and it must match the dimension of `x`\n",
        "                corresponding to `axis`.\n",
        "        axis:   The dimension in `x` corresponding to the elements of `b`.\n",
        "                The value of `axis` is ignored if `b` is not specified.\n",
        "        act:    Name of the activation function to evaluate, or `\"linear\"` to disable.\n",
        "                Can be e.g. `\"relu\"`, `\"lrelu\"`, `\"tanh\"`, `\"sigmoid\"`, `\"swish\"`, etc.\n",
        "                See `activation_funcs` for a full list. `None` is not allowed.\n",
        "        alpha:  Shape parameter for the activation function, or `None` to use the default.\n",
        "        gain:   Scaling factor for the output tensor, or `None` to use default.\n",
        "                See `activation_funcs` for the default scaling of each activation function.\n",
        "                If unsure, consider specifying `1.0`.\n",
        "        impl:   Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n",
        "\n",
        "    Returns:\n",
        "        Tensor of the same shape and datatype as `x`.\n",
        "    \"\"\"\n",
        "\n",
        "    impl_dict = {\n",
        "        'ref':  _fused_bias_act_ref,\n",
        "        'cuda': _fused_bias_act_cuda,\n",
        "    }\n",
        "    return impl_dict[impl](x=x, b=b, axis=axis, act=act, alpha=alpha, gain=gain)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "def _fused_bias_act_cuda(x, b, axis, act, alpha, gain):\n",
        "    \"\"\"Fast CUDA implementation of `fused_bias_act()` using custom ops.\"\"\"\n",
        "\n",
        "    # Validate arguments.\n",
        "    x = tf.convert_to_tensor(x)\n",
        "    empty_tensor = tf.constant([], dtype=x.dtype)\n",
        "    b = tf.convert_to_tensor(b) if b is not None else empty_tensor\n",
        "    act_spec = activation_funcs[act]\n",
        "    assert b.shape.rank == 1 and (b.shape[0] == 0 or b.shape[0] == x.shape[axis])\n",
        "    assert b.shape[0] == 0 or 0 <= axis < x.shape.rank\n",
        "    if alpha is None:\n",
        "        alpha = act_spec.def_alpha\n",
        "    if gain is None:\n",
        "        gain = act_spec.def_gain\n",
        "\n",
        "    # Special cases.\n",
        "    if act == 'linear' and b is None and gain == 1.0:\n",
        "        return x\n",
        "    if act_spec.cuda_idx is None:\n",
        "        return _fused_bias_act_ref(x=x, b=b, axis=axis, act=act, alpha=alpha, gain=gain)\n",
        "\n",
        "    # CUDA kernel.\n",
        "    cuda_kernel = _get_plugin('fused_bias_act').fused_bias_act\n",
        "    cuda_kwargs = dict(axis=axis, act=act_spec.cuda_idx, alpha=alpha, gain=gain)\n",
        "\n",
        "    # Forward pass: y = func(x, b).\n",
        "    def func_y(x, b):\n",
        "        y = cuda_kernel(x=x, b=b, ref=empty_tensor, grad=0, **cuda_kwargs)\n",
        "        y.set_shape(x.shape)\n",
        "        return y\n",
        "\n",
        "    # Backward pass: dx, db = grad(dy, x, y)\n",
        "    def grad_dx(dy, x, y):\n",
        "        ref = {'x': x, 'y': y}[act_spec.ref]\n",
        "        dx = cuda_kernel(x=dy, b=empty_tensor, ref=ref, grad=1, **cuda_kwargs)\n",
        "        dx.set_shape(x.shape)\n",
        "        return dx\n",
        "    def grad_db(dx):\n",
        "        if b.shape[0] == 0:\n",
        "            return empty_tensor\n",
        "        db = dx\n",
        "        if axis < x.shape.rank - 1:\n",
        "            db = tf.reduce_sum(db, list(range(axis + 1, x.shape.rank)))\n",
        "        if axis > 0:\n",
        "            db = tf.reduce_sum(db, list(range(axis)))\n",
        "        db.set_shape(b.shape)\n",
        "        return db\n",
        "\n",
        "    # Second order gradients: d_dy, d_x = grad2(d_dx, d_db, x, y)\n",
        "    def grad2_d_dy(d_dx, d_db, x, y):\n",
        "        ref = {'x': x, 'y': y}[act_spec.ref]\n",
        "        d_dy = cuda_kernel(x=d_dx, b=d_db, ref=ref, grad=1, **cuda_kwargs)\n",
        "        d_dy.set_shape(x.shape)\n",
        "        return d_dy\n",
        "    def grad2_d_x(d_dx, d_db, x, y):\n",
        "        ref = {'x': x, 'y': y}[act_spec.ref]\n",
        "        d_x = cuda_kernel(x=d_dx, b=d_db, ref=ref, grad=2, **cuda_kwargs)\n",
        "        d_x.set_shape(x.shape)\n",
        "        return d_x\n",
        "\n",
        "    # Fast version for piecewise-linear activation funcs.\n",
        "    @tf.custom_gradient\n",
        "    def func_zero_2nd_grad(x, b):\n",
        "        y = func_y(x, b)\n",
        "        @tf.custom_gradient\n",
        "        def grad(dy):\n",
        "            dx = grad_dx(dy, x, y)\n",
        "            db = grad_db(dx)\n",
        "            def grad2(d_dx, d_db):\n",
        "                d_dy = grad2_d_dy(d_dx, d_db, x, y)\n",
        "                return d_dy\n",
        "            return (dx, db), grad2\n",
        "        return y, grad\n",
        "\n",
        "    # Slow version for general activation funcs.\n",
        "    @tf.custom_gradient\n",
        "    def func_nonzero_2nd_grad(x, b):\n",
        "        y = func_y(x, b)\n",
        "        def grad_wrap(dy):\n",
        "            @tf.custom_gradient\n",
        "            def grad_impl(dy, x):\n",
        "                dx = grad_dx(dy, x, y)\n",
        "                db = grad_db(dx)\n",
        "                def grad2(d_dx, d_db):\n",
        "                    d_dy = grad2_d_dy(d_dx, d_db, x, y)\n",
        "                    d_x = grad2_d_x(d_dx, d_db, x, y)\n",
        "                    return d_dy, d_x\n",
        "                return (dx, db), grad2\n",
        "            return grad_impl(dy, x)\n",
        "        return y, grad_wrap\n",
        "\n",
        "    # Which version to use?\n",
        "    if act_spec.zero_2nd_grad:\n",
        "        return func_zero_2nd_grad(x, b)\n",
        "    return func_nonzero_2nd_grad(x, b)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def _fused_bias_act_ref(x, b, axis, act, alpha, gain):\n",
        "    \"\"\"Slow reference implementation of `fused_bias_act()` using standard TensorFlow ops.\"\"\"\n",
        "\n",
        "    # Validate arguments.\n",
        "    x = tf.convert_to_tensor(x)\n",
        "    b = tf.convert_to_tensor(b) if b is not None else tf.constant([], dtype=x.dtype)\n",
        "    act_spec = activation_funcs[act]\n",
        "    assert b.shape.rank == 1 and (b.shape[0] == 0 or b.shape[0] == x.shape[axis])\n",
        "    assert b.shape[0] == 0 or 0 <= axis < x.shape.rank\n",
        "    if alpha is None:\n",
        "        alpha = act_spec.def_alpha\n",
        "    if gain is None:\n",
        "        gain = act_spec.def_gain\n",
        "\n",
        "    # Add bias.\n",
        "    if b.shape[0] != 0:\n",
        "        x += tf.reshape(b, [-1 if i == axis else 1 for i in range(x.shape.rank)])\n",
        "\n",
        "    # Evaluate activation function.\n",
        "    x = act_spec.func(x, alpha=alpha)\n",
        "\n",
        "    # Scale by gain.\n",
        "    if gain != 1:\n",
        "        x *= gain\n",
        "    return x\n",
        "\n",
        "def apply_bias_act(name, x, act='linear', alpha=None, gain=None, lrmul=1):\n",
        "    b = lib.get_param(name+'.Bias', shape=[x.shape[1]], initializer=tf.initializers.zeros()) * lrmul\n",
        "    return fused_bias_act(x, b=tf.cast(b, x.dtype), act=act, alpha=alpha, gain=gain)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Naive upsampling (nearest neighbor) and downsampling (average pooling).\n",
        "\n",
        "def naive_upsample_2d(x, factor=2):\n",
        "        _N, C, H, W = x.shape.as_list()\n",
        "        x = tf.reshape(x, [-1, C, H, 1, W, 1])\n",
        "        x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
        "        return tf.reshape(x, [-1, C, H * factor, W * factor])\n",
        "\n",
        "def naive_downsample_2d(x, factor=2):\n",
        "        _N, C, H, W = x.shape.as_list()\n",
        "        x = tf.reshape(x, [-1, C, H // factor, factor, W // factor, factor])\n",
        "        return tf.reduce_mean(x, axis=[3,5])\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Modulated convolution layer.\n",
        "\n",
        "def modulated_conv2d_layer(name, x, y, fmaps, kernel, up=False, down=False, demodulate=True, resample_kernel=None, gain=1, use_wscale=True, lrmul=1, fused_modconv=True):\n",
        "    assert not (up and down)\n",
        "    assert kernel >= 1 and kernel % 2 == 1\n",
        "\n",
        "    # Get weight.\n",
        "    w = get_weight(name+'.weight', [kernel, kernel, x.shape[1].value, fmaps], gain=gain, use_wscale=use_wscale, lrmul=lrmul)\n",
        "    ww = w[np.newaxis] # [BkkIO] Introduce minibatch dimension.\n",
        "\n",
        "    # Modulate.\n",
        "    s = dense_layer(name+'.mod_weight', y, fmaps=x.shape[1].value) # [BI] Transform incoming W to style.\n",
        "    s = apply_bias_act(name+'.mod_bias', s) + 1 # [BI] Add bias (initially 1).\n",
        "    ww *= tf.cast(s[:, np.newaxis, np.newaxis, :, np.newaxis], w.dtype) # [BkkIO] Scale input feature maps.\n",
        "\n",
        "    # Demodulate.\n",
        "    if demodulate:\n",
        "        d = tf.rsqrt(tf.reduce_sum(tf.square(ww), axis=[1,2,3]) + 1e-8) # [BO] Scaling factor.\n",
        "        ww *= d[:, np.newaxis, np.newaxis, np.newaxis, :] # [BkkIO] Scale output feature maps.\n",
        "\n",
        "    # Reshape/scale input.\n",
        "    if fused_modconv:\n",
        "        x = tf.reshape(x, [1, -1, x.shape[2], x.shape[3]]) # Fused => reshape minibatch to convolution groups.\n",
        "        w = tf.reshape(tf.transpose(ww, [1, 2, 3, 0, 4]), [ww.shape[1], ww.shape[2], ww.shape[3], -1])\n",
        "    else:\n",
        "        x *= tf.cast(s[:, :, np.newaxis, np.newaxis], x.dtype) # [BIhw] Not fused => scale input activations.\n",
        "\n",
        "    # Convolution with optional up/downsampling.\n",
        "    if up:\n",
        "        x = upsample_conv_2d(x, tf.cast(w, x.dtype), data_format='NCHW', k=resample_kernel)\n",
        "    elif down:\n",
        "        x = conv_downsample_2d(x, tf.cast(w, x.dtype), data_format='NCHW', k=resample_kernel)\n",
        "    else:\n",
        "        x = tf.nn.conv2d(x, tf.cast(w, x.dtype), data_format='NCHW', strides=[1,1,1,1], padding='SAME')\n",
        "\n",
        "    # Reshape/scale output.\n",
        "    if fused_modconv:\n",
        "        x = tf.reshape(x, [-1, fmaps, x.shape[2], x.shape[3]]) # Fused => reshape convolution groups back to minibatch.\n",
        "    elif demodulate:\n",
        "        x *= tf.cast(d[:, :, np.newaxis, np.newaxis], x.dtype) # [BOhw] Not fused => scale output activations.\n",
        "    return x\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Minibatch standard deviation layer.\n",
        "def minibatch_stddev_layer(x, group_size=None, num_new_features=1):\n",
        "    if group_size is None:\n",
        "        group_size = tf.shape(x)[0]\n",
        "    else:\n",
        "        group_size = tf.minimum(group_size, tf.shape(x)[0]) # Minibatch must be divisible by (or smaller than) group_size.\n",
        "    G = group_size\n",
        "    F = num_new_features\n",
        "    _N, C, H, W = x.shape.as_list()\n",
        "    c = C // F\n",
        "    y = tf.cast(x, tf.float32)                # [NCHW]   Cast to FP32.\n",
        "    y = tf.reshape(y, [G, -1, F, c, H, W])    # [GnFcHW] Split minibatch N into n groups of size G, and channels C into F groups of size c.\n",
        "    y -= tf.reduce_mean(y, axis=0)            # [GnFcHW] Subtract mean over group.\n",
        "    y = tf.reduce_mean(tf.square(y), axis=0)  # [nFcHW]  Calc variance over group.\n",
        "    y = tf.sqrt(y + 1e-8)                     # [nFcHW]  Calc stddev over group.\n",
        "    y = tf.reduce_mean(y, axis=[2,3,4])       # [nF]     Take average over channels and pixels.\n",
        "    y = tf.cast(y, x.dtype)                   # [nF]     Cast back to original data type.\n",
        "    y = tf.reshape(y, [-1, F, 1, 1])          # [nF11]   Add missing dimensions.\n",
        "    y = tf.tile(y, [G, 1, H, W])              # [NFHW]   Replicate over group and pixels.\n",
        "    return tf.concat([x, y], axis=1)          # [NCHW]   Append to input as new channels.\n",
        "\n",
        "def normalize_2nd_moment(x, axis=1, eps=1e-8):\n",
        "    return x * tf.rsqrt(tf.reduce_mean(tf.square(x), axis=axis, keepdims=True) + eps)     \n",
        "def G_mapping(\n",
        "    name,\n",
        "    latents_in,                             # First input: Latent vectors (Z) [minibatch, latent_size].\n",
        "    labels_in,                              # Second input: Conditioning labels [minibatch, label_size].\n",
        "    latent_size             = 512,          # Latent vector (Z) dimensionality.\n",
        "    label_size              = NUM_CLASSES,            # Label dimensionality, 0 if no labels.\n",
        "    dlatent_size            = 512,          # Disentangled latent (W) dimensionality.\n",
        "    dlatent_broadcast       = None,         # Output disentangled latent (W) as [minibatch, dlatent_size] or [minibatch, dlatent_broadcast, dlatent_size].\n",
        "    mapping_layers          = 2,            # Number of mapping layers.\n",
        "    mapping_fmaps           = 512,          # Number of activations in the mapping layers.\n",
        "    mapping_lrmul           = 0.01,         # Learning rate multiplier for the mapping layers.\n",
        "    mapping_nonlinearity    = 'lrelu',      # Activation function: 'relu', 'lrelu', etc.\n",
        "    normalize_latents       = True,         # Normalize latent vectors (Z) before feeding them to the mapping layers?\n",
        "    dtype                   = 'float32',    # Data type to use for activations and outputs.\n",
        "    **_kwargs):                             # Ignore unrecognized keyword args.\n",
        "\n",
        "    act = mapping_nonlinearity\n",
        "\n",
        "    # Inputs.\n",
        "    latents_in.set_shape([None, latent_size])\n",
        "    labels_in.set_shape([None, label_size])\n",
        "    latents_in = tf.cast(latents_in, dtype)\n",
        "    labels_in = tf.cast(labels_in, dtype)\n",
        "    x = latents_in\n",
        "\n",
        "    # Normalize latents.\n",
        "    if normalize_latents:\n",
        "           x = normalize_2nd_moment(x)\n",
        "    # Embed labels and concatenate them with latents.\n",
        "    if label_size:\n",
        "            y = labels_in\n",
        "            y = apply_bias_act(name+'.embed.bias',dense_layer(name+'.embed.dense', y, fmaps=dlatent_size))\n",
        "            y = normalize_2nd_moment(y)\n",
        "            x = tf.concat([x, y], axis=1)\n",
        "\n",
        "    # Mapping layers.\n",
        "    for layer_idx in range(mapping_layers):\n",
        "            fmaps = dlatent_size if layer_idx == mapping_layers - 1 else mapping_fmaps\n",
        "            x = apply_bias_act(name+'.Bias_act%d' % layer_idx, dense_layer(name+'.Dense%d' % layer_idx, x, fmaps=fmaps, lrmul=mapping_lrmul), act=act, lrmul=mapping_lrmul)\n",
        "\n",
        "    # Broadcast.\n",
        "    if dlatent_broadcast is not None:\n",
        "            x = tf.tile(x[:, np.newaxis], [1, dlatent_broadcast, 1])\n",
        "\n",
        "    # Output.\n",
        "    assert x.dtype == tf.as_dtype(dtype)\n",
        "    return x\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# StyleGAN synthesis network with revised architecture (Figure 2d).\n",
        "# Implements progressive growing, but no skip connections or residual nets (Figure 7).\n",
        "# Used in configs B-D (Table 1).\n",
        "def random_normal(name, shape, dtype=tf.float32, update_noise=False):\n",
        "    noise=lib.get_param(name, shape=shape, dtype=dtype, initializer=tf.initializers.random_normal(), trainable=False)\n",
        "    if update_noise:\n",
        "        with tf.control_dependencies([noise.initializer]):\n",
        "            return tf.identity(noise)\n",
        "    return noise\n",
        "    \n",
        "def random_uniform(name, shape, minval, maxval, dtype=tf.float32, update_noise=False):\n",
        "    noise=lib.get_param(name, shape=shape, dtype=dtype, initializer=tf.initializers.random_uniform(minval=minval, maxval=maxval, dtype=dtype), trainable=False)\n",
        "    if update_noise:\n",
        "        with tf.control_dependencies([noise.initializer]):\n",
        "            return tf.identity(noise)\n",
        "    return noise\n",
        "def G_synthesis_stylegan2(\n",
        "    name,\n",
        "    latents_in,\n",
        "    dlatents_in,                        # Input: Disentangled latents (W) [minibatch, num_layers, dlatent_size].\n",
        "    dlatent_size        = 512,          # Disentangled latent (W) dimensionality.\n",
        "    num_channels        = 3,            # Number of output color channels.\n",
        "    resolution          = 32,         # Output resolution.\n",
        "    fmap_base           = 16 << 10,     # Overall multiplier for the number of feature maps.\n",
        "    fmap_decay          = 1.0,          # log2 feature map reduction when doubling the resolution.\n",
        "    fmap_min            = 1,            # Minimum number of feature maps in any layer.\n",
        "    fmap_max            = 512,          # Maximum number of feature maps in any layer.\n",
        "    randomize_noise     = True,         # True = randomize noise inputs every time (non-deterministic), False = read noise inputs from variables.\n",
        "    architecture        = 'skip',       # Architecture: 'orig', 'skip', 'resnet'.\n",
        "    nonlinearity        = 'lrelu',      # Activation function: 'relu', 'lrelu', etc.\n",
        "    dtype               = dtype,    # Data type to use for activations and outputs.\n",
        "    resample_kernel     = [1,3,3,1],    # Low-pass filter to apply when resampling activations. None = no filtering.\n",
        "    fused_modconv       = False,         # Implement modulated_conv2d_layer() as a single fused op?\n",
        "    update_noise=True,\n",
        "    **_kwargs):                         # Ignore unrecognized keyword args.\n",
        "\n",
        "    resolution_log2 = int(np.log2(resolution))\n",
        "    assert resolution == 2**resolution_log2 and resolution >= 4\n",
        "    def nf(stage): return np.clip(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_min, fmap_max)\n",
        "    assert architecture in ['orig', 'skip', 'resnet']\n",
        "    act = nonlinearity\n",
        "    num_layers = resolution_log2 * 2 - 2\n",
        "    images_out = None\n",
        "\n",
        "    # Primary inputs.\n",
        "    dlatents_in.set_shape([None, num_layers, dlatent_size])\n",
        "    dlatents_in = tf.cast(dlatents_in, dtype)\n",
        "\n",
        "    # Noise inputs.\n",
        "    noise_inputs = []\n",
        "    reused_noise_inputs =[]\n",
        "    for layer_idx in range(num_layers - 1):\n",
        "        res = (layer_idx + 5) // 2\n",
        "        shape = [1, 1, 2**res, 2**res]\n",
        "        noise_inputs.append(lib.get_param(name+'.noise%d' % layer_idx, shape=shape, initializer=tf.initializers.random_normal(), trainable=False))\n",
        "    \n",
        "    #Reuse the input latent noise as the addictive noise\n",
        "    #latents_in=tf.concat([latents_in,tf.reshape(tf.transpose(latents_in),latents_in.shape)],0)\n",
        "    #reuesed_latents_in=[tf.split(tf.reshape(tf.roll(latents_in,-idx-1,0),[-1]),[4**2,8**2,8**2,16**2,16**2,32**2,32**2,-1]) for idx in range(BATCH_SIZE)]\n",
        "    #for layer_idx in range(num_layers - 1):\n",
        "        #res = (layer_idx + 5) // 2\n",
        "       # shape = [BATCH_SIZE, 1, 2**res, 2**res]\n",
        "        #reused_noise_inputs.append(tf.reshape([reuesed_latents_in[idx][layer_idx] for idx in range(BATCH_SIZE)], shape))\n",
        "    # Single convolution layer with all the bells and whistles.\n",
        "    def layer(name, x, layer_idx, fmaps, kernel, up=False):\n",
        "        x = modulated_conv2d_layer(name+'.Mod_conv', x, dlatents_in[:, layer_idx], fmaps=fmaps, kernel=kernel, up=up, resample_kernel=resample_kernel, fused_modconv=fused_modconv)\n",
        "        if randomize_noise:\n",
        "            #noise = random_normal(name+'layer_noise', [8, x.shape[0], 1, x.shape[2], x.shape[3]], dtype=x.dtype, update_noise=update_noise)\n",
        "            #replica_id = tf.distribute.get_replica_context().replica_id_in_sync_group\n",
        "            #noise = noise[replica_id]\n",
        "            noise = tf.random_normal([tf.shape(x)[0], 1, x.shape[2], x.shape[3]], dtype=x.dtype)\n",
        "        else:\n",
        "            noise = tf.cast(noise_inputs[layer_idx], x.dtype)\n",
        "        noise_strength = lib.get_param(name+'.noise_strength', shape=[], initializer=tf.initializers.zeros())\n",
        "        x += noise * tf.cast(noise_strength, x.dtype)\n",
        "        return apply_bias_act(name+'.Bias', x, act=act)\n",
        "\n",
        "    # Building blocks for main layers.\n",
        "    def block(name, x, res): # res = 3..resolution_log2\n",
        "        t = x\n",
        "        x = layer(name+'.%dx%d.Conv0_up' % (2**res, 2**res), x, layer_idx=res*2-5, fmaps=nf(res-1), kernel=3, up=True)\n",
        "        x = layer(name+'.%dx%d.Conv1' % (2**res, 2**res), x, layer_idx=res*2-4, fmaps=nf(res-1), kernel=3)\n",
        "        if architecture == 'resnet':\n",
        "                t = conv2d_layer(name+'.%dx%d.Skip' % (2**res, 2**res), t, fmaps=nf(res-1), kernel=1, up=True, resample_kernel=resample_kernel)\n",
        "                x = (x + t) * (1 / np.sqrt(2))\n",
        "        return x\n",
        "    def upsample(y):\n",
        "            return upsample_2d(y, k=resample_kernel)\n",
        "    def torgb(name, x, y, res): # res = 2..resolution_log2\n",
        "        name=name+'.ToRGB_lod%d' % (resolution_log2 - res)\n",
        "        t = apply_bias_act(name+'.Bias', modulated_conv2d_layer(name+'.Mod_conv', x, dlatents_in[:, res*2-3], fmaps=num_channels, kernel=1, demodulate=False, fused_modconv=fused_modconv))\n",
        "        return t if y is None else y + t\n",
        "\n",
        "    # Early layers.\n",
        "    y = None\n",
        "    x = lib.get_param(name+'.Const4x4', shape=[1, nf(1), 4, 4], initializer=tf.initializers.random_normal())\n",
        "    x = tf.tile(tf.cast(x, dtype), [tf.shape(dlatents_in)[0], 1, 1, 1])\n",
        "    x = layer(name+'.Conv4x4', x, layer_idx=0, fmaps=nf(1), kernel=3)\n",
        "    if architecture == 'skip':\n",
        "        y = torgb(name+'.ToRGB4x4', x, y, 2)\n",
        "\n",
        "    # Main layers.\n",
        "    for res in range(3, resolution_log2 + 1):\n",
        "            x = block(name+'.B%dx%d' % (2**res, 2**res), x, res)\n",
        "            print('after GBlock%dx%d:'%(2**res, 2**res), x)\n",
        "            if architecture == 'skip':\n",
        "                y = upsample(y)\n",
        "            if architecture == 'skip' or res == resolution_log2:\n",
        "                y = torgb(name+'.ToRGB%dx%d' % (2**res, 2**res), x, y, res)\n",
        "    images_out = y\n",
        "\n",
        "    assert images_out.dtype == tf.as_dtype(dtype)\n",
        "    return images_out\n",
        "    \n",
        "\n",
        "            \n",
        "def G_main(\n",
        "    ID,\n",
        "    noise,                                         # First input: Latent vectors (Z) [minibatch, latent_size].\n",
        "    n_samples,\n",
        "    labels,                                          # Second input: Conditioning labels [minibatch, label_size].\n",
        "    NUM_CLASSES=10,\n",
        "    ema=False,\n",
        "    dlatent_size=512,\n",
        "    resolution=32,\n",
        "    truncation_psi          = 0.5,                      # Style strength multiplier for the truncation trick. None = disable.\n",
        "    truncation_cutoff       = None,                     # Number of layers for which to apply the truncation trick. None = disable.\n",
        "    truncation_psi_val      = None,                     # Value for truncation_psi to use during validation.\n",
        "    truncation_cutoff_val   = None,                     # Value for truncation_cutoff to use during validation.\n",
        "    dlatent_avg_beta        = 0.995,                    # Decay for tracking the moving average of W during training. None = disable.\n",
        "    style_mixing_prob       = None,                      # Probability of mixing styles during training. None = disable.\n",
        "    is_training             = True,                    # Network is under training? Enables and disables specific features.\n",
        "    is_validation           = False,                    # Network is under validation? Chooses which value to use for truncation_psi.\n",
        "    return_dlatents         = False,                    # Return dlatents in addition to the images?\n",
        "    is_template_graph       = False,                    # True = template graph constructed by the Network class, False = actual evaluation.\n",
        "    synthesis_func          = 'G_synthesis_stylegan2',  # Build func name for the synthesis network.\n",
        "    update_sn=None,\n",
        "    update_noise=True,\n",
        "    **kwargs):                                          # Arguments for sub-networks (mapping and synthesis).\n",
        "    name= 'Generator%i_'%ID if not ema else 'Generator%i_ema_'%ID\n",
        "    is_validation= not is_training\n",
        "    latents_in=noise\n",
        "    labels_in=tf.one_hot(labels,NUM_CLASSES)\n",
        "    resolution_log2 = int(np.log2(resolution))\n",
        "    num_layers = resolution_log2 * 2 - 2\n",
        "    \n",
        "    # Validate arguments.\n",
        "    assert not is_training or not is_validation\n",
        "    if is_validation:\n",
        "        truncation_psi = truncation_psi_val\n",
        "        truncation_cutoff = truncation_cutoff_val\n",
        "    if is_training or (truncation_psi is not None and not is_tf_expression(truncation_psi) and truncation_psi == 1):\n",
        "        truncation_psi = None\n",
        "    if is_training:\n",
        "        truncation_cutoff = None\n",
        "    if not is_training or (dlatent_avg_beta is not None and not is_tf_expression(dlatent_avg_beta) and dlatent_avg_beta == 1):\n",
        "        dlatent_avg_beta = None\n",
        "    if not is_training or (style_mixing_prob is not None and not is_tf_expression(style_mixing_prob) and style_mixing_prob <= 0):\n",
        "        style_mixing_prob = None\n",
        "        \n",
        "\n",
        "\n",
        "    # Setup variables.\n",
        "    dlatent_avg = lib.get_param(name+'.dlatent_avg', shape=[dlatent_size], initializer=tf.initializers.zeros(), trainable=False)\n",
        "\n",
        "    # Evaluate mapping network.\n",
        "    dlatents = G_mapping(name+'.mapping', latents_in, labels_in, is_training=is_training, dlatent_broadcast=num_layers)\n",
        "    dlatents = tf.cast(dlatents, tf.float32)\n",
        "\n",
        "\n",
        "    # Update moving average of W.\n",
        "    if dlatent_avg_beta is not None:\n",
        "            #batch_avg = cross_replica_mean(dlatents[:, 0], axis=0)\n",
        "            batch_avg = tf.reduce_mean(dlatents[:, 0], axis=0)\n",
        "            update_op = tf.assign(dlatent_avg, lerp(batch_avg, dlatent_avg, dlatent_avg_beta))\n",
        "            with tf.control_dependencies([update_op]):\n",
        "                dlatents = tf.identity(dlatents)\n",
        "\n",
        "    # Perform style mixing regularization.\n",
        "    if style_mixing_prob is not None:\n",
        "            #latents2 = tf.roll(latents_in, 1, 0)\n",
        "            latents2 = tf.random_normal(tf.shape(latents_in))\n",
        "            dlatents2 = G_mapping(name+'.mapping', latents2, labels_in, is_training=is_training, dlatent_broadcast=num_layers)\n",
        "            dlatents2 = tf.cast(dlatents2, tf.float32)\n",
        "            layer_idx = np.arange(num_layers)[np.newaxis, :, np.newaxis]\n",
        "            cur_layers = num_layers# - tf.cast(lod_in, tf.int32) * 2\n",
        "            cutoff_layer=random_uniform(name+'.cutoff_layer', shape=[], minval=1, maxval=cur_layers, dtype=tf.int32, update_noise=update_noise)\n",
        "            use_style_mixing=random_uniform(name+'.use_style_mixing', shape=[], minval=0, maxval=1, dtype=tf.float32, update_noise=update_noise)\n",
        "            mixing_cutoff = tf.cond(\n",
        "                use_style_mixing < style_mixing_prob,\n",
        "                lambda: cutoff_layer,\n",
        "                lambda: cur_layers)        \n",
        "            dlatents = tf.where(tf.broadcast_to(layer_idx < mixing_cutoff, tf.shape(dlatents)), dlatents, dlatents2)\n",
        "\n",
        "    # Apply truncation trick.\n",
        "    if truncation_psi is not None:\n",
        "            layer_idx = np.arange(num_layers)[np.newaxis, :, np.newaxis]\n",
        "            layer_psi = np.ones(layer_idx.shape, dtype=np.float32)\n",
        "            if truncation_cutoff is None:\n",
        "                layer_psi *= truncation_psi\n",
        "            else:\n",
        "                layer_psi = tf.where(layer_idx < truncation_cutoff, layer_psi * truncation_psi, layer_psi)\n",
        "            dlatents = lerp(dlatent_avg, dlatents, layer_psi)\n",
        "\n",
        "    # Evaluate synthesis network.\n",
        "    deps = []\n",
        "\n",
        "    with tf.control_dependencies(deps):\n",
        "        synth_net= G_synthesis_stylegan2 if synthesis_func == 'G_synthesis_stylegan2' else G_synthesis_stylegan_revised\n",
        "        images_out = synth_net(name+'.Synthesis', latents_in, dlatents, is_training=is_training, force_clean_graph=is_template_graph, update_noise=update_noise, **kwargs)\n",
        "\n",
        "    # Return requested outputs.\n",
        "    images_out = tf.transpose(images_out, [0,2,3,1])\n",
        "    images_out =  tf.reshape(images_out, [-1, DATA_DIM])\n",
        "    if return_dlatents:\n",
        "        return images_out, dlatents\n",
        "    return images_out\n",
        "\n",
        "#################################################################################################\n",
        "\n",
        "def D_stylegan2(\n",
        "    ID,\n",
        "    inputs,                          # First input: Images [minibatch, channel, height, width].\n",
        "    labels,                          # Second input: Labels [minibatch, label_size].\n",
        "    kp1,\n",
        "    kp2,\n",
        "    kp3,                       # Second input: Labels [minibatch, label_size].\n",
        "    NUM_CLASSES=10,\n",
        "    ADA=False,\n",
        "    num_channels        = 3,            # Number of input color channels. Overridden based on dataset.\n",
        "    resolution          = 32,         # Input resolution. Overridden based on dataset.\n",
        "    label_size          = 0,            # Dimensionality of the labels, 0 if no labels. Overridden based on dataset.\n",
        "    fmap_base           = 16 << 10,     # Overall multiplier for the number of feature maps.\n",
        "    fmap_decay          = 1.0,          # log2 feature map reduction when doubling the resolution.\n",
        "    fmap_min            = 1,            # Minimum number of feature maps in any layer.\n",
        "    fmap_max            = 512,          # Maximum number of feature maps in any layer.\n",
        "    architecture        = 'skip',     # Architecture: 'orig', 'skip', 'resnet'.\n",
        "    nonlinearity        = 'lrelu',      # Activation function: 'relu', 'lrelu', etc.\n",
        "    mbstd_group_size    = 32,            # Group size for the minibatch standard deviation layer, 0 = disable.\n",
        "    mbstd_num_features  = 1,            # Number of features for the minibatch standard deviation layer.\n",
        "    mapping_layers      = 0,            # Number of additional mapping layers for the conditioning labels.\n",
        "    mapping_fmaps       = 512,         # Number of activations in the mapping layers, None = default.\n",
        "    mapping_lrmul       = 0.1,          # Learning rate multiplier for the mapping layers.\n",
        "    dtype               = dtype,    # Data type to use for activations and outputs.\n",
        "    resample_kernel     = [1,3,3,1],    # Low-pass filter to apply when resampling activations. None = no filtering.\n",
        "    p=None,\n",
        "    **_kwargs):                         # Ignore unrecognized keyword args.\n",
        "    name='Discriminator%i_'%(ID)\n",
        "    label_size=NUM_CLASSES\n",
        "    labels_in=tf.one_hot(labels, NUM_CLASSES)\n",
        "    images_in = tf.cast(inputs, dtype)\n",
        "    labels_in = tf.cast(labels_in, dtype)\n",
        "    images_in=tf.reshape(images_in, [-1, resolution, resolution, num_channels])\n",
        "    labels_in.set_shape([None, label_size])\n",
        "    def nf(stage): return np.clip(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_min, fmap_max)\n",
        "    if mapping_fmaps is None:\n",
        "        mapping_fmaps = nf(0)\n",
        "    # Label embedding and mapping.\n",
        "    if label_size > 0:\n",
        "        y = labels_in\n",
        "        y = apply_bias_act(name+'.LabelEmbed.bias', dense_layer(name+'.LabelEmbed.dense', y, fmaps=mapping_fmaps))\n",
        "        y = normalize_2nd_moment(y)\n",
        "        for idx in range(mapping_layers):\n",
        "            y = apply_bias_act(name+f'.Mapping{idx}.bias',dense_layer(name+f'.Mapping{idx}.dense', y, fmaps=mapping_fmaps, lrmul=mapping_lrmul), act=act, lrmul=mapping_lrmul)\n",
        "        labels_in = y\n",
        "    if ADA:\n",
        "        images_in = augment(images_in,p=p,flip=False,imsp_aug=False)\n",
        "    images_in=tf.transpose(images_in,[0,3,1,2])\n",
        "    resolution=HEIGHT\n",
        "    resolution_log2 = int(np.log2(resolution))\n",
        "    assert resolution == 2**resolution_log2 and resolution >= 4\n",
        "    def nf(stage): return np.clip(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_min, fmap_max)\n",
        "    assert architecture in ['orig', 'skip', 'resnet']\n",
        "    act = nonlinearity\n",
        "\n",
        "    # Building blocks for main layers.\n",
        "    def fromrgb(name, x, y, res): # res = 2..resolution_log2\n",
        "        name=name+'_lod%d' % (resolution_log2 - res)\n",
        "        t = apply_bias_act(name+'.Bias', conv2d_layer(name+'.Conv', y, fmaps=nf(res-1), kernel=1), act=act)\n",
        "        return t if x is None else x + t\n",
        "    def block(name, x, res): # res = 2..resolution_log2\n",
        "        t = x\n",
        "        x = apply_bias_act(name+'.Conv0.Bias', conv2d_layer(name+'.Conv0.Conv', x, fmaps=nf(res-1), kernel=3), act=act)\n",
        "        x = apply_bias_act(name+'.Conv1_down.Bias', conv2d_layer(name+'.Conv1_down.Conv', x, fmaps=nf(res-2), kernel=3, down=True, resample_kernel=resample_kernel), act=act)\n",
        "        if architecture == 'resnet':\n",
        "                t = conv2d_layer(name+'.Skip', t, fmaps=nf(res-2), kernel=1, down=True, resample_kernel=resample_kernel)\n",
        "                x = (x + t) * (1 / np.sqrt(2))\n",
        "        return x\n",
        "    def downsample(y):\n",
        "            return downsample_2d(y, k=resample_kernel)\n",
        "\n",
        "    # Main layers.\n",
        "    x = None\n",
        "    y = images_in\n",
        "    for res in range(resolution_log2, 2, -1):\n",
        "            if architecture == 'skip' or res == resolution_log2:\n",
        "                x = fromrgb(name+'.FromRGB%dx%d' % (2**res, 2**res), x, y, res)\n",
        "            x = block(name+'.DB%dx%d'% (2**res, 2**res), x, res)\n",
        "            print('After DBlock%dx%d:' % (2**res, 2**res), x)\n",
        "            if architecture == 'skip':\n",
        "                y = downsample(y)\n",
        "\n",
        "    # Final layers.\n",
        "    if architecture == 'skip':\n",
        "        x = fromrgb(name+'.FromRGB4x4', x, y, 2)\n",
        "    if mbstd_group_size > 1:\n",
        "        x = minibatch_stddev_layer(x, mbstd_group_size, mbstd_num_features)\n",
        "    x = apply_bias_act(name+'.LastConv.Bias', conv2d_layer(name+'.LastConv.Conv', x, fmaps=nf(1), kernel=3), act=act)\n",
        "    feature=x\n",
        "    print('feature:', feature)\n",
        "    x = apply_bias_act(name+'.Dense0.Bias',dense_layer(name+'.Dense0.Conv', x, fmaps=nf(0)), act=act)\n",
        "\n",
        "    x = apply_bias_act(name+'.Output_bias', dense_layer(name+'.Output_dense', x, fmaps=mapping_fmaps if CONDITIONAL else 1))\n",
        "    if CONDITIONAL:\n",
        "        x = tf.reduce_sum(x * labels_in, axis=1, keepdims=True) / np.sqrt(mapping_fmaps)\n",
        "    scores_out = x\n",
        "    print('d output:',x)\n",
        "\n",
        "    # Output.\n",
        "    assert scores_out.dtype == tf.as_dtype(dtype)\n",
        "    return tf.cast(scores_out, tf.float32), tf.cast(feature, tf.float32), None\n",
        "\n",
        "  \n",
        "if STYLEGAN:\n",
        "    Generator = functools.partial(G_main, synthesis_func= 'G_synthesis_stylegan_revised', resolution = HEIGHT, NUM_CLASSES=NUM_CLASSES)\n",
        "    Discriminator=functools.partial(D_stylegan, NUM_CLASSES=NUM_CLASSES, ADA=ADA)\n",
        "elif STYLEGAN2:\n",
        "    Generator = functools.partial(G_main, synthesis_func= 'G_synthesis_stylegan2', resolution = HEIGHT, NUM_CLASSES=NUM_CLASSES)\n",
        "    Discriminator = functools.partial(D_stylegan2, NUM_CLASSES=NUM_CLASSES, ADA=ADA)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyNmSZxGJQQ9"
      },
      "source": [
        "train_gen = inf_gen('TRAIN')\n",
        "test_gen = inf_gen('TEST')\n",
        "gen={'training_set':train_gen,'test_set':test_gen}\n",
        "data_set_size={'training_set':TRAIN_SIZE,'test_set':TEST_SIZE}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKet1jL484GR"
      },
      "source": [
        "def chosen_minus_max_unchosen(logits, chosen_idx):\n",
        "    N=int(logits.shape[1])\n",
        "    chosen_logits=tf.boolean_mask(logits, tf.one_hot(chosen_idx, N))\n",
        "    unchosen_logits=tf.reshape(tf.boolean_mask(logits, 1-tf.one_hot(chosen_idx, N)),[-1,N-1]) \n",
        "    max_unchosen_logits=tf.reduce_max(unchosen_logits,1)\n",
        "    return chosen_logits-max_unchosen_logits"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5eX39TuJQRB",
        "outputId": "a42cd53e-b9dd-404d-a9ef-76f8e234dc71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# data tensors definitions\n",
        "with tf.device('/cpu:0') and session.as_default():\n",
        "    g_alpha=lib.get_param(name='Generator_alpha', shape=[NUM_GENERATORS], dtype=dtype, initializer=tf.ones_initializer(), trainable=False)\n",
        "    g_w=tf.nn.softmax(g_alpha)\n",
        "    d_alpha=lib.get_param(name='Discriminator_alpha',shape=[NUM_DISCRIMINATORS], dtype=dtype, initializer=tf.ones_initializer(), trainable=False)\n",
        "    d_w=tf.nn.softmax(d_alpha)\n",
        "    d_counter= lib.get_param(name='Discriminator_d_counter',shape=[],dtype=tf.int32, initializer=tf.zeros_initializer(),trainable=False)\n",
        "    indicator= lib.get_param(name='Discriminator_indicator',shape=[4],initializer=tf.zeros_initializer(),trainable=False)\n",
        "    d_p= lib.get_param(name='Discriminator_p',shape=[],initializer=tf.zeros_initializer(),trainable=False)\n",
        "    real_data_splits=tf.split(real_data, num_or_size_splits=NUM_DISCRIMINATORS)\n",
        "    real_labels_splits=tf.split(real_labels, num_or_size_splits=NUM_DISCRIMINATORS)\n",
        "    #real_indices=[tf.where(tf.equal(real_labels%NUM_DISCRIMINATORS, j)) for j in range(NUM_DISCRIMINATORS)]\n",
        "    #real_data_splits=[tf.gather(real_data, real_indices[j]) for j in range(NUM_DISCRIMINATORS)]\n",
        "    #real_labels_splits=[tf.gather(real_labels, real_indices[j]) for j in range(NUM_DISCRIMINATORS)]\n",
        "    \n",
        "    all_fake_sample={}\n",
        "    all_fake_sample_ema={}\n",
        "    #fake_labels=tf.concat([tf.stack([i for i in range(NUM_CLASSES)]) for b in range(BATCH_SIZE*NUM_GENERATORS//NUM_CLASSES)],0)\n",
        "    #fake_labels_splits=tf.split(fake_labels, num_or_size_splits=NUM_GENERATORS)\n",
        "    if RAND_LABELS:\n",
        "      fake_labels=[(tf.random.uniform([BATCH_SIZE],0,max(1,NUM_CLASSES//NUM_GENERATORS),tf.int32)*NUM_GENERATORS+i)%NUM_CLASSES for i in range(NUM_GENERATORS)]\n",
        "    else:\n",
        "      fake_labels=[(tf.range(BATCH_SIZE)*NUM_GENERATORS+i)%NUM_CLASSES for i in range(NUM_GENERATORS)]\n",
        "    stacked_labels=tf.reshape(tf.transpose(tf.stack([fake_labels[i] for i in range(NUM_GENERATORS)]),[1,0]),[-1])\n",
        "    fake_labels_splits=tf.split(stacked_labels, num_or_size_splits=NUM_DISCRIMINATORS)\n",
        "    #fake_labels_splits=real_labels_splits\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "for i in range(NUM_GENERATORS):\n",
        "    with tf.device(DEVICES[i%len(gpu_id)]):\n",
        "        noise = tf.random_normal([BATCH_SIZE, Z_DIM],dtype=dtype)\n",
        "        all_fake_sample[i]=Generator(i,noise,BATCH_SIZE,fake_labels[i], is_training=True)\n",
        "        all_fake_sample_ema[i]=Generator(i,noise,BATCH_SIZE,fake_labels[i],ema=EMA, is_training=False)\n",
        "        #noise = tf.random_normal([int(fake_labels_splits[i].shape[0]), Z_DIM],dtype=dtype)\n",
        "        #all_fake_sample[i]=Generator(i,noise,BATCH_SIZE,fake_labels_splits[i])\n",
        "       \n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    stacked_samples=tf.reshape(tf.transpose(tf.stack([all_fake_sample[i] for i in range(NUM_GENERATORS)]),[1,0,2]),[NUM_GENERATORS*BATCH_SIZE,DATA_DIM])\n",
        "    #stacked_samples=tf.concat([tf.stack([all_fake_sample[i][b] for i in range(NUM_GENERATORS)]) for b in range(BATCH_SIZE)],0)\n",
        "    sample_weights_splits=[tf.gather(g_w, fake_labels[i]) for i in range(NUM_GENERATORS)]\n",
        "    fake_sample=tf.gather(stacked_samples,tf.range(min(100,stacked_samples.shape[0])))\n",
        "    fake_sample_splits=tf.split(stacked_samples, num_or_size_splits=NUM_DISCRIMINATORS)\n",
        "    #fake_sample_splits=all_fake_sample\n",
        "    \n",
        "    stacked_samples_ema=tf.reshape(tf.transpose(tf.stack([all_fake_sample_ema[i] for i in range(NUM_GENERATORS)]),[1,0,2]),[NUM_GENERATORS*BATCH_SIZE,DATA_DIM])\n",
        "    fake_sample=tf.gather(stacked_samples_ema,tf.range(min(100,stacked_samples.shape[0])))\n",
        "    fake_sample=tf.clip_by_value(fake_sample, -1., 1.)\n",
        "disc_real=[]\n",
        "log_sigmoid_disc_real=[]\n",
        "indicator_stat=[]\n",
        "disc_real_hinge=[]\n",
        "ac_real={}\n",
        "disc_fake=[]\n",
        "disc_fake_hinge=[]\n",
        "log_1_minus_sigmoid_disc_fake=[]\n",
        "log_sigmoid_disc_fake=[]\n",
        "ac_fake={}\n",
        "disc_real_noisy_1,disc_real_features_noisy_1, ac_real_noisy_1={},{},{}\n",
        "disc_real_noisy_2,disc_real_features_noisy_2, ac_real_noisy_2={},{},{}\n",
        "disc_fake_noisy,disc_fake_features_noisy, ac_fake_noisy={},{},{}\n",
        "\n",
        "for j in range(NUM_DISCRIMINATORS):\n",
        "    with tf.device(DEVICES[j%len(gpu_id)]):\n",
        "        # x' with dropout noise added\n",
        "        disc_real_noisy_1[j],disc_real_features_noisy_1[j], ac_real_noisy_1[j] = Discriminator(j, real_data_splits[j], real_labels_splits[j],0.8,0.5,0.5)  #dropout rate of 0.2,0.5,0.5\n",
        "        # x'' with dropout noise added\n",
        "        if LAMBDA2: \n",
        "          disc_real_noisy_2[j],disc_real_features_noisy_2[j], ac_real_noisy_2[j] = Discriminator(j, real_data_splits[j], real_labels_splits[j],0.8,0.5,0.5)  #dropout rate of 0.2,0.5,0.5\n",
        "\n",
        "        disc_real.append(d_w[j]*tf.reduce_mean(disc_real_noisy_1[j]))\n",
        "        log_sigmoid_disc_real.append(d_w[j]*tf.reduce_mean(tf.nn.softplus(-disc_real_noisy_1[j])))\n",
        "        disc_real_hinge.append(d_w[j]*tf.reduce_mean(-tf.nn.relu(1-disc_real_noisy_1[j])))\n",
        "        # fake data with dropout noise added\n",
        "        disc_fake_noisy[j],disc_fake_features_noisy[j], ac_fake_noisy[j] = Discriminator(j,fake_sample_splits[j],fake_labels_splits[j], 0.8,0.5,0.5)  #dropout rate of 0.2,0.5,0.5\n",
        "        #disc_fake+=d_w[j]*sample_weights_splits*disc_fake_noisy[j]\n",
        "        disc_fake.append(d_w[j]*tf.reduce_mean(disc_fake_noisy[j]))\n",
        "        disc_fake_hinge.append(d_w[j]*tf.reduce_mean(tf.nn.relu(1+disc_fake_noisy[j])))\n",
        "        log_1_minus_sigmoid_disc_fake.append(d_w[j]*tf.reduce_mean(tf.nn.softplus(disc_fake_noisy[j])))\n",
        "        log_sigmoid_disc_fake.append(d_w[j]*tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(disc_fake_noisy[j]),logits=disc_fake_noisy[j])))\n",
        "        if CONDITIONAL and ACGAN:\n",
        "            ac_real[j]=ac_real_noisy_1[j]\n",
        "            ac_fake[j]=ac_fake_noisy[j]\n",
        "        if MH_LOSS:\n",
        "            indicator_stat.append(d_w[j]*tf.reduce_mean(chosen_minus_max_unchosen(ac_fake_noisy[j],NUM_CLASSES*tf.ones_like(real_labels_splits[j]))))\n",
        "        elif AM_LOSS:\n",
        "            indicator_stat.append(d_w[j]*tf.reduce_mean(tf.math.sign(tf.nn.softmax(ac_fake_noisy[j])[:,NUM_CLASSES]-.5)))\n",
        "        else:\n",
        "            indicator_stat.append(d_w[j]*tf.reduce_mean(tf.math.sign(disc_real_noisy_1[j])))\n",
        "# not applicable to WGAN:\n",
        "with tf.device('/cpu:0'):\n",
        "    indicator_stat=tf.add_n(indicator_stat)\n",
        "    disc_real_accuracy = tf.reduce_mean([tf.cast(disc_real[j]>=0, dtype) for j in range(NUM_DISCRIMINATORS)])\n",
        "    disc_fake_accuracy = tf.reduce_mean([tf.cast(disc_fake[j]<=0, dtype) for j in range(NUM_DISCRIMINATORS)])\n",
        "    disc_accuracy=(disc_real_accuracy+disc_fake_accuracy)/2\n",
        "    disc_real=tf.add_n(disc_real)\n",
        "    disc_real_hinge=tf.add_n(disc_real_hinge)\n",
        "    disc_fake=tf.add_n(disc_fake)\n",
        "    disc_fake_hinge=tf.add_n(disc_fake_hinge)\n",
        "    log_sigmoid_disc_real=tf.add_n(log_sigmoid_disc_real)\n",
        "    log_1_minus_sigmoid_disc_fake=tf.add_n(log_1_minus_sigmoid_disc_fake)\n",
        "    log_sigmoid_disc_fake=tf.add_n(log_sigmoid_disc_fake)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"one_hot_1:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_2:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_3:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_4:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_5:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_6:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_7:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_3:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_14:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_17:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_20:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_3:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_8:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_9:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_10:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_11:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_12:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_13:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_63:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_24:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_27:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_30:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_5:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_14:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_15:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_16:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_17:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_18:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_19:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_123:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_34:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_37:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_40:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_7:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_20:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_21:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_22:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_23:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_24:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_25:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_183:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_44:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_47:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_50:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_9:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_26:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_27:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_28:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_29:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_30:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_31:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_243:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_54:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_57:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_60:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_11:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_32:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_33:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_34:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_35:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_36:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_37:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_303:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_64:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_67:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_70:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_13:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_38:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_39:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_40:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_41:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_42:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_43:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_363:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_74:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_77:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_80:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_15:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_44:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_45:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_46:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_47:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_48:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_49:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_423:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_84:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_87:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_90:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_17:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_50:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_51:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_52:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_53:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_54:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_55:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_483:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_94:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_97:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_100:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_19:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_56:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_57:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_58:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_59:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_60:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_61:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_543:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_104:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_107:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_110:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_21:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_62:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_63:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_64:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_65:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_66:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_67:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_603:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_114:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_117:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_120:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_23:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_68:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_69:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_70:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_71:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_72:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_73:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_663:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_124:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_127:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_130:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_25:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_74:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_75:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_76:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_77:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_78:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_79:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_723:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_134:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_137:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_140:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_27:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_80:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_81:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_82:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_83:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_84:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_85:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_783:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_144:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_147:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_150:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_29:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_86:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_87:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_88:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_89:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_90:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_91:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_843:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_154:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_157:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_160:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_31:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_92:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_93:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_94:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_95:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_96:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_97:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_903:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_164:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_167:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_170:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_33:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_98:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_99:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_100:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_101:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_102:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_103:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_963:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_174:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_177:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_180:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_35:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_104:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_105:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_106:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_107:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_108:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_109:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_1023:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_184:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_187:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_190:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_37:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_110:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_111:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_112:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_113:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_114:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_115:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_1083:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_194:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_197:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_200:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "Tensor(\"one_hot_39:0\", shape=(50, 10), dtype=float32, device=/device:GPU:0)\n",
            "code:  [<tf.Tensor 'concat_116:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_117:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_118:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_119:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_120:0' shape=(50, 148) dtype=float32>, <tf.Tensor 'concat_121:0' shape=(50, 148) dtype=float32>]\n",
            "after dense Tensor(\"Reshape_1143:0\", shape=(50, 4, 4, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 0: Tensor(\"add_204:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 1: Tensor(\"add_207:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "After Block 2: Tensor(\"add_210:0\", shape=(50, 32, 32, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1203:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_212:0\", shape=(?, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_213:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_214:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_215:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1231:0\", shape=(50, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_217:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_218:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_219:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_220:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1260:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_223:0\", shape=(?, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_224:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_225:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_226:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1288:0\", shape=(50, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_228:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_229:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_230:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_231:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1317:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_234:0\", shape=(?, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_235:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_236:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_237:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1345:0\", shape=(50, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_239:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_240:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_241:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_242:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1374:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_245:0\", shape=(?, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_246:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_247:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_248:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1402:0\", shape=(50, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_250:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_251:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_252:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_253:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1431:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_256:0\", shape=(?, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_257:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_258:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_259:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1459:0\", shape=(50, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_261:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_262:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_263:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_264:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1488:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_267:0\", shape=(?, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_268:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_269:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_270:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1516:0\", shape=(50, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_272:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_273:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_274:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_275:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1545:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_278:0\", shape=(?, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_279:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_280:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_281:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1573:0\", shape=(50, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_283:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_284:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_285:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_286:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1602:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_289:0\", shape=(?, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_290:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_291:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_292:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1630:0\", shape=(50, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_294:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_295:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_296:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_297:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1659:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_300:0\", shape=(?, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_301:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_302:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_303:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1687:0\", shape=(50, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_305:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_306:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_307:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_308:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1716:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_311:0\", shape=(?, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_312:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_313:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_314:0\", shape=(?, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "inputs: Tensor(\"Reshape_1744:0\", shape=(50, 32, 32, 3), dtype=float32, device=/device:GPU:0)\n",
            "after resdown1 Tensor(\"add_316:0\", shape=(50, 16, 16, 256), dtype=float32, device=/device:GPU:0)\n",
            "after resdown2 Tensor(\"add_317:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res8 Tensor(\"add_318:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n",
            "after res16 Tensor(\"add_319:0\", shape=(50, 8, 8, 256), dtype=float32, device=/device:GPU:0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAEkOZOX0gRC"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfGoubfnJQRI",
        "outputId": "0f945316-a75c-46a8-addb-a5550442d5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "#cost definitions\n",
        "\n",
        "###################################################### Discriminator #####################################################################\n",
        "with tf.device('/cpu:0'):\n",
        "    disc_cost=tf.zeros([],dtype=dtype)\n",
        "    gen_cost=tf.zeros([],dtype=dtype)\n",
        "    g_orth_reg=tf.zeros([],dtype=dtype)\n",
        "    d_orth_reg=tf.zeros([],dtype=dtype)\n",
        "    # entropy regularizers:\n",
        "    gen_cost -= tf.reduce_mean(tf.log(g_w))\n",
        "    disc_cost -= tf.reduce_mean(tf.log(d_w))\n",
        "\n",
        "    # G LOSS\n",
        "    if GAN_LOSS:\n",
        "        gen_cost+=log_sigmoid_disc_fake\n",
        "    elif HINGE_LOSS or WGAN_LOSS:\n",
        "        gen_cost-=disc_fake\n",
        "    #D LOSS\n",
        "    if GAN_LOSS:\n",
        "        disc_cost+=(log_sigmoid_disc_real+log_1_minus_sigmoid_disc_fake)\n",
        "    elif HINGE_LOSS:\n",
        "        disc_cost+=disc_fake_hinge-disc_real_hinge\n",
        "    elif WGAN_LOSS:\n",
        "        disc_cost+=disc_fake-disc_real\n",
        "# WGAN gradient penalty\n",
        "gradient_penalty=tf.zeros([])\n",
        "wass_dist=tf.zeros([])\n",
        "if COMPUTE_GRADIENT:\n",
        "    gradient_penalty=[]\n",
        "    wass_dist=[]\n",
        "    for j in range(NUM_DISCRIMINATORS):\n",
        "        with tf.device(DEVICES[j%len(gpu_id)]):\n",
        "            eps = tf.random_uniform(\n",
        "            shape=[int(fake_sample_splits[j].shape[0]),1], \n",
        "            minval=0.,\n",
        "            maxval=1.,\n",
        "            dtype=dtype\n",
        "            )\n",
        "            #interpolates = fake_sample_splits[j]\n",
        "            if R1_COEFF:\n",
        "                disc_output=tf.reduce_sum(disc_real_noisy_1[j])\n",
        "                #if len(disc_output.shape)>1 and disc_output.shape[-1]==NUM_CLASSES+1:\n",
        "                #    disc_output=-tf.log(1/tf.reduce_sum(tf.nn.softmax(disc_output)[:,:NUM_CLASSES],1)-1) #logit function of real probability\n",
        "                gradients = tf.gradients(disc_output, [real_data_splits[j]])[0]  #same dropout rate\n",
        "            else:\n",
        "                gradients = tf.gradients(disc_fake_noisy[j], [fake_sample_splits[j]])[0]  #same dropout rate\n",
        "            square_slopes=tf.reduce_sum(tf.square(gradients), reduction_indices=[1])\n",
        "            print('square_slopes:',square_slopes)\n",
        "            slopes = tf.sqrt(square_slopes)   \n",
        "            max_slope=tf.reduce_max(slopes)  \n",
        "            wass_dist.append(d_w[j]*(tf.reduce_mean(disc_real_noisy_1[j])-tf.reduce_mean(disc_fake_noisy[j]))/max_slope)\n",
        "            if LAMBDA:\n",
        "                gradient_penalty.append(d_w[j]*LAMBDA*tf.reduce_mean((slopes-1.)**2))\n",
        "            elif R1_COEFF:\n",
        "                gradient_penalty.append(d_w[j]*R1_COEFF*tf.reduce_mean(square_slopes)/2)\n",
        "    with tf.device('/cpu:0'):\n",
        "        gradient_penalty=tf.add_n(gradient_penalty)\n",
        "        if LAMBDA or R1_COEFF:\n",
        "            disc_cost+=gradient_penalty\n",
        "        wass_dist=tf.reduce_max(wass_dist)\n",
        "\n",
        "# ACGAN Classifier cost for G\n",
        "gen_acgan_cost=[]\n",
        "for j in range(NUM_DISCRIMINATORS):\n",
        "    with tf.device(DEVICES[j%len(gpu_id)]):\n",
        "        if CONDITIONAL and ACGAN: \n",
        "            gen_acgan_cost.append(d_w[j]*ACGAN_SCALE_G*tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=ac_fake[j], labels=fake_labels_splits[j])))\n",
        "with tf.device('/cpu:0'):\n",
        "    if CONDITIONAL and ACGAN: \n",
        "        gen_cost+=tf.add_n(gen_acgan_cost)\n",
        "# ACGAN classification cost\n",
        "ac_cost=[]\n",
        "ac_real_acc=[]\n",
        "ac_fake_acc=[]\n",
        "CT_cost=[]\n",
        "D_MHINGE_LOSS=[]\n",
        "G_MHINGE_LOSS=[]\n",
        "FM_loss=[]\n",
        "for j in range(NUM_DISCRIMINATORS):\n",
        "    with tf.device(DEVICES[j%len(gpu_id)]):\n",
        "        if CONDITIONAL and ACGAN:\n",
        "            # cross-entropy classification cost\n",
        "            ac_cost.append(d_w[j]*ACGAN_SCALE*(tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=ac_real[j], labels=real_labels_splits[j]))))\n",
        "            #auxiliary classifier(in discriminator) accuracy on real data\n",
        "            ac_real_acc.append(d_w[j]*(tf.reduce_mean(tf.cast(tf.equal(tf.to_int32(tf.argmax(ac_real[j], dimension=1)), real_labels_splits[j]),dtype))))\n",
        "            #auxiliary classifier(in discriminator) accuracy on fake data\n",
        "            ac_fake_acc.append(d_w[j]*(tf.reduce_mean(tf.cast(tf.equal(tf.to_int32(tf.argmax(ac_fake[j], dimension=1)),fake_labels_splits[j]),dtype))))\n",
        "        if LAMBDA2:    \n",
        "            # CT-GAN consistency term\n",
        "            CT = LAMBDA2*tf.square(disc_real_noisy_1[j]-disc_real_noisy_2[j])  \n",
        "            CT += LAMBDA2*0.1*tf.reduce_mean(tf.square(disc_real_features_noisy_1[j]-disc_real_features_noisy_2[j]),reduction_indices=[1])\n",
        "            CT_ = tf.maximum(CT-Factor_M,0.)\n",
        "            CT_ = tf.reduce_mean(CT_)\n",
        "            CT_cost.append(d_w[j]*(CT_))\n",
        "        if MH_LOSS or AM_LOSS:\n",
        "            if AM_LOSS:\n",
        "                ac_real_cost=tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=ac_real_noisy_1[j],labels=real_labels_splits[j]))\n",
        "                ac_fake_cost=tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=ac_fake_noisy[j],labels=NUM_CLASSES*tf.ones_like(real_labels_splits[j])))\n",
        "                G_MHINGE_LOSS.append(d_w[j]*tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=ac_fake_noisy[j],labels=fake_labels_splits[j])))\n",
        "            else:\n",
        "                ac_real_cost=tf.reduce_mean(tf.nn.relu(1-chosen_minus_max_unchosen(ac_real_noisy_1[j],real_labels_splits[j])))\n",
        "                ac_fake_cost=tf.reduce_mean(tf.nn.relu(1-chosen_minus_max_unchosen(ac_fake_noisy[j],NUM_CLASSES*tf.ones_like(real_labels_splits[j]))))\n",
        "                G_MHINGE_LOSS.append(d_w[j]*tf.reduce_mean(tf.nn.relu(1-chosen_minus_max_unchosen(ac_fake_noisy[j],fake_labels_splits[j]))))\n",
        "            ac_cost.append(d_w[j]*ac_real_cost)\n",
        "            D_MHINGE_LOSS.append(d_w[j]*(ac_real_cost+ac_fake_cost))\n",
        "            ac_real_acc.append(d_w[j]*(tf.reduce_mean(tf.cast(tf.equal(tf.to_int32(tf.argmax(ac_real_noisy_1[j], dimension=1)), real_labels_splits[j]),dtype))))\n",
        "            ac_fake_acc.append(d_w[j]*(tf.reduce_mean(tf.cast(tf.equal(tf.to_int32(tf.argmax(ac_fake_noisy[j], dimension=1)),fake_labels_splits[j]),dtype))))\n",
        "        if MH_LOSS or AM_LOSS:\n",
        "            FM_loss.append(d_w[j]*tf.reduce_sum(tf.abs(tf.reduce_mean(disc_real_features_noisy_1[j],0)-tf.reduce_mean(disc_fake_features_noisy[j],0))))\n",
        "with tf.device('/cpu:0'):\n",
        "    if ACGAN or MH_LOSS or AM_LOSS:\n",
        "        ac_real_acc=tf.add_n(ac_real_acc)\n",
        "        ac_fake_acc=tf.add_n(ac_fake_acc)\n",
        "        ac_cost=tf.add_n(ac_cost)\n",
        "        if ACGAN:\n",
        "            disc_cost+=ac_cost\n",
        "    else:\n",
        "        ac_cost=tf.zeros([])\n",
        "        ac_real_acc=tf.zeros([])\n",
        "        ac_fake_acc=tf.zeros([]) \n",
        "    if MH_LOSS or AM_LOSS:\n",
        "        disc_cost+= tf.add_n(D_MHINGE_LOSS)\n",
        "        gen_cost=tf.add_n(G_MHINGE_LOSS)+LAMBDA3*tf.add_n(FM_loss)\n",
        "pl_lengths=[]\n",
        "pl_cost=[]\n",
        "if PL_COEFF:\n",
        "    for i in range(NUM_GENERATORS):\n",
        "        with tf.device(DEVICES[i%len(gpu_id)]):\n",
        "            pl_minibatch_shrink=1\n",
        "            pl_decay=0.01\n",
        "            minibatch_size=BATCH_SIZE\n",
        "            pl_minibatch = minibatch_size // pl_minibatch_shrink\n",
        "            pl_latents = noise[i]\n",
        "            pl_labels = fake_labels[i]\n",
        "            fake_images_out, fake_dlatents_out = all_fake_sample[i], dlatents[i] #noise_splits[i//NUM_DEVICES]\n",
        "            num_noise_splits=1\n",
        "            # Compute |J*y|.\n",
        "            pl_noise = tf.random_normal(tf.shape(fake_images_out)) / np.sqrt(HEIGHT*WIDTH)\n",
        "            pl_grads = tf.gradients(tf.reduce_sum(fake_images_out * pl_noise), [fake_dlatents_out])[0]\n",
        "            print('pl_grad:',pl_grads)\n",
        "            pl_lengths=tf.reduce_mean(tf.sqrt(tf.reduce_mean(tf.reduce_sum(tf.square(pl_grads), axis=2), axis=1)))\n",
        "\n",
        "            # Track exponential moving average of |J*y|.\n",
        "            pl_mean_var = lib.get_param('Generator_pl%i'%i, shape=[], initializer=tf.zeros_initializer() ,trainable=False, dtype=tf.float32)\n",
        "            pl_mean = pl_mean_var + pl_decay * (pl_lengths- pl_mean_var)\n",
        "            pl_update = tf.assign(pl_mean_var, pl_mean)\n",
        "            # Calculate (|J*y|-a)^2.\n",
        "            with tf.control_dependencies([pl_update]):\n",
        "                pl_penalty = tf.square(pl_lengths - pl_mean)\n",
        "                pl_cost.append(PL_COEFF*pl_penalty)\n",
        "    with tf.device('/cpu:0'):\n",
        "        gen_cost+=tf.add_n(pl_cost)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the `axis` argument instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the `axis` argument instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-e3a917e66ceb>:106: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-e3a917e66ceb>:106: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EFoBy4hz6ty"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YchjtRrqJQRM"
      },
      "source": [
        "# for records to be saved in a tsv file\n",
        "\n",
        "num_counter=1\n",
        "record={}\n",
        "names=[]\n",
        "if DATASET in IMAGE_DATASETS and NUM_CHANNELS==3:\n",
        "    name='Inception score'\n",
        "    names.append(name)\n",
        "    record[name]=np.zeros(num_counter)\n",
        "    name='IS_std'\n",
        "    names.append(name)\n",
        "    record[name]=np.zeros(num_counter)\n",
        "    name='FID_TRAIN'\n",
        "    names.append(name)\n",
        "    record[name]=np.zeros(num_counter)\n",
        "    name='FID_VAL'\n",
        "    names.append(name)\n",
        "    record[name]=np.zeros(num_counter)\n",
        "name='D(Xr)-D(Xf)'\n",
        "names.append(name)\n",
        "record[name]=np.zeros(num_counter)\n",
        "name='Wass_dist'\n",
        "names.append(name)\n",
        "record[name]=np.zeros(num_counter)\n",
        "for dst in ['training_set','test_set']:\n",
        "    name='FID_'+dst\n",
        "    names.append(name)\n",
        "    record[name]=np.zeros(num_counter)\n",
        "counter=0"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRtoxHhQJQRQ"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TXqBIRJJQRU"
      },
      "source": [
        "ema_params=lib.params_with_name('ema')\n",
        "ema_params=[var for  var in ema_params if 'moving' not in var.name and 'accu' not in var.name]\n",
        "nonema_params=[lib.get_param(var.name.split(':')[0].replace('_ema','')) for var in ema_params]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1wkcOsqJQRW"
      },
      "source": [
        "def warmup():\n",
        "  if ACCU_STATS:\n",
        "        session.run(clear_op)\n",
        "        WARMUP_STEPS=200000//100 if iteration % (10000) == 0 else 100\n",
        "        for i in range(WARMUP_STEPS):\n",
        "            _=session.run(fake_sample)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcqvT_woJQRY"
      },
      "source": [
        "from tensorflow.python.ops import state_ops\n",
        "def ema_update(v, value, decay=0.9999):\n",
        "    #if not v.trainable and '.u_var' not in v.name: decay= 0.\n",
        "    return state_ops.assign_sub(v, (v - value) * (1.-decay))\n",
        "def get_ema_op():\n",
        "    return tf.group(*[ema_update(ema_params[i], nonema_params[i], .9999) for i in range(len(ema_params))]) if EMA else tf.no_op()\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwVS1hYEJQRb"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik6N4faGJQRe"
      },
      "source": [
        "#from keras_radam.training import RAdamOptimizer\n",
        "def increment_p(p=d_p,offset=4*BATCH_SIZE/5000000.):\n",
        "    return  tf.cond(p<1,functools.partial(state_ops.assign_add,ref=p,value=offset),functools.partial(state_ops.assign,ref=p,value=1.))\n",
        "def decrement_p(p=d_p,offset=4*BATCH_SIZE/5000000.):\n",
        "    return tf.cond(p>0,functools.partial(state_ops.assign_sub,ref=p,value=offset),functools.partial(state_ops.assign,ref=p,value=0.))\n",
        "disc_params = lib.params_with_name('Discriminator')\n",
        "gen_params = lib.params_with_name('Generator')\n",
        "with tf.device('/cpu:0') and session.as_default():\n",
        "    gen_opt = tf.train.AdamOptimizer(learning_rate=lr, beta1=BETA1, beta2=BETA2)\n",
        "    disc_opt = tf.train.AdamOptimizer(learning_rate=lr, beta1=BETA1, beta2=BETA2)\n",
        "    gen_train_op = gen_opt.minimize(gen_cost,var_list=gen_params, colocate_gradients_with_ops=True)\n",
        "    disc_train_op = disc_opt.minimize(disc_cost,var_list=disc_params, colocate_gradients_with_ops=True)\n",
        "    with tf.control_dependencies([disc_train_op]):\n",
        "        with tf.control_dependencies([tf.scatter_update(indicator,d_counter%4,indicator_stat)]):\n",
        "          with tf.control_dependencies([tf.assign_add(d_counter, 1)]):\n",
        "            def update_p_fn():\n",
        "                return tf.cond(tf.reduce_mean(indicator)>ADA_TARGET,increment_p, decrement_p)\n",
        "                \n",
        "            updated_p_op=tf.cond(update_p,update_p_fn,lambda:d_p)\n",
        "            with tf.control_dependencies([updated_p_op]):\n",
        "                    disc_train_op=tf.no_op()\n",
        "    if EMA:\n",
        "        with tf.control_dependencies([gen_train_op]):\n",
        "            gen_train_op = tf.cond(curr_iter> EMA_ITER, get_ema_op, tf.no_op)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCOBKNfIJQRh",
        "outputId": "7dd2cb96-68d3-4330-e2e5-ab0aeadc17fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "g_params_count=0\n",
        "d_params_count=0\n",
        "print(\"Generator params:\")\n",
        "for var in lib.params_with_name('Generator'):\n",
        "    print(var.device, var.name, var.get_shape(), np.prod(var.get_shape()))\n",
        "    g_params_count+=int(np.prod(var.get_shape()))\n",
        "print(\"Discriminator params:\")\n",
        "for var in lib.params_with_name('Discriminator'):\n",
        "    print(var.device, var.name, var.get_shape(), np.prod(var.get_shape()))\n",
        "    d_params_count+=int(np.prod(var.get_shape()))\n",
        "print(\"G params total:{:,}\".format(int(g_params_count)))\n",
        "print(\"D params total:{:,}\".format(int(d_params_count)))\n",
        "print(\"All params total:{:,}\".format(int(g_params_count+d_params_count)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator params:\n",
            " Generator_alpha:0 (10,) 10\n",
            "/device:GPU:0 Generator.0.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator.0dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator.0dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator.0.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.0.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.0.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.0.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.0.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.0.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.0.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.0.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.0.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.0.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.0.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.0.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.0.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.0.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.0.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.0.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.0.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.0.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.0.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.0.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.0.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator.0.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator.0.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator.0.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator_ema.0.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator_ema.0dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator_ema.0dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.0.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.0.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.0.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.0.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.0.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.0.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.0.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.0.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.0.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.0.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.0.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.0.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.0.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.0.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.0.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.0.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.0.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.0.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.0.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.0.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.last_bn.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.last_bn.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.last_bn.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.last_bn.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.0.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.0.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator_ema.0.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator_ema.0.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator.1.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator.1dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator.1dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator.1.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.1.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.1.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.1.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.1.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.1.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.1.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.1.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.1.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.1.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.1.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.1.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.1.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.1.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.1.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.1.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.1.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.1.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.1.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.1.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.1.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator.1.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator.1.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator.1.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator_ema.1.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator_ema.1dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator_ema.1dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.1.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.1.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.1.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.1.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.1.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.1.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.1.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.1.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.1.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.1.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.1.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.1.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.1.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.1.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.1.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.1.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.1.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.1.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.1.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.1.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.last_bn.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.last_bn.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.last_bn.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.last_bn.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.1.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.1.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator_ema.1.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator_ema.1.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator.2.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator.2dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator.2dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator.2.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.2.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.2.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.2.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.2.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.2.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.2.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.2.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.2.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.2.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.2.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.2.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.2.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.2.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.2.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.2.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.2.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.2.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.2.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.2.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.2.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator.2.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator.2.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator.2.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator_ema.2.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator_ema.2dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator_ema.2dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.2.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.2.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.2.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.2.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.2.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.2.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.2.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.2.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.2.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.2.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.2.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.2.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.2.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.2.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.2.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.2.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.2.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.2.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.2.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.2.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.last_bn.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.last_bn.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.last_bn.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.last_bn.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.2.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.2.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator_ema.2.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator_ema.2.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator.3.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator.3dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator.3dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator.3.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.3.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.3.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.3.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.3.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.3.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.3.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.3.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.3.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.3.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.3.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.3.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.3.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.3.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.3.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.3.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.3.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.3.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.3.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.3.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.3.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator.3.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator.3.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator.3.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator_ema.3.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator_ema.3dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator_ema.3dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.3.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.3.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.3.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.3.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.3.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.3.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.3.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.3.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.3.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.3.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.3.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.3.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.3.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.3.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.3.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.3.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.3.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.3.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.3.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.3.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.last_bn.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.last_bn.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.last_bn.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.last_bn.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.3.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.3.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator_ema.3.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator_ema.3.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator.4.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator.4dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator.4dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator.4.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.4.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.4.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.4.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.4.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.4.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.4.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.4.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.4.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.4.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.4.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.4.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.4.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.4.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.4.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.4.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.4.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.4.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.4.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.4.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.4.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator.4.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator.4.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator.4.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator_ema.4.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator_ema.4dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator_ema.4dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.4.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.4.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.4.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.4.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.4.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.4.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.4.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.4.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.4.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.4.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.4.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.4.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.4.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.4.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.4.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.4.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.4.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.4.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.4.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.4.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.last_bn.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.last_bn.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.last_bn.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.last_bn.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.4.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.4.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator_ema.4.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator_ema.4.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator.5.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator.5dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator.5dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator.5.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.5.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.5.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.5.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.5.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.5.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.5.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.5.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.5.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.5.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.5.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.5.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.5.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.5.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.5.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.5.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.5.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.5.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.5.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.5.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.5.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator.5.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator.5.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator.5.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator_ema.5.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator_ema.5dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator_ema.5dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.5.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.5.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.5.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.5.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.5.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.5.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.5.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.5.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.5.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.5.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.5.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.5.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.5.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.5.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.5.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.5.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.5.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.5.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.5.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.5.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.last_bn.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.last_bn.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.last_bn.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.last_bn.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.5.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.5.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator_ema.5.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator_ema.5.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator.6.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator.6dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator.6dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator.6.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.6.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.6.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.6.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.6.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.6.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.6.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.6.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.6.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.6.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.6.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.6.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.6.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.6.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.6.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.6.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.6.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.6.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.6.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.6.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.6.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator.6.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator.6.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator.6.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator_ema.6.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator_ema.6dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator_ema.6dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.6.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.6.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.6.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.6.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.6.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.6.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.6.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.6.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.6.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.6.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.6.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.6.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.6.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.6.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.6.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.6.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.6.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.6.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.6.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.6.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.last_bn.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.last_bn.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.last_bn.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.last_bn.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.6.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.6.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator_ema.6.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator_ema.6.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator.7.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator.7dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator.7dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator.7.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.7.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.7.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.7.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.7.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.7.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.7.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.7.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.7.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.7.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.7.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.7.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.7.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.7.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.7.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.7.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.7.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.7.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.7.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.7.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.7.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator.7.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator.7.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator.7.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator_ema.7.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator_ema.7dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator_ema.7dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.7.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.7.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.7.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.7.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.7.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.7.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.7.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.7.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.7.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.7.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.7.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.7.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.7.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.7.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.7.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.7.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.7.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.7.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.7.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.7.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.last_bn.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.last_bn.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.last_bn.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.last_bn.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.7.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.7.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator_ema.7.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator_ema.7.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator.8.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator.8dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator.8dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator.8.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.8.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.8.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.8.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.8.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.8.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.8.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.8.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.8.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.8.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.8.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.8.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.8.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.8.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.8.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.8.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.8.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.8.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.8.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.8.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.8.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator.8.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator.8.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator.8.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator_ema.8.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator_ema.8dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator_ema.8dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.8.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.8.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.8.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.8.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.8.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.8.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.8.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.8.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.8.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.8.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.8.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.8.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.8.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.8.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.8.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.8.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.8.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.8.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.8.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.8.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.last_bn.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.last_bn.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.last_bn.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.last_bn.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.8.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.8.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator_ema.8.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator_ema.8.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator.9.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator.9dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator.9dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator.9.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.9.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.9.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.9.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.9.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.9.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.9.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.9.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.9.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.9.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.9.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.9.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.9.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.9.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.9.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator.9.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator.9.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator.9.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator.9.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator.9.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator.9.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator.9.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator.9.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator.9.last_conv.Biases:0 (3,) 3\n",
            "/device:GPU:0 Generator_ema.9.embed.W:0 (10, 128) 1280\n",
            "/device:GPU:0 Generator_ema.9dense.W:0 (20, 4096) 81920\n",
            "/device:GPU:0 Generator_ema.9dense.W.u_var:0 (20, 1) 20\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up0.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.9.up0.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.9.up0.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up0.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up0.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.9.up0.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.9.up0.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up0.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.9.up0.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.9.up0.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up1.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.9.up1.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.9.up1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up1.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.9.up1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.9.up1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up1.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.9.up1.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.9.up1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn1.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn1.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn1.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn1.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn1.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn1.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn1.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn1.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.9.up2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.9.up2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn2.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn2.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn2.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn2.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn2.Gamma.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn2.Gamma.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn2.Beta.W:0 (148, 256) 37888\n",
            "/device:GPU:0 Generator_ema.9.up2.cbn2.Beta.W.u_var:0 (148, 1) 148\n",
            "/device:GPU:0 Generator_ema.9.up2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Generator_ema.9.up2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Generator_ema.9.up2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.up2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Generator_ema.9.up2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Generator_ema.9.up2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.last_bn.accu_mean:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.last_bn.accu_variance:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.last_bn.accu_counter:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.last_bn.update_accus:0 () 1.0\n",
            "/device:GPU:0 Generator_ema.9.last_bn.gamma:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.last_bn.beta:0 (256,) 256\n",
            "/device:GPU:0 Generator_ema.9.last_conv.Filters:0 (3, 3, 256, 3) 6912\n",
            "/device:GPU:0 Generator_ema.9.last_conv.Filters.u_var:0 (1, 3) 3\n",
            "/device:GPU:0 Generator_ema.9.last_conv.Biases:0 (3,) 3\n",
            "Discriminator params:\n",
            " Discriminator_alpha:0 (10,) 10\n",
            " Discriminator_d_counter:0 () 1.0\n",
            " Discriminator_indicator:0 (4,) 4\n",
            " Discriminator_p:0 () 1.0\n",
            "/device:GPU:0 Discriminator.0.resdown1.conv1.Filters:0 (3, 3, 3, 256) 6912\n",
            "/device:GPU:0 Discriminator.0.resdown1.conv1.Filters.u_var:0 (27, 1) 27\n",
            "/device:GPU:0 Discriminator.0.resdown1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.0.resdown1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.0.resdown1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.0.resdown1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.0.resdown1.conv_sc.Filters:0 (1, 1, 3, 256) 768\n",
            "/device:GPU:0 Discriminator.0.resdown1.conv_sc.Filters.u_var:0 (3, 1) 3\n",
            "/device:GPU:0 Discriminator.0.resdown1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.0.resdown2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.0.resdown2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.0.resdown2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.0.resdown2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.0.resdown2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.0.resdown2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.0.resdown2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Discriminator.0.resdown2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator.0.resdown2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.0.res8.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.0.res8.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.0.res8.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.0.res8.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.0.res8.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.0.res8.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.0.res16.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.0.res16.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.0.res16.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.0.res16.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.0.res16.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.0.res16.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.0.embed.W:0 (10, 256) 2560\n",
            "/device:GPU:0 Discriminator.0.embed.W.u_var:0 (10, 1) 10\n",
            "/device:GPU:0 Discriminator0.Output.W:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator0.Output.W.u_var:0 (1, 1) 1\n",
            "/device:GPU:0 Discriminator0.Output.b:0 (1,) 1\n",
            "/device:GPU:0 Discriminator.0.MHINGEGANOutput.W:0 (256, 11) 2816\n",
            "/device:GPU:0 Discriminator.0.MHINGEGANOutput.W.u_var:0 (1, 11) 11\n",
            "/device:GPU:0 Discriminator.0.MHINGEGANOutput.b:0 (11,) 11\n",
            "/device:GPU:0 Discriminator.1.resdown1.conv1.Filters:0 (3, 3, 3, 256) 6912\n",
            "/device:GPU:0 Discriminator.1.resdown1.conv1.Filters.u_var:0 (27, 1) 27\n",
            "/device:GPU:0 Discriminator.1.resdown1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.1.resdown1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.1.resdown1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.1.resdown1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.1.resdown1.conv_sc.Filters:0 (1, 1, 3, 256) 768\n",
            "/device:GPU:0 Discriminator.1.resdown1.conv_sc.Filters.u_var:0 (3, 1) 3\n",
            "/device:GPU:0 Discriminator.1.resdown1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.1.resdown2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.1.resdown2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.1.resdown2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.1.resdown2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.1.resdown2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.1.resdown2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.1.resdown2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Discriminator.1.resdown2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator.1.resdown2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.1.res8.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.1.res8.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.1.res8.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.1.res8.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.1.res8.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.1.res8.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.1.res16.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.1.res16.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.1.res16.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.1.res16.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.1.res16.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.1.res16.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.1.embed.W:0 (10, 256) 2560\n",
            "/device:GPU:0 Discriminator.1.embed.W.u_var:0 (10, 1) 10\n",
            "/device:GPU:0 Discriminator1.Output.W:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator1.Output.W.u_var:0 (1, 1) 1\n",
            "/device:GPU:0 Discriminator1.Output.b:0 (1,) 1\n",
            "/device:GPU:0 Discriminator.1.MHINGEGANOutput.W:0 (256, 11) 2816\n",
            "/device:GPU:0 Discriminator.1.MHINGEGANOutput.W.u_var:0 (1, 11) 11\n",
            "/device:GPU:0 Discriminator.1.MHINGEGANOutput.b:0 (11,) 11\n",
            "/device:GPU:0 Discriminator.2.resdown1.conv1.Filters:0 (3, 3, 3, 256) 6912\n",
            "/device:GPU:0 Discriminator.2.resdown1.conv1.Filters.u_var:0 (27, 1) 27\n",
            "/device:GPU:0 Discriminator.2.resdown1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.2.resdown1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.2.resdown1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.2.resdown1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.2.resdown1.conv_sc.Filters:0 (1, 1, 3, 256) 768\n",
            "/device:GPU:0 Discriminator.2.resdown1.conv_sc.Filters.u_var:0 (3, 1) 3\n",
            "/device:GPU:0 Discriminator.2.resdown1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.2.resdown2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.2.resdown2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.2.resdown2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.2.resdown2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.2.resdown2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.2.resdown2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.2.resdown2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Discriminator.2.resdown2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator.2.resdown2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.2.res8.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.2.res8.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.2.res8.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.2.res8.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.2.res8.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.2.res8.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.2.res16.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.2.res16.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.2.res16.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.2.res16.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.2.res16.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.2.res16.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.2.embed.W:0 (10, 256) 2560\n",
            "/device:GPU:0 Discriminator.2.embed.W.u_var:0 (10, 1) 10\n",
            "/device:GPU:0 Discriminator2.Output.W:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator2.Output.W.u_var:0 (1, 1) 1\n",
            "/device:GPU:0 Discriminator2.Output.b:0 (1,) 1\n",
            "/device:GPU:0 Discriminator.2.MHINGEGANOutput.W:0 (256, 11) 2816\n",
            "/device:GPU:0 Discriminator.2.MHINGEGANOutput.W.u_var:0 (1, 11) 11\n",
            "/device:GPU:0 Discriminator.2.MHINGEGANOutput.b:0 (11,) 11\n",
            "/device:GPU:0 Discriminator.3.resdown1.conv1.Filters:0 (3, 3, 3, 256) 6912\n",
            "/device:GPU:0 Discriminator.3.resdown1.conv1.Filters.u_var:0 (27, 1) 27\n",
            "/device:GPU:0 Discriminator.3.resdown1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.3.resdown1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.3.resdown1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.3.resdown1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.3.resdown1.conv_sc.Filters:0 (1, 1, 3, 256) 768\n",
            "/device:GPU:0 Discriminator.3.resdown1.conv_sc.Filters.u_var:0 (3, 1) 3\n",
            "/device:GPU:0 Discriminator.3.resdown1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.3.resdown2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.3.resdown2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.3.resdown2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.3.resdown2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.3.resdown2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.3.resdown2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.3.resdown2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Discriminator.3.resdown2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator.3.resdown2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.3.res8.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.3.res8.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.3.res8.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.3.res8.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.3.res8.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.3.res8.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.3.res16.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.3.res16.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.3.res16.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.3.res16.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.3.res16.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.3.res16.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.3.embed.W:0 (10, 256) 2560\n",
            "/device:GPU:0 Discriminator.3.embed.W.u_var:0 (10, 1) 10\n",
            "/device:GPU:0 Discriminator3.Output.W:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator3.Output.W.u_var:0 (1, 1) 1\n",
            "/device:GPU:0 Discriminator3.Output.b:0 (1,) 1\n",
            "/device:GPU:0 Discriminator.3.MHINGEGANOutput.W:0 (256, 11) 2816\n",
            "/device:GPU:0 Discriminator.3.MHINGEGANOutput.W.u_var:0 (1, 11) 11\n",
            "/device:GPU:0 Discriminator.3.MHINGEGANOutput.b:0 (11,) 11\n",
            "/device:GPU:0 Discriminator.4.resdown1.conv1.Filters:0 (3, 3, 3, 256) 6912\n",
            "/device:GPU:0 Discriminator.4.resdown1.conv1.Filters.u_var:0 (27, 1) 27\n",
            "/device:GPU:0 Discriminator.4.resdown1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.4.resdown1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.4.resdown1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.4.resdown1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.4.resdown1.conv_sc.Filters:0 (1, 1, 3, 256) 768\n",
            "/device:GPU:0 Discriminator.4.resdown1.conv_sc.Filters.u_var:0 (3, 1) 3\n",
            "/device:GPU:0 Discriminator.4.resdown1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.4.resdown2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.4.resdown2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.4.resdown2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.4.resdown2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.4.resdown2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.4.resdown2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.4.resdown2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Discriminator.4.resdown2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator.4.resdown2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.4.res8.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.4.res8.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.4.res8.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.4.res8.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.4.res8.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.4.res8.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.4.res16.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.4.res16.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.4.res16.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.4.res16.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.4.res16.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.4.res16.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.4.embed.W:0 (10, 256) 2560\n",
            "/device:GPU:0 Discriminator.4.embed.W.u_var:0 (10, 1) 10\n",
            "/device:GPU:0 Discriminator4.Output.W:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator4.Output.W.u_var:0 (1, 1) 1\n",
            "/device:GPU:0 Discriminator4.Output.b:0 (1,) 1\n",
            "/device:GPU:0 Discriminator.4.MHINGEGANOutput.W:0 (256, 11) 2816\n",
            "/device:GPU:0 Discriminator.4.MHINGEGANOutput.W.u_var:0 (1, 11) 11\n",
            "/device:GPU:0 Discriminator.4.MHINGEGANOutput.b:0 (11,) 11\n",
            "/device:GPU:0 Discriminator.5.resdown1.conv1.Filters:0 (3, 3, 3, 256) 6912\n",
            "/device:GPU:0 Discriminator.5.resdown1.conv1.Filters.u_var:0 (27, 1) 27\n",
            "/device:GPU:0 Discriminator.5.resdown1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.5.resdown1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.5.resdown1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.5.resdown1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.5.resdown1.conv_sc.Filters:0 (1, 1, 3, 256) 768\n",
            "/device:GPU:0 Discriminator.5.resdown1.conv_sc.Filters.u_var:0 (3, 1) 3\n",
            "/device:GPU:0 Discriminator.5.resdown1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.5.resdown2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.5.resdown2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.5.resdown2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.5.resdown2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.5.resdown2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.5.resdown2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.5.resdown2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Discriminator.5.resdown2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator.5.resdown2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.5.res8.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.5.res8.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.5.res8.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.5.res8.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.5.res8.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.5.res8.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.5.res16.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.5.res16.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.5.res16.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.5.res16.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.5.res16.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.5.res16.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.5.embed.W:0 (10, 256) 2560\n",
            "/device:GPU:0 Discriminator.5.embed.W.u_var:0 (10, 1) 10\n",
            "/device:GPU:0 Discriminator5.Output.W:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator5.Output.W.u_var:0 (1, 1) 1\n",
            "/device:GPU:0 Discriminator5.Output.b:0 (1,) 1\n",
            "/device:GPU:0 Discriminator.5.MHINGEGANOutput.W:0 (256, 11) 2816\n",
            "/device:GPU:0 Discriminator.5.MHINGEGANOutput.W.u_var:0 (1, 11) 11\n",
            "/device:GPU:0 Discriminator.5.MHINGEGANOutput.b:0 (11,) 11\n",
            "/device:GPU:0 Discriminator.6.resdown1.conv1.Filters:0 (3, 3, 3, 256) 6912\n",
            "/device:GPU:0 Discriminator.6.resdown1.conv1.Filters.u_var:0 (27, 1) 27\n",
            "/device:GPU:0 Discriminator.6.resdown1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.6.resdown1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.6.resdown1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.6.resdown1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.6.resdown1.conv_sc.Filters:0 (1, 1, 3, 256) 768\n",
            "/device:GPU:0 Discriminator.6.resdown1.conv_sc.Filters.u_var:0 (3, 1) 3\n",
            "/device:GPU:0 Discriminator.6.resdown1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.6.resdown2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.6.resdown2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.6.resdown2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.6.resdown2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.6.resdown2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.6.resdown2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.6.resdown2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Discriminator.6.resdown2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator.6.resdown2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.6.res8.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.6.res8.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.6.res8.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.6.res8.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.6.res8.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.6.res8.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.6.res16.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.6.res16.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.6.res16.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.6.res16.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.6.res16.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.6.res16.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.6.embed.W:0 (10, 256) 2560\n",
            "/device:GPU:0 Discriminator.6.embed.W.u_var:0 (10, 1) 10\n",
            "/device:GPU:0 Discriminator6.Output.W:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator6.Output.W.u_var:0 (1, 1) 1\n",
            "/device:GPU:0 Discriminator6.Output.b:0 (1,) 1\n",
            "/device:GPU:0 Discriminator.6.MHINGEGANOutput.W:0 (256, 11) 2816\n",
            "/device:GPU:0 Discriminator.6.MHINGEGANOutput.W.u_var:0 (1, 11) 11\n",
            "/device:GPU:0 Discriminator.6.MHINGEGANOutput.b:0 (11,) 11\n",
            "/device:GPU:0 Discriminator.7.resdown1.conv1.Filters:0 (3, 3, 3, 256) 6912\n",
            "/device:GPU:0 Discriminator.7.resdown1.conv1.Filters.u_var:0 (27, 1) 27\n",
            "/device:GPU:0 Discriminator.7.resdown1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.7.resdown1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.7.resdown1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.7.resdown1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.7.resdown1.conv_sc.Filters:0 (1, 1, 3, 256) 768\n",
            "/device:GPU:0 Discriminator.7.resdown1.conv_sc.Filters.u_var:0 (3, 1) 3\n",
            "/device:GPU:0 Discriminator.7.resdown1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.7.resdown2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.7.resdown2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.7.resdown2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.7.resdown2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.7.resdown2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.7.resdown2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.7.resdown2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Discriminator.7.resdown2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator.7.resdown2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.7.res8.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.7.res8.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.7.res8.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.7.res8.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.7.res8.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.7.res8.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.7.res16.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.7.res16.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.7.res16.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.7.res16.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.7.res16.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.7.res16.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.7.embed.W:0 (10, 256) 2560\n",
            "/device:GPU:0 Discriminator.7.embed.W.u_var:0 (10, 1) 10\n",
            "/device:GPU:0 Discriminator7.Output.W:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator7.Output.W.u_var:0 (1, 1) 1\n",
            "/device:GPU:0 Discriminator7.Output.b:0 (1,) 1\n",
            "/device:GPU:0 Discriminator.7.MHINGEGANOutput.W:0 (256, 11) 2816\n",
            "/device:GPU:0 Discriminator.7.MHINGEGANOutput.W.u_var:0 (1, 11) 11\n",
            "/device:GPU:0 Discriminator.7.MHINGEGANOutput.b:0 (11,) 11\n",
            "/device:GPU:0 Discriminator.8.resdown1.conv1.Filters:0 (3, 3, 3, 256) 6912\n",
            "/device:GPU:0 Discriminator.8.resdown1.conv1.Filters.u_var:0 (27, 1) 27\n",
            "/device:GPU:0 Discriminator.8.resdown1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.8.resdown1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.8.resdown1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.8.resdown1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.8.resdown1.conv_sc.Filters:0 (1, 1, 3, 256) 768\n",
            "/device:GPU:0 Discriminator.8.resdown1.conv_sc.Filters.u_var:0 (3, 1) 3\n",
            "/device:GPU:0 Discriminator.8.resdown1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.8.resdown2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.8.resdown2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.8.resdown2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.8.resdown2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.8.resdown2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.8.resdown2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.8.resdown2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Discriminator.8.resdown2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator.8.resdown2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.8.res8.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.8.res8.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.8.res8.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.8.res8.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.8.res8.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.8.res8.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.8.res16.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.8.res16.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.8.res16.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.8.res16.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.8.res16.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.8.res16.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.8.embed.W:0 (10, 256) 2560\n",
            "/device:GPU:0 Discriminator.8.embed.W.u_var:0 (10, 1) 10\n",
            "/device:GPU:0 Discriminator8.Output.W:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator8.Output.W.u_var:0 (1, 1) 1\n",
            "/device:GPU:0 Discriminator8.Output.b:0 (1,) 1\n",
            "/device:GPU:0 Discriminator.8.MHINGEGANOutput.W:0 (256, 11) 2816\n",
            "/device:GPU:0 Discriminator.8.MHINGEGANOutput.W.u_var:0 (1, 11) 11\n",
            "/device:GPU:0 Discriminator.8.MHINGEGANOutput.b:0 (11,) 11\n",
            "/device:GPU:0 Discriminator.9.resdown1.conv1.Filters:0 (3, 3, 3, 256) 6912\n",
            "/device:GPU:0 Discriminator.9.resdown1.conv1.Filters.u_var:0 (27, 1) 27\n",
            "/device:GPU:0 Discriminator.9.resdown1.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.9.resdown1.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.9.resdown1.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.9.resdown1.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.9.resdown1.conv_sc.Filters:0 (1, 1, 3, 256) 768\n",
            "/device:GPU:0 Discriminator.9.resdown1.conv_sc.Filters.u_var:0 (3, 1) 3\n",
            "/device:GPU:0 Discriminator.9.resdown1.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.9.resdown2.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.9.resdown2.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.9.resdown2.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.9.resdown2.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.9.resdown2.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.9.resdown2.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.9.resdown2.conv_sc.Filters:0 (1, 1, 256, 256) 65536\n",
            "/device:GPU:0 Discriminator.9.resdown2.conv_sc.Filters.u_var:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator.9.resdown2.conv_sc.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.9.res8.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.9.res8.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.9.res8.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.9.res8.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.9.res8.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.9.res8.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.9.res16.conv1.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.9.res16.conv1.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.9.res16.conv1.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.9.res16.conv2.Filters:0 (3, 3, 256, 256) 589824\n",
            "/device:GPU:0 Discriminator.9.res16.conv2.Filters.u_var:0 (1, 256) 256\n",
            "/device:GPU:0 Discriminator.9.res16.conv2.Biases:0 (256,) 256\n",
            "/device:GPU:0 Discriminator.9.embed.W:0 (10, 256) 2560\n",
            "/device:GPU:0 Discriminator.9.embed.W.u_var:0 (10, 1) 10\n",
            "/device:GPU:0 Discriminator9.Output.W:0 (256, 1) 256\n",
            "/device:GPU:0 Discriminator9.Output.W.u_var:0 (1, 1) 1\n",
            "/device:GPU:0 Discriminator9.Output.b:0 (1,) 1\n",
            "/device:GPU:0 Discriminator.9.MHINGEGANOutput.W:0 (256, 11) 2816\n",
            "/device:GPU:0 Discriminator.9.MHINGEGANOutput.W.u_var:0 (1, 11) 11\n",
            "/device:GPU:0 Discriminator.9.MHINGEGANOutput.b:0 (11,) 11\n",
            "G params total:85,780,830\n",
            "D params total:42,122,896\n",
            "All params total:127,903,726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j25FMZz7JQRl"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoFMiga2JQRq",
        "outputId": "b2a0d11c-4ae2-440a-98d2-77b31687187d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Either restore the last snapshot in snapshot path if there is any or start from scratch\n",
        "g_restore_vars = [var for var in tf.global_variables() if var.name.startswith('G')]\n",
        "d_restore_vars = [var for var in tf.global_variables() if var.name.startswith('D')]\n",
        "g_saver = tf.train.Saver(g_restore_vars,keep_checkpoint_every_n_hours=2)\n",
        "d_saver = tf.train.Saver(d_restore_vars,keep_checkpoint_every_n_hours=2)\n",
        "\n",
        "def take_snapshot():\n",
        "    g_snapshot_path = os.path.join(snapshot_dir,\"iter_\"+ ('%d'%iteration).zfill(int(np.ceil(np.log10(ITERS))+1)) +\"_G.ckpt\")\n",
        "    g_saver.save(session, g_snapshot_path)\n",
        "    d_snapshot_path = os.path.join(snapshot_dir,\"iter_\"+ ('%d'%iteration).zfill(int(np.ceil(np.log10(ITERS))+1)) +\"_D.ckpt\")\n",
        "    d_saver.save(session, d_snapshot_path)\n",
        "    print(\"Snapshot created: %s\" % d_snapshot_path.replace('_D',''))\n",
        "    \n",
        "def build_model(sess):\n",
        "        #self.init_opt()\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        if g_snapshot_path.find('.ckpt') != -1:\n",
        "            g_saver.restore(sess, g_snapshot_path)\n",
        "            d_saver.restore(sess, d_snapshot_path)\n",
        "            istart = g_snapshot_path.rfind('iter_')+5\n",
        "            iend = g_snapshot_path.rfind('_')\n",
        "            _iter = g_snapshot_path[istart:iend]\n",
        "            _iter = int(_iter)\n",
        "        else:\n",
        "            print(\"Created model with fresh parameters.\")\n",
        "            _iter = 0\n",
        "        #print(\"Go to iteration %d\" % iter)\n",
        "        return _iter\n",
        "    \n",
        "# snapshot at least every 2 hours\n",
        "\n",
        "#Restore params if there are\n",
        "lib.plot._iter[0]=iteration=build_model(session)\n",
        "summary_writer = tf.summary.FileWriter(log_dir+'summaries')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created model with fresh parameters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWe55tC6JQRt"
      },
      "source": [
        "code_gradient_penalty=code_disc_cost=cl_cost=cl_real_accuracy=cl_fake_accuracy=cl_accuracy=cl_adv_accuracy=rec_loss=pred_labels=cl_train_op=tf.zeros([],dtype=dtype)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XggdHg5SJQRw",
        "outputId": "ec210c72-0bed-4326-c1f3-8e021ee91684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(session.run(g_w))\n",
        "print(session.run(d_w))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eW7ID891JQRz",
        "outputId": "b4e05219-6959-4df0-d030-ea3a9252f443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data_batch=np.zeros([NUM_GENERATORS*BATCH_SIZE,DATA_DIM], dtype=dtype)\n",
        "train_label_batch=np.zeros(NUM_GENERATORS*BATCH_SIZE,dtype=int)\n",
        "\n",
        "# training\n",
        "\n",
        "while iteration <=ITERS:\n",
        "    running_lr=gan_learning_rate#*(1-iteration/ITERS)\n",
        "    start_time = time.time()\n",
        "    iteration+=1\n",
        "\n",
        "    # Train generator \n",
        "    for i in range(N_GENERATOR):\n",
        "        session.run(gen_train_op,\\\n",
        "        feed_dict={real_data:train_data_batch,\n",
        "        lr:running_lr, curr_iter:iteration})\n",
        "        \n",
        "    # Train critic\n",
        "    for i in range(N_CRITIC):\n",
        "        if GET_LABELS:\n",
        "            for k in range(NUM_GENERATORS):\n",
        "                train_data_batch[k*BATCH_SIZE:(k+1)*BATCH_SIZE],train_label_batch[k*BATCH_SIZE:(k+1)*BATCH_SIZE]=next(train_gen)\n",
        "        else:\n",
        "            train_data_batch=next(train_gen)\n",
        "        \n",
        "        session.run(disc_train_op,\n",
        "            feed_dict={lr: running_lr,\\\n",
        "                       real_data:train_data_batch,\\\n",
        "                       real_labels:train_label_batch, update_p:(N_CRITIC*iteration+i)%4==0 and ADA,\\\n",
        "                      }\n",
        "        )\n",
        "                    \n",
        "    if iteration<10 or iteration % log_interval == 0:\n",
        "        iter_end_time = time.time()\n",
        "        lib.plot.plot('iter_time', iter_end_time - start_time) # this is for calculating iteration time, should not include time for testing, etc.\n",
        "        warmup()\n",
        "        lib.plot.plot('warmup_time', time.time() - iter_end_time)\n",
        "        print(session.run(g_w))\n",
        "        print(session.run(d_w))\n",
        "        #print(session.run([d_p, indicator]))\n",
        "        generate_image(iteration)\n",
        "        _gen_cost,\\\n",
        "        _disc_real,_indicator_stat,_disc_fake, _gradient_penalty, _wass_dist, _disc_cost,\\\n",
        "        _disc_real_acc,_disc_fake_acc,_disc_acc,\\\n",
        "        _ac_cost, _ac_real_acc, _ac_fake_acc,\\\n",
        "        = session.run([ gen_cost,\\\n",
        "        disc_real, indicator_stat, disc_fake, gradient_penalty, wass_dist, disc_cost,\\\n",
        "        disc_real_accuracy,disc_fake_accuracy,disc_accuracy,\\\n",
        "        ac_cost, ac_real_acc, ac_fake_acc],\n",
        "        feed_dict={real_data:train_data_batch,real_labels:train_label_batch, }\n",
        "        )\n",
        "        \n",
        "        lib.plot.plot('gen_cost', _gen_cost)\n",
        "        # Write logs and save samples\n",
        "        if N_CRITIC>0:\n",
        "            lib.plot.plot('disc_cost', _disc_cost)\n",
        "            lib.plot.plot('gradient_penalty', _gradient_penalty)   \n",
        "            lib.plot.plot('disc_real', np.mean(_disc_real))\n",
        "            lib.plot.plot('indicator_stat', np.mean(_indicator_stat))\n",
        "            lib.plot.plot('disc_fake', np.mean(_disc_fake))\n",
        "            lib.plot.plot('disc_fake_acc', _disc_fake_acc)\n",
        "            lib.plot.plot('disc_real_acc', _disc_real_acc)\n",
        "            lib.plot.plot('disc_acc', _disc_acc)\n",
        "            lib.plot.plot('D(Xr)-D(Xf)', np.mean(_disc_real)-np.mean(_disc_fake))\n",
        "            record['D(Xr)-D(Xf)'][counter % num_counter]=np.mean(_disc_real)-np.mean(_disc_fake)\n",
        "            lib.plot.plot('Wass_dist', _wass_dist)\n",
        "            record['Wass_dist'][counter % num_counter]=_wass_dist\n",
        "            lib.plot.plot('ac_cost', _ac_cost) \n",
        "            lib.plot.plot('ac_real_acc', _ac_real_acc) \n",
        "            lib.plot.plot('ac_fake_acc', _ac_fake_acc)      \n",
        "        if iteration % (10000) == 0:  \n",
        "            if DATASET in IMAGE_DATASETS  and NUM_CHANNELS==3:\n",
        "                _inception_score = get_inception_score(BATCH_SIZE*INCEPTION_BATCHES)\n",
        "                print('Inception Score: mean=%f, std=%f'% _inception_score)\n",
        "                lib.plot.plot('inception score', _inception_score[0])\n",
        "                record['Inception score'][counter % num_counter],record['IS_std'][counter % num_counter]=_inception_score\n",
        "            for dst in ['training_set','test_set']:\n",
        "                if dst=='test_set':\n",
        "                    _gen = inf_gen('TEST') \n",
        "                else:\n",
        "                    _gen = inf_gen('TRAIN')\n",
        "                _fid = get_fid(BATCH_SIZE*FID_BATCHES,_gen)\n",
        "                record['FID_'+dst][counter % num_counter]=_fid\n",
        "                print('FID %s=%f'% (dst, _fid))\n",
        "                lib.plot.plot('fid_%s'%dst, _fid)\n",
        "            counter+=1\n",
        "\n",
        "        lib.plot.flush(log_dir)\n",
        "    lib.plot.tick()\n",
        "    # save a snapshot\n",
        "    if iteration % snapshot_interval == 0:\n",
        "        pass\n",
        "        take_snapshot()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10002486 0.10002054 0.09999403 0.09997991 0.09995817 0.10000695\n",
            " 0.09995683 0.10005778 0.10000721 0.09999375]\n",
            "iter 0\titer_time=229.97, warmup_time=53.54, gen_cost=20.29, disc_cost=11.68, gradient_penalty=0.00, disc_real=-0.26, indicator_stat=3.41, disc_fake=0.10, disc_fake_acc=0.50, disc_real_acc=0.50, disc_acc=0.50, D(Xr)-D(Xf)=-0.35, Wass_dist=0.00, ac_cost=7.82, ac_real_acc=0.05, ac_fake_acc=0.02,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10004098 0.10001126 0.10000012 0.09996413 0.10000236 0.09999436\n",
            " 0.09994287 0.10004301 0.09999803 0.10000286]\n",
            "iter 1\titer_time=1.26, warmup_time=8.77, gen_cost=13.63, disc_cost=7.78, gradient_penalty=0.00, disc_real=-0.66, indicator_stat=2.16, disc_fake=-1.00, disc_fake_acc=0.60, disc_real_acc=0.40, disc_acc=0.50, D(Xr)-D(Xf)=0.34, Wass_dist=0.00, ac_cost=4.43, ac_real_acc=0.11, ac_fake_acc=0.03,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10002328 0.10009956 0.09997042 0.09994654 0.09997274 0.09998222\n",
            " 0.09995106 0.10004316 0.10000273 0.10000826]\n",
            "iter 2\titer_time=1.23, warmup_time=8.92, gen_cost=10.70, disc_cost=7.04, gradient_penalty=0.00, disc_real=-0.76, indicator_stat=1.50, disc_fake=-0.75, disc_fake_acc=0.70, disc_real_acc=0.40, disc_acc=0.55, D(Xr)-D(Xf)=-0.01, Wass_dist=0.00, ac_cost=3.70, ac_real_acc=0.14, ac_fake_acc=0.01,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10003223 0.10016014 0.0999773  0.09995324 0.09993074 0.09999459\n",
            " 0.09993314 0.1000459  0.09997246 0.10000023]\n",
            "iter 3\titer_time=1.21, warmup_time=8.81, gen_cost=8.98, disc_cost=5.93, gradient_penalty=0.00, disc_real=-0.42, indicator_stat=1.69, disc_fake=-0.77, disc_fake_acc=0.70, disc_real_acc=0.50, disc_acc=0.60, D(Xr)-D(Xf)=0.35, Wass_dist=0.00, ac_cost=2.91, ac_real_acc=0.13, ac_fake_acc=0.04,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.1000485  0.10014285 0.09998761 0.09998158 0.09992688 0.09994796\n",
            " 0.09990221 0.10006726 0.09997845 0.10001677]\n",
            "iter 4\titer_time=1.24, warmup_time=8.74, gen_cost=7.51, disc_cost=5.20, gradient_penalty=0.00, disc_real=-0.44, indicator_stat=1.42, disc_fake=-0.76, disc_fake_acc=0.80, disc_real_acc=0.40, disc_acc=0.60, D(Xr)-D(Xf)=0.33, Wass_dist=0.00, ac_cost=2.33, ac_real_acc=0.15, ac_fake_acc=0.02,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10006644 0.100105   0.0999912  0.0999964  0.09994832 0.09988671\n",
            " 0.09992205 0.1000739  0.09994356 0.10006639]\n",
            "iter 5\titer_time=1.22, warmup_time=8.85, gen_cost=7.51, disc_cost=5.31, gradient_penalty=0.00, disc_real=-0.61, indicator_stat=1.74, disc_fake=-0.85, disc_fake_acc=0.80, disc_real_acc=0.30, disc_acc=0.55, D(Xr)-D(Xf)=0.24, Wass_dist=0.00, ac_cost=2.51, ac_real_acc=0.08, ac_fake_acc=0.01,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10006639 0.10006461 0.0999885  0.100053   0.09994298 0.09984645\n",
            " 0.09987812 0.10007865 0.09997587 0.10010546]\n",
            "iter 6\titer_time=1.23, warmup_time=8.94, gen_cost=6.51, disc_cost=4.56, gradient_penalty=0.00, disc_real=-0.38, indicator_stat=1.84, disc_fake=-0.73, disc_fake_acc=0.80, disc_real_acc=0.30, disc_acc=0.55, D(Xr)-D(Xf)=0.36, Wass_dist=0.00, ac_cost=2.01, ac_real_acc=0.08, ac_fake_acc=0.02,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10008797 0.10005985 0.09998076 0.10008351 0.09994035 0.0998444\n",
            " 0.09987314 0.10009008 0.09996758 0.10007232]\n",
            "iter 7\titer_time=1.22, warmup_time=8.73, gen_cost=6.02, disc_cost=4.85, gradient_penalty=0.00, disc_real=-0.14, indicator_stat=1.34, disc_fake=-0.38, disc_fake_acc=0.80, disc_real_acc=0.30, disc_acc=0.55, D(Xr)-D(Xf)=0.24, Wass_dist=0.00, ac_cost=1.97, ac_real_acc=0.11, ac_fake_acc=0.01,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10009534 0.10011594 0.09995595 0.10007738 0.09997527 0.09986115\n",
            " 0.09984476 0.10008775 0.09991378 0.10007264]\n",
            "iter 8\titer_time=1.22, warmup_time=8.79, gen_cost=5.01, disc_cost=4.55, gradient_penalty=0.00, disc_real=-0.17, indicator_stat=1.07, disc_fake=-0.37, disc_fake_acc=0.70, disc_real_acc=0.40, disc_acc=0.55, D(Xr)-D(Xf)=0.20, Wass_dist=0.00, ac_cost=1.73, ac_real_acc=0.15, ac_fake_acc=0.01,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.09950235 0.10415807 0.10054126 0.10223402 0.09762061 0.09645796\n",
            " 0.10187039 0.09609817 0.09983023 0.10168695]\n",
            "iter 999\titer_time=1.32, warmup_time=8.82, gen_cost=2.65, disc_cost=3.77, gradient_penalty=0.00, disc_real=-0.22, indicator_stat=0.89, disc_fake=-0.28, disc_fake_acc=0.80, disc_real_acc=0.30, disc_acc=0.55, D(Xr)-D(Xf)=0.05, Wass_dist=0.00, ac_cost=1.20, ac_real_acc=0.32, ac_fake_acc=0.03,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.099369   0.10344444 0.10019325 0.10243841 0.09670649 0.09638644\n",
            " 0.1025221  0.09697131 0.10010743 0.10186116]\n",
            "iter 1999\titer_time=1.30, warmup_time=8.78, gen_cost=2.29, disc_cost=3.77, gradient_penalty=0.00, disc_real=-0.11, indicator_stat=0.65, disc_fake=-0.19, disc_fake_acc=0.70, disc_real_acc=0.40, disc_acc=0.55, D(Xr)-D(Xf)=0.08, Wass_dist=0.00, ac_cost=1.04, ac_real_acc=0.42, ac_fake_acc=0.08,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.09987799 0.1032743  0.10092086 0.10268711 0.09637456 0.0950617\n",
            " 0.10264382 0.09638187 0.10013092 0.10264689]\n",
            "iter 2999\titer_time=1.31, warmup_time=8.55, gen_cost=2.21, disc_cost=3.79, gradient_penalty=0.00, disc_real=-0.14, indicator_stat=0.55, disc_fake=-0.16, disc_fake_acc=0.70, disc_real_acc=0.30, disc_acc=0.50, D(Xr)-D(Xf)=0.02, Wass_dist=0.00, ac_cost=0.97, ac_real_acc=0.44, ac_fake_acc=0.11,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10030725 0.10339142 0.10103354 0.10336443 0.09553838 0.09426504\n",
            " 0.10248583 0.09593315 0.10066256 0.10301832]\n",
            "iter 3999\titer_time=1.30, warmup_time=8.51, gen_cost=2.35, disc_cost=3.72, gradient_penalty=0.00, disc_real=-0.14, indicator_stat=0.65, disc_fake=-0.18, disc_fake_acc=0.70, disc_real_acc=0.40, disc_acc=0.55, D(Xr)-D(Xf)=0.04, Wass_dist=0.00, ac_cost=0.98, ac_real_acc=0.47, ac_fake_acc=0.11,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.09961686 0.1034617  0.10131204 0.10453817 0.09509178 0.0938095\n",
            " 0.10292629 0.09581577 0.09980538 0.10362252]\n",
            "iter 4999\titer_time=1.31, warmup_time=8.50, gen_cost=2.52, disc_cost=3.70, gradient_penalty=0.00, disc_real=-0.20, indicator_stat=0.75, disc_fake=-0.27, disc_fake_acc=0.80, disc_real_acc=0.20, disc_acc=0.50, D(Xr)-D(Xf)=0.08, Wass_dist=0.00, ac_cost=0.99, ac_real_acc=0.49, ac_fake_acc=0.09,\n",
            "Snapshot created: /content/drive/Shared drives/shared/mix-gan/logs/MIX-MHingeGAN-10G10D-CIFAR-10-conditional-CIFAR-10/summaries/iter_0005000.ckpt\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10010277 0.10331611 0.10064065 0.10618858 0.09446173 0.09257339\n",
            " 0.10327728 0.09572402 0.1000545  0.10366103]\n",
            "iter 5999\titer_time=1.29, warmup_time=8.56, gen_cost=2.45, disc_cost=3.70, gradient_penalty=0.00, disc_real=-0.26, indicator_stat=0.54, disc_fake=-0.29, disc_fake_acc=0.80, disc_real_acc=0.30, disc_acc=0.55, D(Xr)-D(Xf)=0.03, Wass_dist=0.00, ac_cost=0.82, ac_real_acc=0.58, ac_fake_acc=0.19,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.09948287 0.1027167  0.10011026 0.10660302 0.09438322 0.09259743\n",
            " 0.10315445 0.09541325 0.10018368 0.10535511]\n",
            "iter 6999\titer_time=1.29, warmup_time=8.45, gen_cost=2.76, disc_cost=3.52, gradient_penalty=0.00, disc_real=-0.22, indicator_stat=0.78, disc_fake=-0.24, disc_fake_acc=0.80, disc_real_acc=0.20, disc_acc=0.50, D(Xr)-D(Xf)=0.02, Wass_dist=0.00, ac_cost=0.81, ac_real_acc=0.60, ac_fake_acc=0.11,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10027576 0.10291567 0.10099634 0.10814665 0.09312124 0.09199283\n",
            " 0.10282196 0.09466168 0.09958203 0.10548586]\n",
            "iter 7999\titer_time=1.29, warmup_time=8.48, gen_cost=2.71, disc_cost=3.54, gradient_penalty=0.00, disc_real=-0.23, indicator_stat=0.64, disc_fake=-0.27, disc_fake_acc=0.60, disc_real_acc=0.30, disc_acc=0.45, D(Xr)-D(Xf)=0.03, Wass_dist=0.00, ac_cost=0.72, ac_real_acc=0.66, ac_fake_acc=0.17,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10003819 0.10346828 0.10029814 0.10928821 0.09243106 0.09087954\n",
            " 0.10349958 0.09502399 0.09896744 0.10610559]\n",
            "iter 8999\titer_time=1.30, warmup_time=8.51, gen_cost=2.65, disc_cost=3.48, gradient_penalty=0.00, disc_real=-0.15, indicator_stat=0.58, disc_fake=-0.27, disc_fake_acc=0.80, disc_real_acc=0.40, disc_acc=0.60, D(Xr)-D(Xf)=0.11, Wass_dist=0.00, ac_cost=0.61, ac_real_acc=0.73, ac_fake_acc=0.18,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10031828 0.10398028 0.09997622 0.1113453  0.09216498 0.09066338\n",
            " 0.10380621 0.09458995 0.09716744 0.10598794]\n",
            "Calculating Inception Score with 50000 images in 10 splits\n",
            "Inception Score calculation time: 34.279177 s\n",
            "Inception Score: mean=5.291157, std=0.044144\n",
            "Calculating FID with 50000 images from each distribution\n",
            "FID calculation time: 64.138251 s\n",
            "FID training_set=55.543701\n",
            "Calculating FID with 50000 images from each distribution\n",
            "FID calculation time: 42.204264 s\n",
            "FID test_set=57.657131\n",
            "iter 9999\titer_time=1.30, warmup_time=169.02, gen_cost=2.84, disc_cost=3.41, gradient_penalty=0.00, disc_real=-0.18, indicator_stat=0.64, disc_fake=-0.28, disc_fake_acc=0.70, disc_real_acc=0.40, disc_acc=0.55, D(Xr)-D(Xf)=0.10, Wass_dist=0.00, ac_cost=0.57, ac_real_acc=0.77, ac_fake_acc=0.17, inception score=5.29, fid_training_set=55.54, fid_test_set=57.66,\n",
            "Snapshot created: /content/drive/Shared drives/shared/mix-gan/logs/MIX-MHingeGAN-10G10D-CIFAR-10-conditional-CIFAR-10/summaries/iter_0010000.ckpt\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10070773 0.10332871 0.10032458 0.11241222 0.09220895 0.08966732\n",
            " 0.10398491 0.09365974 0.09656139 0.10714446]\n",
            "iter 10999\titer_time=1.30, warmup_time=8.49, gen_cost=3.11, disc_cost=3.46, gradient_penalty=0.00, disc_real=-0.18, indicator_stat=0.67, disc_fake=-0.23, disc_fake_acc=0.70, disc_real_acc=0.40, disc_acc=0.55, D(Xr)-D(Xf)=0.05, Wass_dist=0.00, ac_cost=0.58, ac_real_acc=0.74, ac_fake_acc=0.20,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10096146 0.10336024 0.09929086 0.11412676 0.09208328 0.08941721\n",
            " 0.10368362 0.0944844  0.09574782 0.10684446]\n",
            "iter 11999\titer_time=1.29, warmup_time=8.43, gen_cost=3.12, disc_cost=3.30, gradient_penalty=0.00, disc_real=-0.24, indicator_stat=0.74, disc_fake=-0.33, disc_fake_acc=0.80, disc_real_acc=0.30, disc_acc=0.55, D(Xr)-D(Xf)=0.09, Wass_dist=0.00, ac_cost=0.51, ac_real_acc=0.82, ac_fake_acc=0.15,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.1009848  0.1044632  0.0990847  0.11447201 0.09175062 0.08921918\n",
            " 0.10358104 0.09457823 0.09431686 0.10754937]\n",
            "iter 12999\titer_time=1.21, warmup_time=8.48, gen_cost=3.26, disc_cost=3.28, gradient_penalty=0.00, disc_real=-0.23, indicator_stat=0.75, disc_fake=-0.32, disc_fake_acc=0.80, disc_real_acc=0.20, disc_acc=0.50, D(Xr)-D(Xf)=0.10, Wass_dist=0.00, ac_cost=0.46, ac_real_acc=0.82, ac_fake_acc=0.17,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10113976 0.10352018 0.09903859 0.11680076 0.09107053 0.08917782\n",
            " 0.10405157 0.09402432 0.09366615 0.10751026]\n",
            "iter 13999\titer_time=1.21, warmup_time=8.55, gen_cost=3.41, disc_cost=3.21, gradient_penalty=0.00, disc_real=-0.19, indicator_stat=0.95, disc_fake=-0.34, disc_fake_acc=0.80, disc_real_acc=0.30, disc_acc=0.55, D(Xr)-D(Xf)=0.15, Wass_dist=0.00, ac_cost=0.50, ac_real_acc=0.79, ac_fake_acc=0.14,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10189287 0.10436019 0.09873398 0.11714897 0.09073763 0.08948374\n",
            " 0.10374008 0.09331978 0.09205789 0.10852489]\n",
            "iter 14999\titer_time=1.22, warmup_time=8.77, gen_cost=3.48, disc_cost=3.20, gradient_penalty=0.00, disc_real=-0.19, indicator_stat=0.79, disc_fake=-0.37, disc_fake_acc=0.70, disc_real_acc=0.40, disc_acc=0.55, D(Xr)-D(Xf)=0.18, Wass_dist=0.00, ac_cost=0.37, ac_real_acc=0.86, ac_fake_acc=0.19,\n",
            "Snapshot created: /content/drive/Shared drives/shared/mix-gan/logs/MIX-MHingeGAN-10G10D-CIFAR-10-conditional-CIFAR-10/summaries/iter_0015000.ckpt\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.1016221  0.10404474 0.09815482 0.11829021 0.09138983 0.08871581\n",
            " 0.10423639 0.09390385 0.09123049 0.10841174]\n",
            "iter 15999\titer_time=1.20, warmup_time=8.42, gen_cost=3.39, disc_cost=3.23, gradient_penalty=0.00, disc_real=-0.09, indicator_stat=0.68, disc_fake=-0.27, disc_fake_acc=0.60, disc_real_acc=0.50, disc_acc=0.55, D(Xr)-D(Xf)=0.18, Wass_dist=0.00, ac_cost=0.36, ac_real_acc=0.86, ac_fake_acc=0.20,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10259868 0.10362668 0.09760749 0.11955587 0.09055959 0.08931404\n",
            " 0.10367223 0.09345568 0.09010097 0.10950882]\n",
            "iter 16999\titer_time=1.20, warmup_time=8.47, gen_cost=3.71, disc_cost=3.07, gradient_penalty=0.00, disc_real=-0.20, indicator_stat=0.97, disc_fake=-0.29, disc_fake_acc=0.70, disc_real_acc=0.20, disc_acc=0.45, D(Xr)-D(Xf)=0.08, Wass_dist=0.00, ac_cost=0.35, ac_real_acc=0.87, ac_fake_acc=0.14,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10197886 0.10404437 0.09769233 0.1205024  0.0909765  0.08909113\n",
            " 0.1044208  0.094261   0.08922906 0.1078036 ]\n",
            "iter 17999\titer_time=1.20, warmup_time=8.44, gen_cost=3.76, disc_cost=3.11, gradient_penalty=0.00, disc_real=-0.23, indicator_stat=0.96, disc_fake=-0.44, disc_fake_acc=0.60, disc_real_acc=0.50, disc_acc=0.55, D(Xr)-D(Xf)=0.22, Wass_dist=0.00, ac_cost=0.35, ac_real_acc=0.88, ac_fake_acc=0.16,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10268473 0.10406855 0.09710886 0.12098905 0.09076529 0.08763824\n",
            " 0.10422476 0.09414159 0.08920883 0.1091701 ]\n",
            "iter 18999\titer_time=1.19, warmup_time=8.40, gen_cost=3.91, disc_cost=3.01, gradient_penalty=0.00, disc_real=-0.31, indicator_stat=1.15, disc_fake=-0.47, disc_fake_acc=0.70, disc_real_acc=0.40, disc_acc=0.55, D(Xr)-D(Xf)=0.16, Wass_dist=0.00, ac_cost=0.35, ac_real_acc=0.88, ac_fake_acc=0.12,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10251686 0.10455766 0.09712052 0.1216867  0.09022843 0.08863065\n",
            " 0.1040999  0.09411754 0.08761588 0.10942578]\n",
            "Calculating Inception Score with 50000 images in 10 splits\n",
            "Inception Score calculation time: 23.208899 s\n",
            "Inception Score: mean=9.877143, std=0.071567\n",
            "Calculating FID with 50000 images from each distribution\n",
            "FID calculation time: 42.185308 s\n",
            "FID training_set=5.440390\n",
            "Calculating FID with 50000 images from each distribution\n",
            "FID calculation time: 42.085963 s\n",
            "FID test_set=7.506529\n",
            "iter 19999\titer_time=1.20, warmup_time=168.83, gen_cost=3.93, disc_cost=3.01, gradient_penalty=0.00, disc_real=-0.22, indicator_stat=1.05, disc_fake=-0.41, disc_fake_acc=0.80, disc_real_acc=0.20, disc_acc=0.50, D(Xr)-D(Xf)=0.19, Wass_dist=0.00, ac_cost=0.30, ac_real_acc=0.90, ac_fake_acc=0.13, inception score=9.88, fid_training_set=5.44, fid_test_set=7.51,\n",
            "Snapshot created: /content/drive/Shared drives/shared/mix-gan/logs/MIX-MHingeGAN-10G10D-CIFAR-10-conditional-CIFAR-10/summaries/iter_0020000.ckpt\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10354478 0.10356648 0.09752543 0.12223671 0.09066345 0.088263\n",
            " 0.10391497 0.09380352 0.0870926  0.10938902]\n",
            "iter 20999\titer_time=1.20, warmup_time=8.43, gen_cost=4.02, disc_cost=3.04, gradient_penalty=0.00, disc_real=-0.22, indicator_stat=1.09, disc_fake=-0.40, disc_fake_acc=0.70, disc_real_acc=0.30, disc_acc=0.50, D(Xr)-D(Xf)=0.18, Wass_dist=0.00, ac_cost=0.30, ac_real_acc=0.89, ac_fake_acc=0.16,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10358816 0.10425766 0.0968138  0.12269625 0.09034095 0.08817075\n",
            " 0.10456142 0.09414476 0.0862025  0.10922379]\n",
            "iter 21999\titer_time=1.20, warmup_time=8.46, gen_cost=4.20, disc_cost=2.92, gradient_penalty=0.00, disc_real=-0.22, indicator_stat=1.22, disc_fake=-0.42, disc_fake_acc=0.60, disc_real_acc=0.40, disc_acc=0.50, D(Xr)-D(Xf)=0.20, Wass_dist=0.00, ac_cost=0.28, ac_real_acc=0.91, ac_fake_acc=0.12,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10363235 0.10366303 0.09671709 0.1230251  0.09038342 0.08818511\n",
            " 0.10411078 0.09524859 0.08595281 0.10908172]\n",
            "iter 22999\titer_time=1.21, warmup_time=8.42, gen_cost=4.41, disc_cost=2.93, gradient_penalty=0.00, disc_real=-0.26, indicator_stat=1.46, disc_fake=-0.44, disc_fake_acc=0.80, disc_real_acc=0.30, disc_acc=0.55, D(Xr)-D(Xf)=0.19, Wass_dist=0.00, ac_cost=0.34, ac_real_acc=0.88, ac_fake_acc=0.10,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10325008 0.10414651 0.09649504 0.12302718 0.09036338 0.08803446\n",
            " 0.10404755 0.09539525 0.08505489 0.11018574]\n",
            "iter 23999\titer_time=1.20, warmup_time=8.42, gen_cost=4.25, disc_cost=2.92, gradient_penalty=0.00, disc_real=-0.11, indicator_stat=1.26, disc_fake=-0.42, disc_fake_acc=0.60, disc_real_acc=0.50, disc_acc=0.55, D(Xr)-D(Xf)=0.32, Wass_dist=0.00, ac_cost=0.26, ac_real_acc=0.89, ac_fake_acc=0.13,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.1042062  0.10426326 0.09562074 0.12347106 0.08964311 0.0881341\n",
            " 0.10423158 0.09533457 0.08504188 0.1100535 ]\n",
            "iter 24999\titer_time=1.20, warmup_time=8.45, gen_cost=4.41, disc_cost=2.82, gradient_penalty=0.00, disc_real=-0.20, indicator_stat=1.33, disc_fake=-0.47, disc_fake_acc=0.70, disc_real_acc=0.30, disc_acc=0.50, D(Xr)-D(Xf)=0.27, Wass_dist=0.00, ac_cost=0.21, ac_real_acc=0.94, ac_fake_acc=0.10,\n",
            "Snapshot created: /content/drive/Shared drives/shared/mix-gan/logs/MIX-MHingeGAN-10G10D-CIFAR-10-conditional-CIFAR-10/summaries/iter_0025000.ckpt\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10375646 0.1042248  0.09631261 0.12290482 0.09004018 0.08884096\n",
            " 0.10462937 0.09499043 0.08462718 0.10967324]\n",
            "iter 25999\titer_time=1.20, warmup_time=8.44, gen_cost=4.66, disc_cost=2.80, gradient_penalty=0.00, disc_real=-0.37, indicator_stat=1.54, disc_fake=-0.49, disc_fake_acc=0.70, disc_real_acc=0.20, disc_acc=0.45, D(Xr)-D(Xf)=0.12, Wass_dist=0.00, ac_cost=0.24, ac_real_acc=0.92, ac_fake_acc=0.09,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10394798 0.10395277 0.09612352 0.12300052 0.09061148 0.08823135\n",
            " 0.10435084 0.09556554 0.08406104 0.11015492]\n",
            "iter 26999\titer_time=1.24, warmup_time=9.13, gen_cost=4.54, disc_cost=2.84, gradient_penalty=0.00, disc_real=-0.20, indicator_stat=1.39, disc_fake=-0.43, disc_fake_acc=0.70, disc_real_acc=0.40, disc_acc=0.55, D(Xr)-D(Xf)=0.23, Wass_dist=0.00, ac_cost=0.20, ac_real_acc=0.94, ac_fake_acc=0.13,\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "[0.10453303 0.10363796 0.09621298 0.12189936 0.09046479 0.08891916\n",
            " 0.10467985 0.09593619 0.0838917  0.10982505]\n",
            "iter 27999\titer_time=1.24, warmup_time=9.26, gen_cost=4.74, disc_cost=2.79, gradient_penalty=0.00, disc_real=-0.41, indicator_stat=1.58, disc_fake=-0.53, disc_fake_acc=0.70, disc_real_acc=0.50, disc_acc=0.60, D(Xr)-D(Xf)=0.12, Wass_dist=0.00, ac_cost=0.21, ac_real_acc=0.93, ac_fake_acc=0.08,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd6FYpwaWB7O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3XXuzPuJQR4"
      },
      "source": [
        "take_snapshot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VplPhnMV_QA4"
      },
      "source": [
        "get_inception_score(BATCH_SIZE*INCEPTION_BATCHES)\n",
        "for dst in ['training_set','test_set']:\n",
        "  _gen = inf_gen('TRAIN') if dst=='training_set' else inf_gen('TEST')\n",
        "  _fid = get_fid(BATCH_SIZE*FID_BATCHES,_gen)\n",
        "  print('FID %s=%f'% (dst, _fid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EOc_a3vJQR6"
      },
      "source": [
        "get_inception_score(50000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GTMNKY_JQR8"
      },
      "source": [
        "# save statistics into a csv file\n",
        "\n",
        "import csv \n",
        "import codecs\n",
        "from io import StringIO\n",
        "names.sort()\n",
        "eval_mean={}\n",
        "unbiased_std={}\n",
        "for key in record:\n",
        "    for j in range(num_counter):\n",
        "        if record[key][j]==0:\n",
        "            record[key]=record[key][:j]\n",
        "            break\n",
        "    eval_mean[key]=np.mean(record[key])\n",
        "    unbiased_std[key]=np.std(record[key],ddof=1)    \n",
        "\n",
        "class UnicodeWriter:\n",
        "    def __init__(self, f, dialect=csv.excel, encoding=\"utf-8-sig\", **kwds):\n",
        "        self.queue = StringIO()\n",
        "        self.writer = csv.writer(self.queue, dialect=dialect, **kwds)\n",
        "        self.stream = f\n",
        "        self.encoder = codecs.getincrementalencoder(encoding)()\n",
        "    def writerow(self, row):\n",
        "        '''writerow(unicode) -> None\n",
        "        This function takes a Unicode string and encodes it to the output.\n",
        "        '''\n",
        "        self.writer.writerow([s for s in row])\n",
        "        data = self.queue.getvalue()\n",
        "        data = self.encoder.encode(data)\n",
        "        self.stream.write(data)\n",
        "        self.queue.truncate(0)\n",
        "    def writerows(self, rows):\n",
        "        for row in rows:\n",
        "            self.writerow(row)\n",
        "                       \n",
        "with open(log_dir+'stats.csv', 'wb') as csvfile:\n",
        "    spamwriter = UnicodeWriter(csvfile, delimiter=',')\n",
        "    spamwriter.writerow(names)\n",
        "    line=[]\n",
        "    for i in range(len(names)):\n",
        "        line.append(u'%s Â± %s'%(str(round(eval_mean[names[i]],3)),str(round(unbiased_std[names[i]],3))))\n",
        "    spamwriter.writerow(line)\n",
        "with open(log_dir+'stats.csv', 'a') as csvfile:    \n",
        "    writer=csv.writer(csvfile)\n",
        "    line=[]\n",
        "    for i in range(len(names)):\n",
        "        line.append(eval_mean[names[i]])\n",
        "    for i in range(len(names)):\n",
        "        line.append(unbiased_std[names[i]])\n",
        "    writer.writerow(line)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvBM27VeJQSA"
      },
      "source": [
        "exit()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}